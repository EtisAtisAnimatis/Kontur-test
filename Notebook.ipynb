{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce8cbf1a",
   "metadata": {},
   "source": [
    "# Kontur-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c3f15d",
   "metadata": {},
   "source": [
    "### Задача: Классификация новостных заголовков на реальные и ложные."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dab0a14",
   "metadata": {},
   "source": [
    "Импортируем необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65871a76",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'аааа' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14612/415948259.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mаааа\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"stopwords\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'аааа' is not defined"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "аааа\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "import string\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,LSTM,GRU,Dense,SpatialDropout1D\n",
    "from keras.initializers import Constant\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11a6b03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_stopwords = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e55baee",
   "metadata": {},
   "source": [
    "Посмотрим на данные.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8e4863f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>is_fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Москвичу Владимиру Клутину пришёл счёт за вмеш...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Агент Кокорина назвал езду по встречке житейск...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Госдума рассмотрит возможность введения секрет...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ФАС заблокировала поставку скоростных трамваев...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Против Навального завели дело о недоносительст...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  is_fake\n",
       "0  Москвичу Владимиру Клутину пришёл счёт за вмеш...        1\n",
       "1  Агент Кокорина назвал езду по встречке житейск...        0\n",
       "2  Госдума рассмотрит возможность введения секрет...        1\n",
       "3  ФАС заблокировала поставку скоростных трамваев...        0\n",
       "4  Против Навального завели дело о недоносительст...        1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.tsv',sep = '\\t')\n",
    "test = pd.read_csv('test.tsv',sep = '\\t')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b876f4a",
   "metadata": {},
   "source": [
    "1 - фейковая новость  \n",
    "0 - реальная новость"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "953e5e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ceb0a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5758.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           is_fake\n",
       "count  5758.000000\n",
       "mean      0.500000\n",
       "std       0.500043\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       0.500000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d58f5498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\George\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'samples')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=train.is_fake.value_counts()\n",
    "sns.barplot(x.index,x)\n",
    "plt.gca().set_ylabel('samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c650317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corpus(target):\n",
    "    corpus=[]\n",
    "    \n",
    "    for x in train[train['is_fake']==target]['title'].str.split():\n",
    "        for i in x:\n",
    "            corpus.append(i)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bafba0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=create_corpus(0)\n",
    "\n",
    "dic=defaultdict(int)\n",
    "\n",
    "for word in corpus:\n",
    "    if word in russian_stopwords:\n",
    "        dic[word]+=1\n",
    "        \n",
    "top=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:50] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "51829312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 50 artists>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y=zip(*top)\n",
    "plt.bar(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "16d2837a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus=create_corpus(1)\n",
    "\n",
    "dic=defaultdict(int)\n",
    "for word in corpus:\n",
    "    if word in russian_stopwords:\n",
    "        dic[word]+=1\n",
    "\n",
    "top=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10] \n",
    "    \n",
    "\n",
    "\n",
    "x,y=zip(*top)\n",
    "plt.bar(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fe767595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 1 artists>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "corpus=create_corpus(0)\n",
    "\n",
    "dic=defaultdict(int)\n",
    "special = string.punctuation\n",
    "for i in (corpus):\n",
    "    if i in special:\n",
    "        dic[i]+=1\n",
    "        \n",
    "x,y=zip(*dic.items())\n",
    "plt.bar(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9eef2b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7290dbed-f7b5-483c-b3d2-97cabe477a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6758, 2)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "88676984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def remove_punct(text):\n",
    " #   table=str.maketrans('','',string.punctuation)\n",
    "  #  return text.translate(table)\n",
    "def remove_punct(line):\n",
    "    for p in string.punctuation:\n",
    "        if p in line:\n",
    "            if p == '-':\n",
    "                line = line.replace(p, ' ')\n",
    "            else:\n",
    "                line = line.replace(p, '')\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "38cd5243",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title']=df['title'].apply(lambda x : remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d66f516f-29bb-43bb-88bc-ff1f9db6a136",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title']=df['title'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b4015221-c883-4984-af5e-a9e7c6d8fc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>is_fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>москвичу владимиру клутину пришёл счёт за вмеш...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>агент кокорина назвал езду по встречке житейск...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>госдума рассмотрит возможность введения секрет...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>фас заблокировала поставку скоростных трамваев...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>против навального завели дело о недоносительст...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>российским студентам запретят учиться за рубежом</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>путин пишет книгу об истории украины</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>россияне обхитрили рост цен</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>звезда «ворониных» раскрыл подробности о своем...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>microsoft объявила дату выхода очков дополненн...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  is_fake\n",
       "0  москвичу владимиру клутину пришёл счёт за вмеш...        1\n",
       "1  агент кокорина назвал езду по встречке житейск...        0\n",
       "2  госдума рассмотрит возможность введения секрет...        1\n",
       "3  фас заблокировала поставку скоростных трамваев...        0\n",
       "4  против навального завели дело о недоносительст...        1\n",
       "5   российским студентам запретят учиться за рубежом        1\n",
       "6               путин пишет книгу об истории украины        1\n",
       "7                        россияне обхитрили рост цен        0\n",
       "8  звезда «ворониных» раскрыл подробности о своем...        0\n",
       "9  microsoft объявила дату выхода очков дополненн...        0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ddca237b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corpus(df):\n",
    "    corpus=[]\n",
    "    for train in tqdm(df['title']):\n",
    "        words=[word.lower() for word in word_tokenize(train) if((word.isalpha()==1) & (word not in russian_stopwords) & (len(word)>3))]\n",
    "        corpus.append(words)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "18306317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6758/6758 [00:01<00:00, 5563.80it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus=create_corpus(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f0a6717d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx = 0\n",
    "for i in range(len(corpus)):\n",
    "    if len(corpus[i])>mx:\n",
    "        mx = len(corpus[i])\n",
    "mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "72d1135d-696f-40e0-8356-1d6787b3668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "    \n",
    "    PER,\n",
    "    NamesExtractor,\n",
    "\n",
    "    Doc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d29ced11",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = NewsEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0966b1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество знакомых слов:  43867\n",
      "Количество незнакомых слов:  1707\n",
      "Количество слов, которые стали знакомыми после удаления 1-2 последних букв:  422\n",
      "Итоговое кол-во незнакомых слов:  1285\n"
     ]
    }
   ],
   "source": [
    "known = 0\n",
    "unknown = 0\n",
    "unknown_became_known = 0\n",
    "corpus_known = []\n",
    "corpus_unknown = []\n",
    "for i in range(len(corpus)):\n",
    "    for j in range(len(corpus[i])):\n",
    "        if corpus[i][j] in emb:\n",
    "            known +=1\n",
    "            corpus_known.append(corpus[i][j])\n",
    "        else:\n",
    "            unknown +=1\n",
    "            if corpus[i][j][0:-1:1] in emb:\n",
    "                unknown_became_known += 1\n",
    "                corpus_known.append(corpus[i][j][0:-1:1])\n",
    "            elif corpus[i][j][0:-2:1] in emb:\n",
    "                unknown_became_known += 1\n",
    "                corpus_known.append(corpus[i][j][0:-2:1])\n",
    "            else:\n",
    "                corpus_unknown.append(corpus[i][j])\n",
    "print(\"Количество знакомых слов: \",known)\n",
    "print(\"Количество незнакомых слов: \",unknown)\n",
    "print(\"Количество слов, которые стали знакомыми после удаления 1-2 последних букв: \", unknown_became_known)\n",
    "print(\"Итоговое кол-во незнакомых слов: \", unknown - unknown_became_known )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "15ea9078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#теперь попробуем поставить слова в начальную форму используя наташку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e189b7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "syntax_parser = NewsSyntaxParser(emb)\n",
    "ner_tagger = NewsNERTagger(emb)\n",
    "names_extractor = NamesExtractor(morph_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "781ad571",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = np.arange(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e53ef118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>is_fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>москвичу владимиру клутину пришёл счёт за вмеш...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>агент кокорина назвал езду по встречке житейск...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>госдума рассмотрит возможность введения секрет...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>фас заблокировала поставку скоростных трамваев...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>против навального завели дело о недоносительст...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6753</th>\n",
       "      <td>прокуратура заподозрила явлинского в авторитар...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6754</th>\n",
       "      <td>в день победы стратегические ракетоносцы ту 16...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6755</th>\n",
       "      <td>ск возбудил дело против авиакомпании «победа» ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6756</th>\n",
       "      <td>криптомонетный двор туркменистана выпустил юби...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6757</th>\n",
       "      <td>deutsche bahn заплатит рекордный штраф за чтен...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6758 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  is_fake\n",
       "0     москвичу владимиру клутину пришёл счёт за вмеш...        1\n",
       "1     агент кокорина назвал езду по встречке житейск...        0\n",
       "2     госдума рассмотрит возможность введения секрет...        1\n",
       "3     фас заблокировала поставку скоростных трамваев...        0\n",
       "4     против навального завели дело о недоносительст...        1\n",
       "...                                                 ...      ...\n",
       "6753  прокуратура заподозрила явлинского в авторитар...        0\n",
       "6754  в день победы стратегические ракетоносцы ту 16...        0\n",
       "6755  ск возбудил дело против авиакомпании «победа» ...        0\n",
       "6756  криптомонетный двор туркменистана выпустил юби...        0\n",
       "6757  deutsche bahn заплатит рекордный штраф за чтен...        0\n",
       "\n",
       "[6758 rows x 2 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2f7db188",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(corpus_unknown)):\n",
    "    corpus_unknown[i] = Doc(corpus_unknown[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8c6c4019",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_lemms = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "93ad51ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(corpus_unknown)):\n",
    "    corpus_unknown[i].segment(segmenter)\n",
    "    corpus_unknown[i].tag_morph(morph_tagger)\n",
    "    corpus_unknown[i].tokens[0].lemmatize(morph_vocab)\n",
    "    corpus_lemms.append(corpus_unknown[i].tokens[0].lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "07594bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "uncnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ace2632b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(corpus_lemms)):\n",
    "    if corpus_lemms[i] in emb:\n",
    "        cnt +=1\n",
    "        corpus_known.append(corpus_lemms[i])\n",
    "    elif corpus_lemms[i][0:-1:1] in emb:\n",
    "        cnt +=1\n",
    "        corpus_known.append(corpus_lemms[i][0:-1:1])\n",
    "    elif corpus_lemms[i][0:-2:1] in emb:\n",
    "        cnt +=1\n",
    "        corpus_known.append(corpus_lemms[i][0:-2:1])\n",
    "    else:\n",
    "        uncnt += 1\n",
    "\n",
    "print(cnt)\n",
    "# 349 слов изучено"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4d60f79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44638"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9b989a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18806"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(corpus_known))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d63e643b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'бузова' in emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "eafd9e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN=20\n",
    "tokenizer_obj=Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(corpus)\n",
    "sequences=tokenizer_obj.texts_to_sequences(corpus)\n",
    "\n",
    "tweet_pad=pad_sequences(sequences,maxlen=MAX_LEN,truncating='post',padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d8a4ed10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6801,  1816,  6802, ...,     0,     0,     0],\n",
       "       [ 2505,  6805,    34, ...,     0,     0,     0],\n",
       "       [   74,  1082,   876, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [ 2403,    95,    11, ...,     0,     0,     0],\n",
       "       [19783, 19784,  2323, ...,     0,     0,     0],\n",
       "       [ 3498, 19786,  1117, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bf789394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 19787\n"
     ]
    }
   ],
   "source": [
    "word_index=tokenizer_obj.word_index\n",
    "print('Number of unique words:',len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8071eb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19787/19787 [00:01<00:00, 12925.02it/s]\n"
     ]
    }
   ],
   "source": [
    "num_words=len(word_index)+1\n",
    "embedding_matrix=np.zeros((num_words,300))\n",
    "\n",
    "for word,i in tqdm(word_index.items()):\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    \n",
    "    if word in emb:\n",
    "        embedding_matrix[i]=emb[word]\n",
    "    elif word[0:-1:1] in emb:\n",
    "        embedding_matrix[i] = emb[word[0:-1:1]]\n",
    "    elif word[0:-2:1] in emb:\n",
    "        embedding_matrix[i] = emb[word[0:-2:1]]\n",
    "    else:\n",
    "        word = Doc(word)\n",
    "        word.segment(segmenter)\n",
    "        word.tag_morph(morph_tagger)\n",
    "        word.tokens[0].lemmatize(morph_vocab)\n",
    "        if word.tokens[0].lemma in emb:\n",
    "            embedding_matrix[i] = emb[word.tokens[0].lemma]\n",
    "        elif word.tokens[0].lemma[0:-1:1] in emb:\n",
    "            embedding_matrix[i] = emb[word.tokens[0].lemma[0:-1:1]]\n",
    "        elif word.tokens[0].lemma[0:-2:1] in emb:\n",
    "            embedding_matrix[i] = emb[word.tokens[0].lemma[0:-2:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "668b41e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "\n",
    "embedding=Embedding(num_words,300,embeddings_initializer=Constant(embedding_matrix),\n",
    "                   input_length=MAX_LEN,trainable=False)\n",
    "\n",
    "model.add(embedding)\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(64 , dropout=0.2, recurrent_dropout=0.2,kernel_initializer='glorot_uniform'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "optimzer=Adam(learning_rate=1e-5)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimzer,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bc676bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 20, 300)           5936400   \n",
      "                                                                 \n",
      " spatial_dropout1d_8 (Spatia  (None, 20, 300)          0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 64)                93440     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,029,905\n",
      "Trainable params: 93,505\n",
      "Non-trainable params: 5,936,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f8d22d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_m =tweet_pad[:train.shape[0]]\n",
    "test_m =tweet_pad[train.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c6cb18c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train (4894, 20)\n",
      "Shape of Validation  (864, 20)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(train_m,train['is_fake'].values,test_size=0.15)\n",
    "print('Shape of train',X_train.shape)\n",
    "print(\"Shape of Validation \",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "07ec4a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "98/98 - 7s - loss: 0.6927 - accuracy: 0.4990 - val_loss: 0.6915 - val_accuracy: 0.5475 - 7s/epoch - 71ms/step\n",
      "Epoch 2/50\n",
      "98/98 - 3s - loss: 0.6914 - accuracy: 0.5513 - val_loss: 0.6899 - val_accuracy: 0.6100 - 3s/epoch - 27ms/step\n",
      "Epoch 3/50\n",
      "98/98 - 3s - loss: 0.6901 - accuracy: 0.5770 - val_loss: 0.6880 - val_accuracy: 0.6528 - 3s/epoch - 27ms/step\n",
      "Epoch 4/50\n",
      "98/98 - 3s - loss: 0.6882 - accuracy: 0.6212 - val_loss: 0.6855 - val_accuracy: 0.6759 - 3s/epoch - 28ms/step\n",
      "Epoch 5/50\n",
      "98/98 - 3s - loss: 0.6859 - accuracy: 0.6430 - val_loss: 0.6819 - val_accuracy: 0.6944 - 3s/epoch - 32ms/step\n",
      "Epoch 6/50\n",
      "98/98 - 3s - loss: 0.6825 - accuracy: 0.6571 - val_loss: 0.6768 - val_accuracy: 0.7083 - 3s/epoch - 31ms/step\n",
      "Epoch 7/50\n",
      "98/98 - 10s - loss: 0.6781 - accuracy: 0.6676 - val_loss: 0.6689 - val_accuracy: 0.7234 - 10s/epoch - 99ms/step\n",
      "Epoch 8/50\n",
      "98/98 - 3s - loss: 0.6709 - accuracy: 0.6806 - val_loss: 0.6567 - val_accuracy: 0.7373 - 3s/epoch - 28ms/step\n",
      "Epoch 9/50\n",
      "98/98 - 3s - loss: 0.6593 - accuracy: 0.6908 - val_loss: 0.6375 - val_accuracy: 0.7407 - 3s/epoch - 27ms/step\n",
      "Epoch 10/50\n",
      "98/98 - 3s - loss: 0.6412 - accuracy: 0.6992 - val_loss: 0.6077 - val_accuracy: 0.7442 - 3s/epoch - 27ms/step\n",
      "Epoch 11/50\n",
      "98/98 - 3s - loss: 0.6180 - accuracy: 0.7064 - val_loss: 0.5717 - val_accuracy: 0.7569 - 3s/epoch - 27ms/step\n",
      "Epoch 12/50\n",
      "98/98 - 3s - loss: 0.5868 - accuracy: 0.7264 - val_loss: 0.5332 - val_accuracy: 0.7720 - 3s/epoch - 29ms/step\n",
      "Epoch 13/50\n",
      "98/98 - 3s - loss: 0.5608 - accuracy: 0.7378 - val_loss: 0.5027 - val_accuracy: 0.7743 - 3s/epoch - 31ms/step\n",
      "Epoch 14/50\n",
      "98/98 - 3s - loss: 0.5370 - accuracy: 0.7542 - val_loss: 0.4793 - val_accuracy: 0.7812 - 3s/epoch - 32ms/step\n",
      "Epoch 15/50\n",
      "98/98 - 3s - loss: 0.5235 - accuracy: 0.7562 - val_loss: 0.4632 - val_accuracy: 0.7917 - 3s/epoch - 31ms/step\n",
      "Epoch 16/50\n",
      "98/98 - 3s - loss: 0.5055 - accuracy: 0.7722 - val_loss: 0.4513 - val_accuracy: 0.7975 - 3s/epoch - 29ms/step\n",
      "Epoch 17/50\n",
      "98/98 - 3s - loss: 0.4988 - accuracy: 0.7675 - val_loss: 0.4429 - val_accuracy: 0.7963 - 3s/epoch - 29ms/step\n",
      "Epoch 18/50\n",
      "98/98 - 3s - loss: 0.4893 - accuracy: 0.7636 - val_loss: 0.4373 - val_accuracy: 0.7986 - 3s/epoch - 32ms/step\n",
      "Epoch 19/50\n",
      "98/98 - 3s - loss: 0.4815 - accuracy: 0.7722 - val_loss: 0.4331 - val_accuracy: 0.8009 - 3s/epoch - 32ms/step\n",
      "Epoch 20/50\n",
      "98/98 - 3s - loss: 0.4761 - accuracy: 0.7767 - val_loss: 0.4295 - val_accuracy: 0.8044 - 3s/epoch - 32ms/step\n",
      "Epoch 21/50\n",
      "98/98 - 3s - loss: 0.4722 - accuracy: 0.7746 - val_loss: 0.4269 - val_accuracy: 0.8009 - 3s/epoch - 32ms/step\n",
      "Epoch 22/50\n",
      "98/98 - 3s - loss: 0.4672 - accuracy: 0.7826 - val_loss: 0.4254 - val_accuracy: 0.7998 - 3s/epoch - 31ms/step\n",
      "Epoch 23/50\n",
      "98/98 - 3s - loss: 0.4649 - accuracy: 0.7818 - val_loss: 0.4231 - val_accuracy: 0.8032 - 3s/epoch - 31ms/step\n",
      "Epoch 24/50\n",
      "98/98 - 3s - loss: 0.4606 - accuracy: 0.7840 - val_loss: 0.4217 - val_accuracy: 0.7998 - 3s/epoch - 33ms/step\n",
      "Epoch 25/50\n",
      "98/98 - 3s - loss: 0.4561 - accuracy: 0.7838 - val_loss: 0.4201 - val_accuracy: 0.8009 - 3s/epoch - 31ms/step\n",
      "Epoch 26/50\n",
      "98/98 - 3s - loss: 0.4581 - accuracy: 0.7897 - val_loss: 0.4186 - val_accuracy: 0.7963 - 3s/epoch - 32ms/step\n",
      "Epoch 27/50\n",
      "98/98 - 3s - loss: 0.4532 - accuracy: 0.7879 - val_loss: 0.4176 - val_accuracy: 0.7986 - 3s/epoch - 31ms/step\n",
      "Epoch 28/50\n",
      "98/98 - 3s - loss: 0.4512 - accuracy: 0.7914 - val_loss: 0.4161 - val_accuracy: 0.7975 - 3s/epoch - 32ms/step\n",
      "Epoch 29/50\n",
      "98/98 - 3s - loss: 0.4498 - accuracy: 0.7906 - val_loss: 0.4160 - val_accuracy: 0.7986 - 3s/epoch - 33ms/step\n",
      "Epoch 30/50\n",
      "98/98 - 3s - loss: 0.4456 - accuracy: 0.7934 - val_loss: 0.4141 - val_accuracy: 0.8009 - 3s/epoch - 31ms/step\n",
      "Epoch 31/50\n",
      "98/98 - 3s - loss: 0.4524 - accuracy: 0.7922 - val_loss: 0.4132 - val_accuracy: 0.7998 - 3s/epoch - 31ms/step\n",
      "Epoch 32/50\n",
      "98/98 - 3s - loss: 0.4428 - accuracy: 0.7971 - val_loss: 0.4116 - val_accuracy: 0.7986 - 3s/epoch - 31ms/step\n",
      "Epoch 33/50\n",
      "98/98 - 4s - loss: 0.4409 - accuracy: 0.7955 - val_loss: 0.4111 - val_accuracy: 0.7975 - 4s/epoch - 37ms/step\n",
      "Epoch 34/50\n",
      "98/98 - 5s - loss: 0.4396 - accuracy: 0.7977 - val_loss: 0.4102 - val_accuracy: 0.8009 - 5s/epoch - 48ms/step\n",
      "Epoch 35/50\n",
      "98/98 - 5s - loss: 0.4379 - accuracy: 0.7973 - val_loss: 0.4091 - val_accuracy: 0.7998 - 5s/epoch - 48ms/step\n",
      "Epoch 36/50\n",
      "98/98 - 4s - loss: 0.4320 - accuracy: 0.8008 - val_loss: 0.4083 - val_accuracy: 0.8009 - 4s/epoch - 42ms/step\n",
      "Epoch 37/50\n",
      "98/98 - 4s - loss: 0.4400 - accuracy: 0.7977 - val_loss: 0.4076 - val_accuracy: 0.8009 - 4s/epoch - 43ms/step\n",
      "Epoch 38/50\n",
      "98/98 - 4s - loss: 0.4339 - accuracy: 0.8038 - val_loss: 0.4067 - val_accuracy: 0.8021 - 4s/epoch - 42ms/step\n",
      "Epoch 39/50\n",
      "98/98 - 4s - loss: 0.4360 - accuracy: 0.7975 - val_loss: 0.4060 - val_accuracy: 0.8021 - 4s/epoch - 42ms/step\n",
      "Epoch 40/50\n",
      "98/98 - 4s - loss: 0.4361 - accuracy: 0.7977 - val_loss: 0.4060 - val_accuracy: 0.8032 - 4s/epoch - 40ms/step\n",
      "Epoch 41/50\n",
      "98/98 - 4s - loss: 0.4331 - accuracy: 0.8016 - val_loss: 0.4057 - val_accuracy: 0.8079 - 4s/epoch - 44ms/step\n",
      "Epoch 42/50\n",
      "98/98 - 4s - loss: 0.4321 - accuracy: 0.8026 - val_loss: 0.4051 - val_accuracy: 0.8079 - 4s/epoch - 44ms/step\n",
      "Epoch 43/50\n",
      "98/98 - 5s - loss: 0.4276 - accuracy: 0.8051 - val_loss: 0.4046 - val_accuracy: 0.8102 - 5s/epoch - 47ms/step\n",
      "Epoch 44/50\n",
      "98/98 - 4s - loss: 0.4308 - accuracy: 0.7985 - val_loss: 0.4033 - val_accuracy: 0.8113 - 4s/epoch - 41ms/step\n",
      "Epoch 45/50\n",
      "98/98 - 4s - loss: 0.4302 - accuracy: 0.8047 - val_loss: 0.4029 - val_accuracy: 0.8113 - 4s/epoch - 41ms/step\n",
      "Epoch 46/50\n",
      "98/98 - 4s - loss: 0.4264 - accuracy: 0.8079 - val_loss: 0.4024 - val_accuracy: 0.8113 - 4s/epoch - 42ms/step\n",
      "Epoch 47/50\n",
      "98/98 - 4s - loss: 0.4267 - accuracy: 0.8055 - val_loss: 0.4014 - val_accuracy: 0.8125 - 4s/epoch - 39ms/step\n",
      "Epoch 48/50\n",
      "98/98 - 4s - loss: 0.4255 - accuracy: 0.8043 - val_loss: 0.4007 - val_accuracy: 0.8125 - 4s/epoch - 36ms/step\n",
      "Epoch 49/50\n",
      "98/98 - 4s - loss: 0.4196 - accuracy: 0.8067 - val_loss: 0.4006 - val_accuracy: 0.8137 - 4s/epoch - 38ms/step\n",
      "Epoch 50/50\n",
      "98/98 - 3s - loss: 0.4255 - accuracy: 0.8045 - val_loss: 0.3997 - val_accuracy: 0.8148 - 3s/epoch - 34ms/step\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,batch_size=50,epochs=50,validation_data=(X_test,y_test),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "cd235b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "49/49 - 3s - loss: 0.4148 - accuracy: 0.8141 - val_loss: 0.3994 - val_accuracy: 0.8148 - 3s/epoch - 54ms/step\n",
      "Epoch 2/50\n",
      "49/49 - 3s - loss: 0.4140 - accuracy: 0.8092 - val_loss: 0.3988 - val_accuracy: 0.8171 - 3s/epoch - 52ms/step\n",
      "Epoch 3/50\n",
      "49/49 - 3s - loss: 0.4207 - accuracy: 0.8075 - val_loss: 0.3986 - val_accuracy: 0.8171 - 3s/epoch - 52ms/step\n",
      "Epoch 4/50\n",
      "49/49 - 3s - loss: 0.4246 - accuracy: 0.8089 - val_loss: 0.3982 - val_accuracy: 0.8171 - 3s/epoch - 55ms/step\n",
      "Epoch 5/50\n",
      "49/49 - 3s - loss: 0.4174 - accuracy: 0.8116 - val_loss: 0.3977 - val_accuracy: 0.8160 - 3s/epoch - 54ms/step\n",
      "Epoch 6/50\n",
      "49/49 - 3s - loss: 0.4140 - accuracy: 0.8112 - val_loss: 0.3972 - val_accuracy: 0.8171 - 3s/epoch - 53ms/step\n",
      "Epoch 7/50\n",
      "49/49 - 3s - loss: 0.4143 - accuracy: 0.8157 - val_loss: 0.3970 - val_accuracy: 0.8171 - 3s/epoch - 51ms/step\n",
      "Epoch 8/50\n",
      "49/49 - 3s - loss: 0.4203 - accuracy: 0.8110 - val_loss: 0.3967 - val_accuracy: 0.8171 - 3s/epoch - 51ms/step\n",
      "Epoch 9/50\n",
      "49/49 - 3s - loss: 0.4204 - accuracy: 0.8098 - val_loss: 0.3963 - val_accuracy: 0.8160 - 3s/epoch - 52ms/step\n",
      "Epoch 10/50\n",
      "49/49 - 3s - loss: 0.4134 - accuracy: 0.8130 - val_loss: 0.3961 - val_accuracy: 0.8148 - 3s/epoch - 53ms/step\n",
      "Epoch 11/50\n",
      "49/49 - 3s - loss: 0.4165 - accuracy: 0.8163 - val_loss: 0.3962 - val_accuracy: 0.8171 - 3s/epoch - 56ms/step\n",
      "Epoch 12/50\n",
      "49/49 - 3s - loss: 0.4165 - accuracy: 0.8163 - val_loss: 0.3957 - val_accuracy: 0.8183 - 3s/epoch - 53ms/step\n",
      "Epoch 13/50\n",
      "49/49 - 3s - loss: 0.4117 - accuracy: 0.8157 - val_loss: 0.3950 - val_accuracy: 0.8148 - 3s/epoch - 54ms/step\n",
      "Epoch 14/50\n",
      "49/49 - 4s - loss: 0.4110 - accuracy: 0.8177 - val_loss: 0.3947 - val_accuracy: 0.8148 - 4s/epoch - 72ms/step\n",
      "Epoch 15/50\n",
      "49/49 - 3s - loss: 0.4101 - accuracy: 0.8132 - val_loss: 0.3945 - val_accuracy: 0.8137 - 3s/epoch - 64ms/step\n",
      "Epoch 16/50\n",
      "49/49 - 3s - loss: 0.4114 - accuracy: 0.8202 - val_loss: 0.3943 - val_accuracy: 0.8137 - 3s/epoch - 63ms/step\n",
      "Epoch 17/50\n",
      "49/49 - 3s - loss: 0.4130 - accuracy: 0.8087 - val_loss: 0.3943 - val_accuracy: 0.8160 - 3s/epoch - 61ms/step\n",
      "Epoch 18/50\n",
      "49/49 - 3s - loss: 0.4159 - accuracy: 0.8147 - val_loss: 0.3941 - val_accuracy: 0.8160 - 3s/epoch - 61ms/step\n",
      "Epoch 19/50\n",
      "49/49 - 3s - loss: 0.4101 - accuracy: 0.8114 - val_loss: 0.3936 - val_accuracy: 0.8171 - 3s/epoch - 58ms/step\n",
      "Epoch 20/50\n",
      "49/49 - 3s - loss: 0.4090 - accuracy: 0.8204 - val_loss: 0.3933 - val_accuracy: 0.8183 - 3s/epoch - 64ms/step\n",
      "Epoch 21/50\n",
      "49/49 - 3s - loss: 0.4198 - accuracy: 0.8128 - val_loss: 0.3930 - val_accuracy: 0.8183 - 3s/epoch - 71ms/step\n",
      "Epoch 22/50\n",
      "49/49 - 3s - loss: 0.4051 - accuracy: 0.8147 - val_loss: 0.3925 - val_accuracy: 0.8183 - 3s/epoch - 64ms/step\n",
      "Epoch 23/50\n",
      "49/49 - 3s - loss: 0.4069 - accuracy: 0.8190 - val_loss: 0.3922 - val_accuracy: 0.8183 - 3s/epoch - 62ms/step\n",
      "Epoch 24/50\n",
      "49/49 - 4s - loss: 0.4053 - accuracy: 0.8155 - val_loss: 0.3920 - val_accuracy: 0.8183 - 4s/epoch - 73ms/step\n",
      "Epoch 25/50\n",
      "49/49 - 3s - loss: 0.4063 - accuracy: 0.8204 - val_loss: 0.3914 - val_accuracy: 0.8183 - 3s/epoch - 62ms/step\n",
      "Epoch 26/50\n",
      "49/49 - 3s - loss: 0.4043 - accuracy: 0.8198 - val_loss: 0.3916 - val_accuracy: 0.8183 - 3s/epoch - 58ms/step\n",
      "Epoch 27/50\n",
      "49/49 - 3s - loss: 0.4093 - accuracy: 0.8165 - val_loss: 0.3919 - val_accuracy: 0.8183 - 3s/epoch - 61ms/step\n",
      "Epoch 28/50\n",
      "49/49 - 3s - loss: 0.4084 - accuracy: 0.8147 - val_loss: 0.3916 - val_accuracy: 0.8183 - 3s/epoch - 55ms/step\n",
      "Epoch 29/50\n",
      "49/49 - 3s - loss: 0.4040 - accuracy: 0.8226 - val_loss: 0.3908 - val_accuracy: 0.8183 - 3s/epoch - 52ms/step\n",
      "Epoch 30/50\n",
      "49/49 - 3s - loss: 0.4044 - accuracy: 0.8143 - val_loss: 0.3901 - val_accuracy: 0.8194 - 3s/epoch - 52ms/step\n",
      "Epoch 31/50\n",
      "49/49 - 3s - loss: 0.4056 - accuracy: 0.8159 - val_loss: 0.3899 - val_accuracy: 0.8183 - 3s/epoch - 53ms/step\n",
      "Epoch 32/50\n",
      "49/49 - 3s - loss: 0.4055 - accuracy: 0.8151 - val_loss: 0.3897 - val_accuracy: 0.8171 - 3s/epoch - 54ms/step\n",
      "Epoch 33/50\n",
      "49/49 - 3s - loss: 0.4022 - accuracy: 0.8190 - val_loss: 0.3898 - val_accuracy: 0.8183 - 3s/epoch - 56ms/step\n",
      "Epoch 34/50\n",
      "49/49 - 3s - loss: 0.4038 - accuracy: 0.8159 - val_loss: 0.3888 - val_accuracy: 0.8171 - 3s/epoch - 53ms/step\n",
      "Epoch 35/50\n",
      "49/49 - 3s - loss: 0.3965 - accuracy: 0.8265 - val_loss: 0.3888 - val_accuracy: 0.8160 - 3s/epoch - 52ms/step\n",
      "Epoch 36/50\n",
      "49/49 - 3s - loss: 0.3976 - accuracy: 0.8208 - val_loss: 0.3884 - val_accuracy: 0.8160 - 3s/epoch - 51ms/step\n",
      "Epoch 37/50\n",
      "49/49 - 3s - loss: 0.4032 - accuracy: 0.8220 - val_loss: 0.3879 - val_accuracy: 0.8183 - 3s/epoch - 53ms/step\n",
      "Epoch 38/50\n",
      "49/49 - 3s - loss: 0.3994 - accuracy: 0.8192 - val_loss: 0.3881 - val_accuracy: 0.8171 - 3s/epoch - 56ms/step\n",
      "Epoch 39/50\n",
      "49/49 - 3s - loss: 0.4032 - accuracy: 0.8171 - val_loss: 0.3881 - val_accuracy: 0.8171 - 3s/epoch - 56ms/step\n",
      "Epoch 40/50\n",
      "49/49 - 3s - loss: 0.3977 - accuracy: 0.8175 - val_loss: 0.3873 - val_accuracy: 0.8171 - 3s/epoch - 55ms/step\n",
      "Epoch 41/50\n",
      "49/49 - 3s - loss: 0.3987 - accuracy: 0.8171 - val_loss: 0.3865 - val_accuracy: 0.8171 - 3s/epoch - 52ms/step\n",
      "Epoch 42/50\n",
      "49/49 - 3s - loss: 0.3936 - accuracy: 0.8230 - val_loss: 0.3863 - val_accuracy: 0.8171 - 3s/epoch - 52ms/step\n",
      "Epoch 43/50\n",
      "49/49 - 3s - loss: 0.3953 - accuracy: 0.8228 - val_loss: 0.3863 - val_accuracy: 0.8171 - 3s/epoch - 51ms/step\n",
      "Epoch 44/50\n",
      "49/49 - 3s - loss: 0.3987 - accuracy: 0.8175 - val_loss: 0.3855 - val_accuracy: 0.8171 - 3s/epoch - 53ms/step\n",
      "Epoch 45/50\n",
      "49/49 - 3s - loss: 0.3958 - accuracy: 0.8212 - val_loss: 0.3853 - val_accuracy: 0.8171 - 3s/epoch - 56ms/step\n",
      "Epoch 46/50\n",
      "49/49 - 3s - loss: 0.3955 - accuracy: 0.8224 - val_loss: 0.3844 - val_accuracy: 0.8183 - 3s/epoch - 52ms/step\n",
      "Epoch 47/50\n",
      "49/49 - 3s - loss: 0.3996 - accuracy: 0.8241 - val_loss: 0.3841 - val_accuracy: 0.8183 - 3s/epoch - 51ms/step\n",
      "Epoch 48/50\n",
      "49/49 - 3s - loss: 0.3937 - accuracy: 0.8210 - val_loss: 0.3841 - val_accuracy: 0.8171 - 3s/epoch - 51ms/step\n",
      "Epoch 49/50\n",
      "49/49 - 3s - loss: 0.3914 - accuracy: 0.8243 - val_loss: 0.3845 - val_accuracy: 0.8218 - 3s/epoch - 53ms/step\n",
      "Epoch 50/50\n",
      "49/49 - 3s - loss: 0.4014 - accuracy: 0.8220 - val_loss: 0.3840 - val_accuracy: 0.8206 - 3s/epoch - 52ms/step\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,batch_size=100,epochs=50,validation_data=(X_test,y_test),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "45f60899",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "49/49 - 2s - loss: 0.3928 - accuracy: 0.8245 - val_loss: 0.3838 - val_accuracy: 0.8206 - 2s/epoch - 48ms/step\n",
      "Epoch 2/250\n",
      "49/49 - 3s - loss: 0.3957 - accuracy: 0.8253 - val_loss: 0.3836 - val_accuracy: 0.8206 - 3s/epoch - 53ms/step\n",
      "Epoch 3/250\n",
      "49/49 - 2s - loss: 0.3914 - accuracy: 0.8235 - val_loss: 0.3835 - val_accuracy: 0.8206 - 2s/epoch - 49ms/step\n",
      "Epoch 4/250\n",
      "49/49 - 2s - loss: 0.3940 - accuracy: 0.8237 - val_loss: 0.3834 - val_accuracy: 0.8206 - 2s/epoch - 47ms/step\n",
      "Epoch 5/250\n",
      "49/49 - 2s - loss: 0.3899 - accuracy: 0.8318 - val_loss: 0.3829 - val_accuracy: 0.8206 - 2s/epoch - 46ms/step\n",
      "Epoch 6/250\n",
      "49/49 - 2s - loss: 0.3843 - accuracy: 0.8288 - val_loss: 0.3826 - val_accuracy: 0.8194 - 2s/epoch - 47ms/step\n",
      "Epoch 7/250\n",
      "49/49 - 2s - loss: 0.3862 - accuracy: 0.8282 - val_loss: 0.3824 - val_accuracy: 0.8194 - 2s/epoch - 46ms/step\n",
      "Epoch 8/250\n",
      "49/49 - 2s - loss: 0.3878 - accuracy: 0.8275 - val_loss: 0.3822 - val_accuracy: 0.8206 - 2s/epoch - 47ms/step\n",
      "Epoch 9/250\n",
      "49/49 - 2s - loss: 0.3927 - accuracy: 0.8284 - val_loss: 0.3820 - val_accuracy: 0.8206 - 2s/epoch - 46ms/step\n",
      "Epoch 10/250\n",
      "49/49 - 2s - loss: 0.3913 - accuracy: 0.8247 - val_loss: 0.3809 - val_accuracy: 0.8206 - 2s/epoch - 45ms/step\n",
      "Epoch 11/250\n",
      "49/49 - 2s - loss: 0.3908 - accuracy: 0.8226 - val_loss: 0.3809 - val_accuracy: 0.8206 - 2s/epoch - 47ms/step\n",
      "Epoch 12/250\n",
      "49/49 - 3s - loss: 0.3844 - accuracy: 0.8288 - val_loss: 0.3803 - val_accuracy: 0.8218 - 3s/epoch - 57ms/step\n",
      "Epoch 13/250\n",
      "49/49 - 3s - loss: 0.3864 - accuracy: 0.8265 - val_loss: 0.3809 - val_accuracy: 0.8218 - 3s/epoch - 57ms/step\n",
      "Epoch 14/250\n",
      "49/49 - 3s - loss: 0.3931 - accuracy: 0.8267 - val_loss: 0.3798 - val_accuracy: 0.8218 - 3s/epoch - 59ms/step\n",
      "Epoch 15/250\n",
      "49/49 - 3s - loss: 0.3847 - accuracy: 0.8253 - val_loss: 0.3795 - val_accuracy: 0.8229 - 3s/epoch - 64ms/step\n",
      "Epoch 16/250\n",
      "49/49 - 3s - loss: 0.3921 - accuracy: 0.8263 - val_loss: 0.3787 - val_accuracy: 0.8229 - 3s/epoch - 65ms/step\n",
      "Epoch 17/250\n",
      "49/49 - 3s - loss: 0.3787 - accuracy: 0.8327 - val_loss: 0.3787 - val_accuracy: 0.8229 - 3s/epoch - 58ms/step\n",
      "Epoch 18/250\n",
      "49/49 - 3s - loss: 0.3792 - accuracy: 0.8341 - val_loss: 0.3787 - val_accuracy: 0.8241 - 3s/epoch - 56ms/step\n",
      "Epoch 19/250\n",
      "49/49 - 3s - loss: 0.3857 - accuracy: 0.8269 - val_loss: 0.3780 - val_accuracy: 0.8241 - 3s/epoch - 56ms/step\n",
      "Epoch 20/250\n",
      "49/49 - 3s - loss: 0.3834 - accuracy: 0.8312 - val_loss: 0.3782 - val_accuracy: 0.8241 - 3s/epoch - 59ms/step\n",
      "Epoch 21/250\n",
      "49/49 - 3s - loss: 0.3814 - accuracy: 0.8292 - val_loss: 0.3781 - val_accuracy: 0.8241 - 3s/epoch - 62ms/step\n",
      "Epoch 22/250\n",
      "49/49 - 3s - loss: 0.3833 - accuracy: 0.8306 - val_loss: 0.3782 - val_accuracy: 0.8229 - 3s/epoch - 57ms/step\n",
      "Epoch 23/250\n",
      "49/49 - 3s - loss: 0.3771 - accuracy: 0.8351 - val_loss: 0.3777 - val_accuracy: 0.8241 - 3s/epoch - 56ms/step\n",
      "Epoch 24/250\n",
      "49/49 - 3s - loss: 0.3857 - accuracy: 0.8259 - val_loss: 0.3769 - val_accuracy: 0.8241 - 3s/epoch - 54ms/step\n",
      "Epoch 25/250\n",
      "49/49 - 3s - loss: 0.3745 - accuracy: 0.8318 - val_loss: 0.3771 - val_accuracy: 0.8241 - 3s/epoch - 59ms/step\n",
      "Epoch 26/250\n",
      "49/49 - 3s - loss: 0.3789 - accuracy: 0.8337 - val_loss: 0.3762 - val_accuracy: 0.8241 - 3s/epoch - 57ms/step\n",
      "Epoch 27/250\n",
      "49/49 - 3s - loss: 0.3877 - accuracy: 0.8261 - val_loss: 0.3759 - val_accuracy: 0.8241 - 3s/epoch - 53ms/step\n",
      "Epoch 28/250\n",
      "49/49 - 2s - loss: 0.3764 - accuracy: 0.8335 - val_loss: 0.3760 - val_accuracy: 0.8252 - 2s/epoch - 47ms/step\n",
      "Epoch 29/250\n",
      "49/49 - 2s - loss: 0.3833 - accuracy: 0.8302 - val_loss: 0.3758 - val_accuracy: 0.8252 - 2s/epoch - 47ms/step\n",
      "Epoch 30/250\n",
      "49/49 - 2s - loss: 0.3801 - accuracy: 0.8318 - val_loss: 0.3760 - val_accuracy: 0.8264 - 2s/epoch - 47ms/step\n",
      "Epoch 31/250\n",
      "49/49 - 2s - loss: 0.3869 - accuracy: 0.8288 - val_loss: 0.3747 - val_accuracy: 0.8252 - 2s/epoch - 47ms/step\n",
      "Epoch 32/250\n",
      "49/49 - 2s - loss: 0.3711 - accuracy: 0.8327 - val_loss: 0.3745 - val_accuracy: 0.8252 - 2s/epoch - 47ms/step\n",
      "Epoch 33/250\n",
      "49/49 - 2s - loss: 0.3714 - accuracy: 0.8371 - val_loss: 0.3745 - val_accuracy: 0.8241 - 2s/epoch - 47ms/step\n",
      "Epoch 34/250\n",
      "49/49 - 2s - loss: 0.3707 - accuracy: 0.8378 - val_loss: 0.3754 - val_accuracy: 0.8252 - 2s/epoch - 48ms/step\n",
      "Epoch 35/250\n",
      "49/49 - 2s - loss: 0.3677 - accuracy: 0.8369 - val_loss: 0.3749 - val_accuracy: 0.8252 - 2s/epoch - 49ms/step\n",
      "Epoch 36/250\n",
      "49/49 - 2s - loss: 0.3754 - accuracy: 0.8345 - val_loss: 0.3742 - val_accuracy: 0.8264 - 2s/epoch - 49ms/step\n",
      "Epoch 37/250\n",
      "49/49 - 2s - loss: 0.3763 - accuracy: 0.8353 - val_loss: 0.3740 - val_accuracy: 0.8264 - 2s/epoch - 49ms/step\n",
      "Epoch 38/250\n",
      "49/49 - 2s - loss: 0.3767 - accuracy: 0.8357 - val_loss: 0.3738 - val_accuracy: 0.8264 - 2s/epoch - 48ms/step\n",
      "Epoch 39/250\n",
      "49/49 - 2s - loss: 0.3751 - accuracy: 0.8363 - val_loss: 0.3735 - val_accuracy: 0.8264 - 2s/epoch - 50ms/step\n",
      "Epoch 40/250\n",
      "49/49 - 3s - loss: 0.3726 - accuracy: 0.8329 - val_loss: 0.3732 - val_accuracy: 0.8264 - 3s/epoch - 55ms/step\n",
      "Epoch 41/250\n",
      "49/49 - 2s - loss: 0.3693 - accuracy: 0.8351 - val_loss: 0.3723 - val_accuracy: 0.8275 - 2s/epoch - 50ms/step\n",
      "Epoch 42/250\n",
      "49/49 - 3s - loss: 0.3727 - accuracy: 0.8316 - val_loss: 0.3719 - val_accuracy: 0.8275 - 3s/epoch - 60ms/step\n",
      "Epoch 43/250\n",
      "49/49 - 2s - loss: 0.3716 - accuracy: 0.8333 - val_loss: 0.3725 - val_accuracy: 0.8275 - 2s/epoch - 48ms/step\n",
      "Epoch 44/250\n",
      "49/49 - 2s - loss: 0.3687 - accuracy: 0.8402 - val_loss: 0.3720 - val_accuracy: 0.8275 - 2s/epoch - 48ms/step\n",
      "Epoch 45/250\n",
      "49/49 - 2s - loss: 0.3727 - accuracy: 0.8349 - val_loss: 0.3715 - val_accuracy: 0.8287 - 2s/epoch - 48ms/step\n",
      "Epoch 46/250\n",
      "49/49 - 2s - loss: 0.3738 - accuracy: 0.8418 - val_loss: 0.3712 - val_accuracy: 0.8310 - 2s/epoch - 49ms/step\n",
      "Epoch 47/250\n",
      "49/49 - 2s - loss: 0.3728 - accuracy: 0.8351 - val_loss: 0.3715 - val_accuracy: 0.8299 - 2s/epoch - 47ms/step\n",
      "Epoch 48/250\n",
      "49/49 - 3s - loss: 0.3709 - accuracy: 0.8382 - val_loss: 0.3715 - val_accuracy: 0.8299 - 3s/epoch - 61ms/step\n",
      "Epoch 49/250\n",
      "49/49 - 3s - loss: 0.3683 - accuracy: 0.8406 - val_loss: 0.3703 - val_accuracy: 0.8310 - 3s/epoch - 55ms/step\n",
      "Epoch 50/250\n",
      "49/49 - 2s - loss: 0.3690 - accuracy: 0.8380 - val_loss: 0.3697 - val_accuracy: 0.8310 - 2s/epoch - 50ms/step\n",
      "Epoch 51/250\n",
      "49/49 - 2s - loss: 0.3675 - accuracy: 0.8347 - val_loss: 0.3695 - val_accuracy: 0.8310 - 2s/epoch - 49ms/step\n",
      "Epoch 52/250\n",
      "49/49 - 2s - loss: 0.3680 - accuracy: 0.8320 - val_loss: 0.3695 - val_accuracy: 0.8299 - 2s/epoch - 50ms/step\n",
      "Epoch 53/250\n",
      "49/49 - 2s - loss: 0.3693 - accuracy: 0.8369 - val_loss: 0.3699 - val_accuracy: 0.8287 - 2s/epoch - 49ms/step\n",
      "Epoch 54/250\n",
      "49/49 - 3s - loss: 0.3649 - accuracy: 0.8410 - val_loss: 0.3687 - val_accuracy: 0.8310 - 3s/epoch - 53ms/step\n",
      "Epoch 55/250\n",
      "49/49 - 3s - loss: 0.3659 - accuracy: 0.8406 - val_loss: 0.3690 - val_accuracy: 0.8287 - 3s/epoch - 51ms/step\n",
      "Epoch 56/250\n",
      "49/49 - 2s - loss: 0.3569 - accuracy: 0.8435 - val_loss: 0.3688 - val_accuracy: 0.8310 - 2s/epoch - 47ms/step\n",
      "Epoch 57/250\n",
      "49/49 - 2s - loss: 0.3719 - accuracy: 0.8410 - val_loss: 0.3684 - val_accuracy: 0.8310 - 2s/epoch - 48ms/step\n",
      "Epoch 58/250\n",
      "49/49 - 3s - loss: 0.3637 - accuracy: 0.8423 - val_loss: 0.3675 - val_accuracy: 0.8310 - 3s/epoch - 51ms/step\n",
      "Epoch 59/250\n",
      "49/49 - 3s - loss: 0.3755 - accuracy: 0.8316 - val_loss: 0.3677 - val_accuracy: 0.8299 - 3s/epoch - 51ms/step\n",
      "Epoch 60/250\n",
      "49/49 - 3s - loss: 0.3579 - accuracy: 0.8363 - val_loss: 0.3668 - val_accuracy: 0.8310 - 3s/epoch - 52ms/step\n",
      "Epoch 61/250\n",
      "49/49 - 3s - loss: 0.3615 - accuracy: 0.8492 - val_loss: 0.3657 - val_accuracy: 0.8299 - 3s/epoch - 53ms/step\n",
      "Epoch 62/250\n",
      "49/49 - 3s - loss: 0.3574 - accuracy: 0.8445 - val_loss: 0.3674 - val_accuracy: 0.8287 - 3s/epoch - 58ms/step\n",
      "Epoch 63/250\n",
      "49/49 - 3s - loss: 0.3579 - accuracy: 0.8443 - val_loss: 0.3666 - val_accuracy: 0.8299 - 3s/epoch - 57ms/step\n",
      "Epoch 64/250\n",
      "49/49 - 3s - loss: 0.3660 - accuracy: 0.8404 - val_loss: 0.3661 - val_accuracy: 0.8310 - 3s/epoch - 56ms/step\n",
      "Epoch 65/250\n",
      "49/49 - 3s - loss: 0.3642 - accuracy: 0.8359 - val_loss: 0.3655 - val_accuracy: 0.8310 - 3s/epoch - 52ms/step\n",
      "Epoch 66/250\n",
      "49/49 - 3s - loss: 0.3610 - accuracy: 0.8435 - val_loss: 0.3664 - val_accuracy: 0.8310 - 3s/epoch - 56ms/step\n",
      "Epoch 67/250\n",
      "49/49 - 3s - loss: 0.3649 - accuracy: 0.8408 - val_loss: 0.3660 - val_accuracy: 0.8322 - 3s/epoch - 58ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/250\n",
      "49/49 - 3s - loss: 0.3605 - accuracy: 0.8429 - val_loss: 0.3650 - val_accuracy: 0.8322 - 3s/epoch - 51ms/step\n",
      "Epoch 69/250\n",
      "49/49 - 3s - loss: 0.3650 - accuracy: 0.8361 - val_loss: 0.3647 - val_accuracy: 0.8322 - 3s/epoch - 53ms/step\n",
      "Epoch 70/250\n",
      "49/49 - 3s - loss: 0.3584 - accuracy: 0.8470 - val_loss: 0.3634 - val_accuracy: 0.8310 - 3s/epoch - 61ms/step\n",
      "Epoch 71/250\n",
      "49/49 - 3s - loss: 0.3660 - accuracy: 0.8357 - val_loss: 0.3642 - val_accuracy: 0.8310 - 3s/epoch - 59ms/step\n",
      "Epoch 72/250\n",
      "49/49 - 2s - loss: 0.3627 - accuracy: 0.8431 - val_loss: 0.3629 - val_accuracy: 0.8322 - 2s/epoch - 50ms/step\n",
      "Epoch 73/250\n",
      "49/49 - 3s - loss: 0.3605 - accuracy: 0.8374 - val_loss: 0.3632 - val_accuracy: 0.8299 - 3s/epoch - 56ms/step\n",
      "Epoch 74/250\n",
      "49/49 - 3s - loss: 0.3553 - accuracy: 0.8447 - val_loss: 0.3626 - val_accuracy: 0.8299 - 3s/epoch - 62ms/step\n",
      "Epoch 75/250\n",
      "49/49 - 3s - loss: 0.3619 - accuracy: 0.8404 - val_loss: 0.3630 - val_accuracy: 0.8299 - 3s/epoch - 55ms/step\n",
      "Epoch 76/250\n",
      "49/49 - 2s - loss: 0.3671 - accuracy: 0.8355 - val_loss: 0.3632 - val_accuracy: 0.8299 - 2s/epoch - 51ms/step\n",
      "Epoch 77/250\n",
      "49/49 - 2s - loss: 0.3567 - accuracy: 0.8439 - val_loss: 0.3625 - val_accuracy: 0.8310 - 2s/epoch - 50ms/step\n",
      "Epoch 78/250\n",
      "49/49 - 2s - loss: 0.3573 - accuracy: 0.8416 - val_loss: 0.3606 - val_accuracy: 0.8322 - 2s/epoch - 48ms/step\n",
      "Epoch 79/250\n",
      "49/49 - 3s - loss: 0.3630 - accuracy: 0.8396 - val_loss: 0.3611 - val_accuracy: 0.8310 - 3s/epoch - 52ms/step\n",
      "Epoch 80/250\n",
      "49/49 - 2s - loss: 0.3512 - accuracy: 0.8451 - val_loss: 0.3607 - val_accuracy: 0.8310 - 2s/epoch - 49ms/step\n",
      "Epoch 81/250\n",
      "49/49 - 2s - loss: 0.3571 - accuracy: 0.8429 - val_loss: 0.3620 - val_accuracy: 0.8299 - 2s/epoch - 50ms/step\n",
      "Epoch 82/250\n",
      "49/49 - 3s - loss: 0.3561 - accuracy: 0.8474 - val_loss: 0.3615 - val_accuracy: 0.8287 - 3s/epoch - 54ms/step\n",
      "Epoch 83/250\n",
      "49/49 - 3s - loss: 0.3492 - accuracy: 0.8519 - val_loss: 0.3615 - val_accuracy: 0.8310 - 3s/epoch - 55ms/step\n",
      "Epoch 84/250\n",
      "49/49 - 2s - loss: 0.3506 - accuracy: 0.8463 - val_loss: 0.3610 - val_accuracy: 0.8299 - 2s/epoch - 50ms/step\n",
      "Epoch 85/250\n",
      "49/49 - 3s - loss: 0.3574 - accuracy: 0.8468 - val_loss: 0.3601 - val_accuracy: 0.8299 - 3s/epoch - 59ms/step\n",
      "Epoch 86/250\n",
      "49/49 - 2s - loss: 0.3484 - accuracy: 0.8465 - val_loss: 0.3599 - val_accuracy: 0.8287 - 2s/epoch - 51ms/step\n",
      "Epoch 87/250\n",
      "49/49 - 3s - loss: 0.3526 - accuracy: 0.8443 - val_loss: 0.3598 - val_accuracy: 0.8287 - 3s/epoch - 56ms/step\n",
      "Epoch 88/250\n",
      "49/49 - 3s - loss: 0.3507 - accuracy: 0.8498 - val_loss: 0.3600 - val_accuracy: 0.8299 - 3s/epoch - 56ms/step\n",
      "Epoch 89/250\n",
      "49/49 - 3s - loss: 0.3463 - accuracy: 0.8447 - val_loss: 0.3590 - val_accuracy: 0.8299 - 3s/epoch - 57ms/step\n",
      "Epoch 90/250\n",
      "49/49 - 3s - loss: 0.3509 - accuracy: 0.8453 - val_loss: 0.3595 - val_accuracy: 0.8322 - 3s/epoch - 57ms/step\n",
      "Epoch 91/250\n",
      "49/49 - 2s - loss: 0.3516 - accuracy: 0.8461 - val_loss: 0.3590 - val_accuracy: 0.8333 - 2s/epoch - 50ms/step\n",
      "Epoch 92/250\n",
      "49/49 - 3s - loss: 0.3480 - accuracy: 0.8455 - val_loss: 0.3584 - val_accuracy: 0.8333 - 3s/epoch - 53ms/step\n",
      "Epoch 93/250\n",
      "49/49 - 3s - loss: 0.3525 - accuracy: 0.8443 - val_loss: 0.3593 - val_accuracy: 0.8322 - 3s/epoch - 56ms/step\n",
      "Epoch 94/250\n",
      "49/49 - 3s - loss: 0.3539 - accuracy: 0.8486 - val_loss: 0.3578 - val_accuracy: 0.8322 - 3s/epoch - 60ms/step\n",
      "Epoch 95/250\n",
      "49/49 - 3s - loss: 0.3440 - accuracy: 0.8508 - val_loss: 0.3585 - val_accuracy: 0.8333 - 3s/epoch - 62ms/step\n",
      "Epoch 96/250\n",
      "49/49 - 3s - loss: 0.3484 - accuracy: 0.8519 - val_loss: 0.3587 - val_accuracy: 0.8322 - 3s/epoch - 52ms/step\n",
      "Epoch 97/250\n",
      "49/49 - 3s - loss: 0.3493 - accuracy: 0.8465 - val_loss: 0.3593 - val_accuracy: 0.8345 - 3s/epoch - 55ms/step\n",
      "Epoch 98/250\n",
      "49/49 - 3s - loss: 0.3434 - accuracy: 0.8508 - val_loss: 0.3585 - val_accuracy: 0.8345 - 3s/epoch - 64ms/step\n",
      "Epoch 99/250\n",
      "49/49 - 3s - loss: 0.3424 - accuracy: 0.8539 - val_loss: 0.3569 - val_accuracy: 0.8322 - 3s/epoch - 60ms/step\n",
      "Epoch 100/250\n",
      "49/49 - 3s - loss: 0.3492 - accuracy: 0.8463 - val_loss: 0.3572 - val_accuracy: 0.8333 - 3s/epoch - 60ms/step\n",
      "Epoch 101/250\n",
      "49/49 - 3s - loss: 0.3449 - accuracy: 0.8492 - val_loss: 0.3578 - val_accuracy: 0.8333 - 3s/epoch - 57ms/step\n",
      "Epoch 102/250\n",
      "49/49 - 3s - loss: 0.3448 - accuracy: 0.8492 - val_loss: 0.3560 - val_accuracy: 0.8345 - 3s/epoch - 58ms/step\n",
      "Epoch 103/250\n",
      "49/49 - 3s - loss: 0.3490 - accuracy: 0.8476 - val_loss: 0.3562 - val_accuracy: 0.8322 - 3s/epoch - 63ms/step\n",
      "Epoch 104/250\n",
      "49/49 - 3s - loss: 0.3473 - accuracy: 0.8502 - val_loss: 0.3568 - val_accuracy: 0.8322 - 3s/epoch - 56ms/step\n",
      "Epoch 105/250\n",
      "49/49 - 3s - loss: 0.3512 - accuracy: 0.8404 - val_loss: 0.3560 - val_accuracy: 0.8322 - 3s/epoch - 58ms/step\n",
      "Epoch 106/250\n",
      "49/49 - 3s - loss: 0.3375 - accuracy: 0.8527 - val_loss: 0.3554 - val_accuracy: 0.8333 - 3s/epoch - 53ms/step\n",
      "Epoch 107/250\n",
      "49/49 - 3s - loss: 0.3424 - accuracy: 0.8498 - val_loss: 0.3554 - val_accuracy: 0.8322 - 3s/epoch - 53ms/step\n",
      "Epoch 108/250\n",
      "49/49 - 3s - loss: 0.3452 - accuracy: 0.8502 - val_loss: 0.3556 - val_accuracy: 0.8333 - 3s/epoch - 52ms/step\n",
      "Epoch 109/250\n",
      "49/49 - 3s - loss: 0.3433 - accuracy: 0.8494 - val_loss: 0.3560 - val_accuracy: 0.8322 - 3s/epoch - 58ms/step\n",
      "Epoch 110/250\n",
      "49/49 - 3s - loss: 0.3374 - accuracy: 0.8539 - val_loss: 0.3555 - val_accuracy: 0.8322 - 3s/epoch - 55ms/step\n",
      "Epoch 111/250\n",
      "49/49 - 3s - loss: 0.3485 - accuracy: 0.8500 - val_loss: 0.3532 - val_accuracy: 0.8322 - 3s/epoch - 60ms/step\n",
      "Epoch 112/250\n",
      "49/49 - 3s - loss: 0.3433 - accuracy: 0.8496 - val_loss: 0.3543 - val_accuracy: 0.8333 - 3s/epoch - 58ms/step\n",
      "Epoch 113/250\n",
      "49/49 - 3s - loss: 0.3407 - accuracy: 0.8564 - val_loss: 0.3540 - val_accuracy: 0.8333 - 3s/epoch - 52ms/step\n",
      "Epoch 114/250\n",
      "49/49 - 2s - loss: 0.3477 - accuracy: 0.8461 - val_loss: 0.3531 - val_accuracy: 0.8310 - 2s/epoch - 50ms/step\n",
      "Epoch 115/250\n",
      "49/49 - 2s - loss: 0.3450 - accuracy: 0.8500 - val_loss: 0.3533 - val_accuracy: 0.8322 - 2s/epoch - 50ms/step\n",
      "Epoch 116/250\n",
      "49/49 - 3s - loss: 0.3385 - accuracy: 0.8564 - val_loss: 0.3541 - val_accuracy: 0.8356 - 3s/epoch - 51ms/step\n",
      "Epoch 117/250\n",
      "49/49 - 3s - loss: 0.3451 - accuracy: 0.8490 - val_loss: 0.3519 - val_accuracy: 0.8322 - 3s/epoch - 55ms/step\n",
      "Epoch 118/250\n",
      "49/49 - 4s - loss: 0.3363 - accuracy: 0.8537 - val_loss: 0.3527 - val_accuracy: 0.8322 - 4s/epoch - 75ms/step\n",
      "Epoch 119/250\n",
      "49/49 - 3s - loss: 0.3359 - accuracy: 0.8564 - val_loss: 0.3522 - val_accuracy: 0.8322 - 3s/epoch - 63ms/step\n",
      "Epoch 120/250\n",
      "49/49 - 3s - loss: 0.3385 - accuracy: 0.8531 - val_loss: 0.3522 - val_accuracy: 0.8310 - 3s/epoch - 69ms/step\n",
      "Epoch 121/250\n",
      "49/49 - 3s - loss: 0.3392 - accuracy: 0.8508 - val_loss: 0.3532 - val_accuracy: 0.8333 - 3s/epoch - 64ms/step\n",
      "Epoch 122/250\n",
      "49/49 - 3s - loss: 0.3398 - accuracy: 0.8557 - val_loss: 0.3517 - val_accuracy: 0.8322 - 3s/epoch - 65ms/step\n",
      "Epoch 123/250\n",
      "49/49 - 3s - loss: 0.3391 - accuracy: 0.8535 - val_loss: 0.3512 - val_accuracy: 0.8322 - 3s/epoch - 64ms/step\n",
      "Epoch 124/250\n",
      "49/49 - 3s - loss: 0.3373 - accuracy: 0.8555 - val_loss: 0.3511 - val_accuracy: 0.8322 - 3s/epoch - 64ms/step\n",
      "Epoch 125/250\n",
      "49/49 - 3s - loss: 0.3375 - accuracy: 0.8517 - val_loss: 0.3508 - val_accuracy: 0.8345 - 3s/epoch - 60ms/step\n",
      "Epoch 126/250\n",
      "49/49 - 3s - loss: 0.3435 - accuracy: 0.8486 - val_loss: 0.3509 - val_accuracy: 0.8356 - 3s/epoch - 59ms/step\n",
      "Epoch 127/250\n",
      "49/49 - 3s - loss: 0.3373 - accuracy: 0.8557 - val_loss: 0.3519 - val_accuracy: 0.8368 - 3s/epoch - 61ms/step\n",
      "Epoch 128/250\n",
      "49/49 - 3s - loss: 0.3323 - accuracy: 0.8572 - val_loss: 0.3503 - val_accuracy: 0.8368 - 3s/epoch - 64ms/step\n",
      "Epoch 129/250\n",
      "49/49 - 3s - loss: 0.3333 - accuracy: 0.8586 - val_loss: 0.3506 - val_accuracy: 0.8368 - 3s/epoch - 65ms/step\n",
      "Epoch 130/250\n",
      "49/49 - 3s - loss: 0.3381 - accuracy: 0.8535 - val_loss: 0.3497 - val_accuracy: 0.8368 - 3s/epoch - 61ms/step\n",
      "Epoch 131/250\n",
      "49/49 - 3s - loss: 0.3355 - accuracy: 0.8498 - val_loss: 0.3498 - val_accuracy: 0.8380 - 3s/epoch - 59ms/step\n",
      "Epoch 132/250\n",
      "49/49 - 3s - loss: 0.3228 - accuracy: 0.8621 - val_loss: 0.3497 - val_accuracy: 0.8380 - 3s/epoch - 61ms/step\n",
      "Epoch 133/250\n",
      "49/49 - 3s - loss: 0.3290 - accuracy: 0.8553 - val_loss: 0.3499 - val_accuracy: 0.8380 - 3s/epoch - 69ms/step\n",
      "Epoch 134/250\n",
      "49/49 - 3s - loss: 0.3328 - accuracy: 0.8557 - val_loss: 0.3509 - val_accuracy: 0.8391 - 3s/epoch - 69ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/250\n",
      "49/49 - 3s - loss: 0.3289 - accuracy: 0.8582 - val_loss: 0.3506 - val_accuracy: 0.8391 - 3s/epoch - 60ms/step\n",
      "Epoch 136/250\n",
      "49/49 - 3s - loss: 0.3307 - accuracy: 0.8596 - val_loss: 0.3492 - val_accuracy: 0.8368 - 3s/epoch - 60ms/step\n",
      "Epoch 137/250\n",
      "49/49 - 3s - loss: 0.3260 - accuracy: 0.8586 - val_loss: 0.3492 - val_accuracy: 0.8356 - 3s/epoch - 65ms/step\n",
      "Epoch 138/250\n",
      "49/49 - 3s - loss: 0.3349 - accuracy: 0.8551 - val_loss: 0.3476 - val_accuracy: 0.8368 - 3s/epoch - 63ms/step\n",
      "Epoch 139/250\n",
      "49/49 - 3s - loss: 0.3253 - accuracy: 0.8609 - val_loss: 0.3489 - val_accuracy: 0.8380 - 3s/epoch - 67ms/step\n",
      "Epoch 140/250\n",
      "49/49 - 3s - loss: 0.3260 - accuracy: 0.8551 - val_loss: 0.3473 - val_accuracy: 0.8403 - 3s/epoch - 58ms/step\n",
      "Epoch 141/250\n",
      "49/49 - 3s - loss: 0.3313 - accuracy: 0.8580 - val_loss: 0.3481 - val_accuracy: 0.8368 - 3s/epoch - 54ms/step\n",
      "Epoch 142/250\n",
      "49/49 - 3s - loss: 0.3344 - accuracy: 0.8551 - val_loss: 0.3475 - val_accuracy: 0.8380 - 3s/epoch - 58ms/step\n",
      "Epoch 143/250\n",
      "49/49 - 3s - loss: 0.3271 - accuracy: 0.8594 - val_loss: 0.3475 - val_accuracy: 0.8380 - 3s/epoch - 55ms/step\n",
      "Epoch 144/250\n",
      "49/49 - 3s - loss: 0.3306 - accuracy: 0.8539 - val_loss: 0.3472 - val_accuracy: 0.8403 - 3s/epoch - 59ms/step\n",
      "Epoch 145/250\n",
      "49/49 - 3s - loss: 0.3228 - accuracy: 0.8609 - val_loss: 0.3472 - val_accuracy: 0.8414 - 3s/epoch - 56ms/step\n",
      "Epoch 146/250\n",
      "49/49 - 3s - loss: 0.3311 - accuracy: 0.8568 - val_loss: 0.3469 - val_accuracy: 0.8426 - 3s/epoch - 53ms/step\n",
      "Epoch 147/250\n",
      "49/49 - 3s - loss: 0.3313 - accuracy: 0.8572 - val_loss: 0.3466 - val_accuracy: 0.8426 - 3s/epoch - 54ms/step\n",
      "Epoch 148/250\n",
      "49/49 - 3s - loss: 0.3300 - accuracy: 0.8557 - val_loss: 0.3454 - val_accuracy: 0.8438 - 3s/epoch - 55ms/step\n",
      "Epoch 149/250\n",
      "49/49 - 3s - loss: 0.3195 - accuracy: 0.8604 - val_loss: 0.3444 - val_accuracy: 0.8426 - 3s/epoch - 57ms/step\n",
      "Epoch 150/250\n",
      "49/49 - 3s - loss: 0.3215 - accuracy: 0.8609 - val_loss: 0.3445 - val_accuracy: 0.8426 - 3s/epoch - 56ms/step\n",
      "Epoch 151/250\n",
      "49/49 - 3s - loss: 0.3250 - accuracy: 0.8606 - val_loss: 0.3458 - val_accuracy: 0.8449 - 3s/epoch - 58ms/step\n",
      "Epoch 152/250\n",
      "49/49 - 3s - loss: 0.3213 - accuracy: 0.8627 - val_loss: 0.3445 - val_accuracy: 0.8438 - 3s/epoch - 57ms/step\n",
      "Epoch 153/250\n",
      "49/49 - 3s - loss: 0.3288 - accuracy: 0.8555 - val_loss: 0.3445 - val_accuracy: 0.8449 - 3s/epoch - 59ms/step\n",
      "Epoch 154/250\n",
      "49/49 - 3s - loss: 0.3221 - accuracy: 0.8621 - val_loss: 0.3435 - val_accuracy: 0.8449 - 3s/epoch - 55ms/step\n",
      "Epoch 155/250\n",
      "49/49 - 3s - loss: 0.3295 - accuracy: 0.8588 - val_loss: 0.3441 - val_accuracy: 0.8461 - 3s/epoch - 57ms/step\n",
      "Epoch 156/250\n",
      "49/49 - 3s - loss: 0.3200 - accuracy: 0.8609 - val_loss: 0.3433 - val_accuracy: 0.8438 - 3s/epoch - 54ms/step\n",
      "Epoch 157/250\n",
      "49/49 - 3s - loss: 0.3203 - accuracy: 0.8627 - val_loss: 0.3439 - val_accuracy: 0.8461 - 3s/epoch - 54ms/step\n",
      "Epoch 158/250\n",
      "49/49 - 3s - loss: 0.3240 - accuracy: 0.8647 - val_loss: 0.3447 - val_accuracy: 0.8449 - 3s/epoch - 56ms/step\n",
      "Epoch 159/250\n",
      "49/49 - 3s - loss: 0.3171 - accuracy: 0.8660 - val_loss: 0.3429 - val_accuracy: 0.8449 - 3s/epoch - 59ms/step\n",
      "Epoch 160/250\n",
      "49/49 - 4s - loss: 0.3189 - accuracy: 0.8633 - val_loss: 0.3427 - val_accuracy: 0.8461 - 4s/epoch - 77ms/step\n",
      "Epoch 161/250\n",
      "49/49 - 4s - loss: 0.3240 - accuracy: 0.8633 - val_loss: 0.3424 - val_accuracy: 0.8449 - 4s/epoch - 77ms/step\n",
      "Epoch 162/250\n",
      "49/49 - 4s - loss: 0.3263 - accuracy: 0.8576 - val_loss: 0.3430 - val_accuracy: 0.8438 - 4s/epoch - 91ms/step\n",
      "Epoch 163/250\n",
      "49/49 - 4s - loss: 0.3170 - accuracy: 0.8666 - val_loss: 0.3415 - val_accuracy: 0.8461 - 4s/epoch - 81ms/step\n",
      "Epoch 164/250\n",
      "49/49 - 4s - loss: 0.3232 - accuracy: 0.8641 - val_loss: 0.3410 - val_accuracy: 0.8461 - 4s/epoch - 77ms/step\n",
      "Epoch 165/250\n",
      "49/49 - 4s - loss: 0.3147 - accuracy: 0.8678 - val_loss: 0.3406 - val_accuracy: 0.8461 - 4s/epoch - 81ms/step\n",
      "Epoch 166/250\n",
      "49/49 - 3s - loss: 0.3186 - accuracy: 0.8592 - val_loss: 0.3423 - val_accuracy: 0.8472 - 3s/epoch - 61ms/step\n",
      "Epoch 167/250\n",
      "49/49 - 3s - loss: 0.3140 - accuracy: 0.8653 - val_loss: 0.3418 - val_accuracy: 0.8484 - 3s/epoch - 51ms/step\n",
      "Epoch 168/250\n",
      "49/49 - 3s - loss: 0.3141 - accuracy: 0.8666 - val_loss: 0.3416 - val_accuracy: 0.8495 - 3s/epoch - 52ms/step\n",
      "Epoch 169/250\n",
      "49/49 - 3s - loss: 0.3146 - accuracy: 0.8596 - val_loss: 0.3417 - val_accuracy: 0.8472 - 3s/epoch - 54ms/step\n",
      "Epoch 170/250\n",
      "49/49 - 4s - loss: 0.3168 - accuracy: 0.8641 - val_loss: 0.3404 - val_accuracy: 0.8484 - 4s/epoch - 84ms/step\n",
      "Epoch 171/250\n",
      "49/49 - 4s - loss: 0.3186 - accuracy: 0.8653 - val_loss: 0.3406 - val_accuracy: 0.8472 - 4s/epoch - 83ms/step\n",
      "Epoch 172/250\n",
      "49/49 - 5s - loss: 0.3207 - accuracy: 0.8653 - val_loss: 0.3401 - val_accuracy: 0.8507 - 5s/epoch - 95ms/step\n",
      "Epoch 173/250\n",
      "49/49 - 5s - loss: 0.3113 - accuracy: 0.8672 - val_loss: 0.3407 - val_accuracy: 0.8495 - 5s/epoch - 93ms/step\n",
      "Epoch 174/250\n",
      "49/49 - 4s - loss: 0.3130 - accuracy: 0.8666 - val_loss: 0.3392 - val_accuracy: 0.8472 - 4s/epoch - 86ms/step\n",
      "Epoch 175/250\n",
      "49/49 - 4s - loss: 0.3143 - accuracy: 0.8647 - val_loss: 0.3388 - val_accuracy: 0.8484 - 4s/epoch - 83ms/step\n",
      "Epoch 176/250\n",
      "49/49 - 4s - loss: 0.3107 - accuracy: 0.8655 - val_loss: 0.3386 - val_accuracy: 0.8484 - 4s/epoch - 87ms/step\n",
      "Epoch 177/250\n",
      "49/49 - 5s - loss: 0.3077 - accuracy: 0.8655 - val_loss: 0.3401 - val_accuracy: 0.8507 - 5s/epoch - 95ms/step\n",
      "Epoch 178/250\n",
      "49/49 - 5s - loss: 0.3216 - accuracy: 0.8598 - val_loss: 0.3383 - val_accuracy: 0.8484 - 5s/epoch - 101ms/step\n",
      "Epoch 179/250\n",
      "49/49 - 4s - loss: 0.3082 - accuracy: 0.8692 - val_loss: 0.3381 - val_accuracy: 0.8484 - 4s/epoch - 89ms/step\n",
      "Epoch 180/250\n",
      "49/49 - 5s - loss: 0.3146 - accuracy: 0.8641 - val_loss: 0.3392 - val_accuracy: 0.8507 - 5s/epoch - 100ms/step\n",
      "Epoch 181/250\n",
      "49/49 - 5s - loss: 0.3123 - accuracy: 0.8666 - val_loss: 0.3376 - val_accuracy: 0.8484 - 5s/epoch - 96ms/step\n",
      "Epoch 182/250\n",
      "49/49 - 5s - loss: 0.3078 - accuracy: 0.8692 - val_loss: 0.3380 - val_accuracy: 0.8507 - 5s/epoch - 97ms/step\n",
      "Epoch 183/250\n",
      "49/49 - 5s - loss: 0.3137 - accuracy: 0.8723 - val_loss: 0.3383 - val_accuracy: 0.8507 - 5s/epoch - 100ms/step\n",
      "Epoch 184/250\n",
      "49/49 - 5s - loss: 0.3016 - accuracy: 0.8739 - val_loss: 0.3365 - val_accuracy: 0.8484 - 5s/epoch - 98ms/step\n",
      "Epoch 185/250\n",
      "49/49 - 4s - loss: 0.3073 - accuracy: 0.8668 - val_loss: 0.3364 - val_accuracy: 0.8495 - 4s/epoch - 87ms/step\n",
      "Epoch 186/250\n",
      "49/49 - 4s - loss: 0.3155 - accuracy: 0.8641 - val_loss: 0.3375 - val_accuracy: 0.8507 - 4s/epoch - 87ms/step\n",
      "Epoch 187/250\n",
      "49/49 - 4s - loss: 0.3027 - accuracy: 0.8705 - val_loss: 0.3374 - val_accuracy: 0.8507 - 4s/epoch - 86ms/step\n",
      "Epoch 188/250\n",
      "49/49 - 4s - loss: 0.3111 - accuracy: 0.8676 - val_loss: 0.3361 - val_accuracy: 0.8495 - 4s/epoch - 83ms/step\n",
      "Epoch 189/250\n",
      "49/49 - 4s - loss: 0.3136 - accuracy: 0.8674 - val_loss: 0.3359 - val_accuracy: 0.8507 - 4s/epoch - 77ms/step\n",
      "Epoch 190/250\n",
      "49/49 - 4s - loss: 0.3021 - accuracy: 0.8735 - val_loss: 0.3349 - val_accuracy: 0.8507 - 4s/epoch - 80ms/step\n",
      "Epoch 191/250\n",
      "49/49 - 4s - loss: 0.3093 - accuracy: 0.8707 - val_loss: 0.3374 - val_accuracy: 0.8484 - 4s/epoch - 80ms/step\n",
      "Epoch 192/250\n",
      "49/49 - 4s - loss: 0.2985 - accuracy: 0.8705 - val_loss: 0.3367 - val_accuracy: 0.8484 - 4s/epoch - 74ms/step\n",
      "Epoch 193/250\n",
      "49/49 - 4s - loss: 0.3000 - accuracy: 0.8715 - val_loss: 0.3359 - val_accuracy: 0.8507 - 4s/epoch - 75ms/step\n",
      "Epoch 194/250\n",
      "49/49 - 4s - loss: 0.3048 - accuracy: 0.8700 - val_loss: 0.3347 - val_accuracy: 0.8507 - 4s/epoch - 72ms/step\n",
      "Epoch 195/250\n",
      "49/49 - 4s - loss: 0.3073 - accuracy: 0.8651 - val_loss: 0.3344 - val_accuracy: 0.8507 - 4s/epoch - 75ms/step\n",
      "Epoch 196/250\n",
      "49/49 - 4s - loss: 0.3061 - accuracy: 0.8692 - val_loss: 0.3350 - val_accuracy: 0.8519 - 4s/epoch - 78ms/step\n",
      "Epoch 197/250\n",
      "49/49 - 4s - loss: 0.3097 - accuracy: 0.8662 - val_loss: 0.3341 - val_accuracy: 0.8530 - 4s/epoch - 81ms/step\n",
      "Epoch 198/250\n",
      "49/49 - 4s - loss: 0.3033 - accuracy: 0.8768 - val_loss: 0.3336 - val_accuracy: 0.8530 - 4s/epoch - 77ms/step\n",
      "Epoch 199/250\n",
      "49/49 - 4s - loss: 0.3030 - accuracy: 0.8698 - val_loss: 0.3339 - val_accuracy: 0.8542 - 4s/epoch - 74ms/step\n",
      "Epoch 200/250\n",
      "49/49 - 4s - loss: 0.2970 - accuracy: 0.8733 - val_loss: 0.3342 - val_accuracy: 0.8530 - 4s/epoch - 75ms/step\n",
      "Epoch 201/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 - 4s - loss: 0.3124 - accuracy: 0.8643 - val_loss: 0.3344 - val_accuracy: 0.8519 - 4s/epoch - 82ms/step\n",
      "Epoch 202/250\n",
      "49/49 - 4s - loss: 0.2953 - accuracy: 0.8752 - val_loss: 0.3331 - val_accuracy: 0.8530 - 4s/epoch - 76ms/step\n",
      "Epoch 203/250\n",
      "49/49 - 4s - loss: 0.3003 - accuracy: 0.8739 - val_loss: 0.3339 - val_accuracy: 0.8542 - 4s/epoch - 74ms/step\n",
      "Epoch 204/250\n",
      "49/49 - 4s - loss: 0.3024 - accuracy: 0.8698 - val_loss: 0.3335 - val_accuracy: 0.8542 - 4s/epoch - 75ms/step\n",
      "Epoch 205/250\n",
      "49/49 - 4s - loss: 0.2972 - accuracy: 0.8752 - val_loss: 0.3330 - val_accuracy: 0.8542 - 4s/epoch - 78ms/step\n",
      "Epoch 206/250\n",
      "49/49 - 4s - loss: 0.2990 - accuracy: 0.8739 - val_loss: 0.3319 - val_accuracy: 0.8542 - 4s/epoch - 76ms/step\n",
      "Epoch 207/250\n",
      "49/49 - 4s - loss: 0.3015 - accuracy: 0.8655 - val_loss: 0.3329 - val_accuracy: 0.8530 - 4s/epoch - 77ms/step\n",
      "Epoch 208/250\n",
      "49/49 - 4s - loss: 0.3059 - accuracy: 0.8690 - val_loss: 0.3309 - val_accuracy: 0.8542 - 4s/epoch - 78ms/step\n",
      "Epoch 209/250\n",
      "49/49 - 4s - loss: 0.3050 - accuracy: 0.8678 - val_loss: 0.3318 - val_accuracy: 0.8542 - 4s/epoch - 77ms/step\n",
      "Epoch 210/250\n",
      "49/49 - 4s - loss: 0.2959 - accuracy: 0.8739 - val_loss: 0.3314 - val_accuracy: 0.8542 - 4s/epoch - 79ms/step\n",
      "Epoch 211/250\n",
      "49/49 - 4s - loss: 0.3080 - accuracy: 0.8707 - val_loss: 0.3320 - val_accuracy: 0.8530 - 4s/epoch - 79ms/step\n",
      "Epoch 212/250\n",
      "49/49 - 4s - loss: 0.2974 - accuracy: 0.8749 - val_loss: 0.3290 - val_accuracy: 0.8565 - 4s/epoch - 76ms/step\n",
      "Epoch 213/250\n",
      "49/49 - 4s - loss: 0.3002 - accuracy: 0.8727 - val_loss: 0.3306 - val_accuracy: 0.8542 - 4s/epoch - 79ms/step\n",
      "Epoch 214/250\n",
      "49/49 - 4s - loss: 0.3003 - accuracy: 0.8709 - val_loss: 0.3294 - val_accuracy: 0.8553 - 4s/epoch - 74ms/step\n",
      "Epoch 215/250\n",
      "49/49 - 4s - loss: 0.2966 - accuracy: 0.8725 - val_loss: 0.3304 - val_accuracy: 0.8519 - 4s/epoch - 77ms/step\n",
      "Epoch 216/250\n",
      "49/49 - 4s - loss: 0.2975 - accuracy: 0.8772 - val_loss: 0.3303 - val_accuracy: 0.8519 - 4s/epoch - 74ms/step\n",
      "Epoch 217/250\n",
      "49/49 - 4s - loss: 0.2997 - accuracy: 0.8739 - val_loss: 0.3307 - val_accuracy: 0.8519 - 4s/epoch - 75ms/step\n",
      "Epoch 218/250\n",
      "49/49 - 4s - loss: 0.3038 - accuracy: 0.8666 - val_loss: 0.3290 - val_accuracy: 0.8530 - 4s/epoch - 82ms/step\n",
      "Epoch 219/250\n",
      "49/49 - 4s - loss: 0.3001 - accuracy: 0.8733 - val_loss: 0.3295 - val_accuracy: 0.8507 - 4s/epoch - 77ms/step\n",
      "Epoch 220/250\n",
      "49/49 - 4s - loss: 0.3019 - accuracy: 0.8700 - val_loss: 0.3281 - val_accuracy: 0.8553 - 4s/epoch - 72ms/step\n",
      "Epoch 221/250\n",
      "49/49 - 4s - loss: 0.2915 - accuracy: 0.8784 - val_loss: 0.3276 - val_accuracy: 0.8553 - 4s/epoch - 78ms/step\n",
      "Epoch 222/250\n",
      "49/49 - 4s - loss: 0.2901 - accuracy: 0.8770 - val_loss: 0.3283 - val_accuracy: 0.8530 - 4s/epoch - 80ms/step\n",
      "Epoch 223/250\n",
      "49/49 - 4s - loss: 0.2924 - accuracy: 0.8741 - val_loss: 0.3290 - val_accuracy: 0.8530 - 4s/epoch - 81ms/step\n",
      "Epoch 224/250\n",
      "49/49 - 4s - loss: 0.2977 - accuracy: 0.8694 - val_loss: 0.3264 - val_accuracy: 0.8576 - 4s/epoch - 78ms/step\n",
      "Epoch 225/250\n",
      "49/49 - 4s - loss: 0.2873 - accuracy: 0.8809 - val_loss: 0.3266 - val_accuracy: 0.8553 - 4s/epoch - 81ms/step\n",
      "Epoch 226/250\n",
      "49/49 - 4s - loss: 0.3024 - accuracy: 0.8721 - val_loss: 0.3297 - val_accuracy: 0.8519 - 4s/epoch - 80ms/step\n",
      "Epoch 227/250\n",
      "49/49 - 4s - loss: 0.2964 - accuracy: 0.8662 - val_loss: 0.3267 - val_accuracy: 0.8530 - 4s/epoch - 79ms/step\n",
      "Epoch 228/250\n",
      "49/49 - 4s - loss: 0.2950 - accuracy: 0.8770 - val_loss: 0.3293 - val_accuracy: 0.8507 - 4s/epoch - 82ms/step\n",
      "Epoch 229/250\n",
      "49/49 - 4s - loss: 0.2928 - accuracy: 0.8782 - val_loss: 0.3270 - val_accuracy: 0.8542 - 4s/epoch - 82ms/step\n",
      "Epoch 230/250\n",
      "49/49 - 4s - loss: 0.2852 - accuracy: 0.8803 - val_loss: 0.3265 - val_accuracy: 0.8542 - 4s/epoch - 82ms/step\n",
      "Epoch 231/250\n",
      "49/49 - 4s - loss: 0.2850 - accuracy: 0.8786 - val_loss: 0.3255 - val_accuracy: 0.8565 - 4s/epoch - 79ms/step\n",
      "Epoch 232/250\n",
      "49/49 - 4s - loss: 0.2858 - accuracy: 0.8799 - val_loss: 0.3263 - val_accuracy: 0.8565 - 4s/epoch - 77ms/step\n",
      "Epoch 233/250\n",
      "49/49 - 5s - loss: 0.2921 - accuracy: 0.8786 - val_loss: 0.3260 - val_accuracy: 0.8565 - 5s/epoch - 93ms/step\n",
      "Epoch 234/250\n",
      "49/49 - 4s - loss: 0.2888 - accuracy: 0.8799 - val_loss: 0.3247 - val_accuracy: 0.8553 - 4s/epoch - 78ms/step\n",
      "Epoch 235/250\n",
      "49/49 - 3s - loss: 0.2892 - accuracy: 0.8743 - val_loss: 0.3250 - val_accuracy: 0.8565 - 3s/epoch - 71ms/step\n",
      "Epoch 236/250\n",
      "49/49 - 3s - loss: 0.2846 - accuracy: 0.8848 - val_loss: 0.3254 - val_accuracy: 0.8576 - 3s/epoch - 64ms/step\n",
      "Epoch 237/250\n",
      "49/49 - 3s - loss: 0.2894 - accuracy: 0.8774 - val_loss: 0.3263 - val_accuracy: 0.8542 - 3s/epoch - 57ms/step\n",
      "Epoch 238/250\n",
      "49/49 - 3s - loss: 0.2913 - accuracy: 0.8774 - val_loss: 0.3255 - val_accuracy: 0.8588 - 3s/epoch - 53ms/step\n",
      "Epoch 239/250\n",
      "49/49 - 3s - loss: 0.2910 - accuracy: 0.8799 - val_loss: 0.3254 - val_accuracy: 0.8553 - 3s/epoch - 55ms/step\n",
      "Epoch 240/250\n",
      "49/49 - 3s - loss: 0.2972 - accuracy: 0.8723 - val_loss: 0.3234 - val_accuracy: 0.8588 - 3s/epoch - 54ms/step\n",
      "Epoch 241/250\n",
      "49/49 - 3s - loss: 0.2837 - accuracy: 0.8794 - val_loss: 0.3243 - val_accuracy: 0.8553 - 3s/epoch - 55ms/step\n",
      "Epoch 242/250\n",
      "49/49 - 3s - loss: 0.2766 - accuracy: 0.8827 - val_loss: 0.3247 - val_accuracy: 0.8565 - 3s/epoch - 56ms/step\n",
      "Epoch 243/250\n",
      "49/49 - 3s - loss: 0.2845 - accuracy: 0.8823 - val_loss: 0.3239 - val_accuracy: 0.8542 - 3s/epoch - 57ms/step\n",
      "Epoch 244/250\n",
      "49/49 - 3s - loss: 0.2816 - accuracy: 0.8819 - val_loss: 0.3258 - val_accuracy: 0.8565 - 3s/epoch - 57ms/step\n",
      "Epoch 245/250\n",
      "49/49 - 3s - loss: 0.2803 - accuracy: 0.8846 - val_loss: 0.3247 - val_accuracy: 0.8565 - 3s/epoch - 58ms/step\n",
      "Epoch 246/250\n",
      "49/49 - 3s - loss: 0.2829 - accuracy: 0.8764 - val_loss: 0.3246 - val_accuracy: 0.8565 - 3s/epoch - 59ms/step\n",
      "Epoch 247/250\n",
      "49/49 - 3s - loss: 0.2867 - accuracy: 0.8760 - val_loss: 0.3250 - val_accuracy: 0.8542 - 3s/epoch - 71ms/step\n",
      "Epoch 248/250\n",
      "49/49 - 4s - loss: 0.2785 - accuracy: 0.8817 - val_loss: 0.3256 - val_accuracy: 0.8553 - 4s/epoch - 84ms/step\n",
      "Epoch 249/250\n",
      "49/49 - 4s - loss: 0.2869 - accuracy: 0.8807 - val_loss: 0.3239 - val_accuracy: 0.8553 - 4s/epoch - 80ms/step\n",
      "Epoch 250/250\n",
      "49/49 - 4s - loss: 0.2832 - accuracy: 0.8841 - val_loss: 0.3236 - val_accuracy: 0.8565 - 4s/epoch - 82ms/step\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,batch_size=100,epochs=250,validation_data=(X_test,y_test),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5f6c991f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "1224/1224 - 20s - loss: 0.2872 - accuracy: 0.8782 - val_loss: 0.3166 - val_accuracy: 0.8634 - 20s/epoch - 16ms/step\n",
      "Epoch 2/250\n",
      "1224/1224 - 20s - loss: 0.2762 - accuracy: 0.8856 - val_loss: 0.3170 - val_accuracy: 0.8646 - 20s/epoch - 16ms/step\n",
      "Epoch 3/250\n",
      "1224/1224 - 23s - loss: 0.2777 - accuracy: 0.8856 - val_loss: 0.3186 - val_accuracy: 0.8634 - 23s/epoch - 19ms/step\n",
      "Epoch 4/250\n",
      "1224/1224 - 26s - loss: 0.2765 - accuracy: 0.8852 - val_loss: 0.3156 - val_accuracy: 0.8669 - 26s/epoch - 21ms/step\n",
      "Epoch 5/250\n",
      "1224/1224 - 25s - loss: 0.2792 - accuracy: 0.8807 - val_loss: 0.3121 - val_accuracy: 0.8727 - 25s/epoch - 21ms/step\n",
      "Epoch 6/250\n",
      "1224/1224 - 27s - loss: 0.2797 - accuracy: 0.8833 - val_loss: 0.3176 - val_accuracy: 0.8634 - 27s/epoch - 22ms/step\n",
      "Epoch 7/250\n",
      "1224/1224 - 28s - loss: 0.2709 - accuracy: 0.8862 - val_loss: 0.3119 - val_accuracy: 0.8727 - 28s/epoch - 23ms/step\n",
      "Epoch 8/250\n",
      "1224/1224 - 22s - loss: 0.2725 - accuracy: 0.8846 - val_loss: 0.3140 - val_accuracy: 0.8646 - 22s/epoch - 18ms/step\n",
      "Epoch 9/250\n",
      "1224/1224 - 30s - loss: 0.2551 - accuracy: 0.8950 - val_loss: 0.3265 - val_accuracy: 0.8623 - 30s/epoch - 24ms/step\n",
      "Epoch 10/250\n",
      "1224/1224 - 27s - loss: 0.2625 - accuracy: 0.8841 - val_loss: 0.3137 - val_accuracy: 0.8646 - 27s/epoch - 22ms/step\n",
      "Epoch 11/250\n",
      "1224/1224 - 28s - loss: 0.2669 - accuracy: 0.8860 - val_loss: 0.3158 - val_accuracy: 0.8657 - 28s/epoch - 23ms/step\n",
      "Epoch 12/250\n",
      "1224/1224 - 26s - loss: 0.2575 - accuracy: 0.8911 - val_loss: 0.3228 - val_accuracy: 0.8646 - 26s/epoch - 21ms/step\n",
      "Epoch 13/250\n",
      "1224/1224 - 19s - loss: 0.2526 - accuracy: 0.8964 - val_loss: 0.3162 - val_accuracy: 0.8715 - 19s/epoch - 15ms/step\n",
      "Epoch 14/250\n",
      "1224/1224 - 22s - loss: 0.2583 - accuracy: 0.8929 - val_loss: 0.3176 - val_accuracy: 0.8750 - 22s/epoch - 18ms/step\n",
      "Epoch 15/250\n",
      "1224/1224 - 26s - loss: 0.2525 - accuracy: 0.8929 - val_loss: 0.3169 - val_accuracy: 0.8727 - 26s/epoch - 21ms/step\n",
      "Epoch 16/250\n",
      "1224/1224 - 24s - loss: 0.2473 - accuracy: 0.8956 - val_loss: 0.3139 - val_accuracy: 0.8681 - 24s/epoch - 20ms/step\n",
      "Epoch 17/250\n",
      "1224/1224 - 26s - loss: 0.2521 - accuracy: 0.8960 - val_loss: 0.3232 - val_accuracy: 0.8704 - 26s/epoch - 21ms/step\n",
      "Epoch 18/250\n",
      "1224/1224 - 23s - loss: 0.2462 - accuracy: 0.8997 - val_loss: 0.3222 - val_accuracy: 0.8727 - 23s/epoch - 19ms/step\n",
      "Epoch 19/250\n",
      "1224/1224 - 25s - loss: 0.2578 - accuracy: 0.8921 - val_loss: 0.3109 - val_accuracy: 0.8715 - 25s/epoch - 20ms/step\n",
      "Epoch 20/250\n",
      "1224/1224 - 28s - loss: 0.2466 - accuracy: 0.9013 - val_loss: 0.3094 - val_accuracy: 0.8727 - 28s/epoch - 23ms/step\n",
      "Epoch 21/250\n",
      "1224/1224 - 27s - loss: 0.2407 - accuracy: 0.8989 - val_loss: 0.3117 - val_accuracy: 0.8704 - 27s/epoch - 22ms/step\n",
      "Epoch 22/250\n",
      "1224/1224 - 26s - loss: 0.2384 - accuracy: 0.9005 - val_loss: 0.3208 - val_accuracy: 0.8715 - 26s/epoch - 21ms/step\n",
      "Epoch 23/250\n",
      "1224/1224 - 26s - loss: 0.2407 - accuracy: 0.8980 - val_loss: 0.3092 - val_accuracy: 0.8750 - 26s/epoch - 21ms/step\n",
      "Epoch 24/250\n",
      "1224/1224 - 23s - loss: 0.2414 - accuracy: 0.9015 - val_loss: 0.3170 - val_accuracy: 0.8738 - 23s/epoch - 19ms/step\n",
      "Epoch 25/250\n",
      "1224/1224 - 23s - loss: 0.2436 - accuracy: 0.9021 - val_loss: 0.3191 - val_accuracy: 0.8692 - 23s/epoch - 18ms/step\n",
      "Epoch 26/250\n",
      "1224/1224 - 25s - loss: 0.2355 - accuracy: 0.9019 - val_loss: 0.3183 - val_accuracy: 0.8704 - 25s/epoch - 20ms/step\n",
      "Epoch 27/250\n",
      "1224/1224 - 23s - loss: 0.2245 - accuracy: 0.9128 - val_loss: 0.3071 - val_accuracy: 0.8773 - 23s/epoch - 19ms/step\n",
      "Epoch 28/250\n",
      "1224/1224 - 23s - loss: 0.2293 - accuracy: 0.9056 - val_loss: 0.3092 - val_accuracy: 0.8785 - 23s/epoch - 19ms/step\n",
      "Epoch 29/250\n",
      "1224/1224 - 24s - loss: 0.2338 - accuracy: 0.9042 - val_loss: 0.3089 - val_accuracy: 0.8750 - 24s/epoch - 19ms/step\n",
      "Epoch 30/250\n",
      "1224/1224 - 24s - loss: 0.2258 - accuracy: 0.9099 - val_loss: 0.3088 - val_accuracy: 0.8738 - 24s/epoch - 19ms/step\n",
      "Epoch 31/250\n",
      "1224/1224 - 22s - loss: 0.2255 - accuracy: 0.9085 - val_loss: 0.3145 - val_accuracy: 0.8738 - 22s/epoch - 18ms/step\n",
      "Epoch 32/250\n",
      "1224/1224 - 22s - loss: 0.2220 - accuracy: 0.9142 - val_loss: 0.3076 - val_accuracy: 0.8843 - 22s/epoch - 18ms/step\n",
      "Epoch 33/250\n",
      "1224/1224 - 25s - loss: 0.2253 - accuracy: 0.9105 - val_loss: 0.3188 - val_accuracy: 0.8727 - 25s/epoch - 21ms/step\n",
      "Epoch 34/250\n",
      "1224/1224 - 20s - loss: 0.2226 - accuracy: 0.9089 - val_loss: 0.3145 - val_accuracy: 0.8738 - 20s/epoch - 16ms/step\n",
      "Epoch 35/250\n",
      "1224/1224 - 18s - loss: 0.2277 - accuracy: 0.9070 - val_loss: 0.3131 - val_accuracy: 0.8796 - 18s/epoch - 14ms/step\n",
      "Epoch 36/250\n",
      "1224/1224 - 19s - loss: 0.2264 - accuracy: 0.9087 - val_loss: 0.3073 - val_accuracy: 0.8819 - 19s/epoch - 15ms/step\n",
      "Epoch 37/250\n",
      "1224/1224 - 18s - loss: 0.2279 - accuracy: 0.9093 - val_loss: 0.3118 - val_accuracy: 0.8843 - 18s/epoch - 15ms/step\n",
      "Epoch 38/250\n",
      "1224/1224 - 18s - loss: 0.2196 - accuracy: 0.9081 - val_loss: 0.3126 - val_accuracy: 0.8843 - 18s/epoch - 14ms/step\n",
      "Epoch 39/250\n",
      "1224/1224 - 18s - loss: 0.2191 - accuracy: 0.9095 - val_loss: 0.3137 - val_accuracy: 0.8843 - 18s/epoch - 15ms/step\n",
      "Epoch 40/250\n",
      "1224/1224 - 19s - loss: 0.2228 - accuracy: 0.9036 - val_loss: 0.3146 - val_accuracy: 0.8808 - 19s/epoch - 15ms/step\n",
      "Epoch 41/250\n",
      "1224/1224 - 17s - loss: 0.2190 - accuracy: 0.9146 - val_loss: 0.3096 - val_accuracy: 0.8819 - 17s/epoch - 14ms/step\n",
      "Epoch 42/250\n",
      "1224/1224 - 17s - loss: 0.2202 - accuracy: 0.9152 - val_loss: 0.3196 - val_accuracy: 0.8785 - 17s/epoch - 14ms/step\n",
      "Epoch 43/250\n",
      "1224/1224 - 18s - loss: 0.2124 - accuracy: 0.9162 - val_loss: 0.3098 - val_accuracy: 0.8796 - 18s/epoch - 15ms/step\n",
      "Epoch 44/250\n",
      "1224/1224 - 19s - loss: 0.2122 - accuracy: 0.9156 - val_loss: 0.3169 - val_accuracy: 0.8773 - 19s/epoch - 15ms/step\n",
      "Epoch 45/250\n",
      "1224/1224 - 18s - loss: 0.2072 - accuracy: 0.9172 - val_loss: 0.3210 - val_accuracy: 0.8750 - 18s/epoch - 15ms/step\n",
      "Epoch 46/250\n",
      "1224/1224 - 18s - loss: 0.2075 - accuracy: 0.9162 - val_loss: 0.3162 - val_accuracy: 0.8750 - 18s/epoch - 15ms/step\n",
      "Epoch 47/250\n",
      "1224/1224 - 17s - loss: 0.2064 - accuracy: 0.9174 - val_loss: 0.3151 - val_accuracy: 0.8773 - 17s/epoch - 14ms/step\n",
      "Epoch 48/250\n",
      "1224/1224 - 17s - loss: 0.2130 - accuracy: 0.9146 - val_loss: 0.3111 - val_accuracy: 0.8762 - 17s/epoch - 14ms/step\n",
      "Epoch 49/250\n",
      "1224/1224 - 17s - loss: 0.2036 - accuracy: 0.9197 - val_loss: 0.3112 - val_accuracy: 0.8750 - 17s/epoch - 14ms/step\n",
      "Epoch 50/250\n",
      "1224/1224 - 17s - loss: 0.2023 - accuracy: 0.9162 - val_loss: 0.3164 - val_accuracy: 0.8785 - 17s/epoch - 14ms/step\n",
      "Epoch 51/250\n",
      "1224/1224 - 18s - loss: 0.2016 - accuracy: 0.9187 - val_loss: 0.3220 - val_accuracy: 0.8808 - 18s/epoch - 15ms/step\n",
      "Epoch 52/250\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14024/1069306208.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Users\\George\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\George\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\George\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\George\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\George\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\George\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\George\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mD:\\Users\\George\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\George\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,batch_size=4,epochs=250,validation_data=(X_test,y_test),verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c052a3",
   "metadata": {},
   "source": [
    "# ans = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05215e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c47c7998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(864, 20)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "55e3381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = np.round(ans).astype(int).reshape(864)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a96b4fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.49      0.51       432\n",
      "           1       0.53      0.59      0.56       432\n",
      "\n",
      "    accuracy                           0.54       864\n",
      "   macro avg       0.54      0.54      0.54       864\n",
      "weighted avg       0.54      0.54      0.54       864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ans,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "086782dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 2, 'epochs': 250, 'steps': 49}\n"
     ]
    }
   ],
   "source": [
    "print(history.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "85d5227c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b895023d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e43a1fa9",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12176/1716962898.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mzeros\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mones\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "ones = 0\n",
    "zeros = 0\n",
    "for i in range(len(ans)):\n",
    "    if ans[i][0]>=0.5:\n",
    "        ans[i][0] = 1\n",
    "        ones+=1\n",
    "    else:\n",
    "        ans[i][0] = 0\n",
    "        zeros += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a00b1a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "adb418b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "73bdc840",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre=model.predict(test_m)\n",
    "y_pre=np.round(y_pre).astype(int).reshape(1000)\n",
    "sub=pd.DataFrame({'title':test['title'].values.tolist(),'is_fake':y_pre})\n",
    "sub.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3684a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
