{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce8cbf1a",
   "metadata": {},
   "source": [
    "# Kontur-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c3f15d",
   "metadata": {},
   "source": [
    "### Задача: Классификация новостных заголовков на реальные и ложные."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dab0a14",
   "metadata": {},
   "source": [
    "Импортируем необходимые библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "65871a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\George/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "import string\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,LSTM,GRU,Dense,SpatialDropout1D\n",
    "from keras.initializers import Constant\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "pd.options.display.max_colwidth = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e55baee",
   "metadata": {},
   "source": [
    "Посмотрим на данные.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "f8e4863f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>is_fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Москвичу Владимиру Клутину пришёл счёт за вмешательство в американские выборы</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Агент Кокорина назвал езду по встречке житейской историей</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Госдума рассмотрит возможность введения секретных статей Уголовного кодекса</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ФАС заблокировала поставку скоростных трамваев для Москвы</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Против Навального завели дело о недоносительстве на Волкова</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           title  \\\n",
       "0  Москвичу Владимиру Клутину пришёл счёт за вмешательство в американские выборы   \n",
       "1  Агент Кокорина назвал езду по встречке житейской историей                       \n",
       "2  Госдума рассмотрит возможность введения секретных статей Уголовного кодекса     \n",
       "3  ФАС заблокировала поставку скоростных трамваев для Москвы                       \n",
       "4  Против Навального завели дело о недоносительстве на Волкова                     \n",
       "\n",
       "   is_fake  \n",
       "0  1        \n",
       "1  0        \n",
       "2  1        \n",
       "3  0        \n",
       "4  1        "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.tsv',sep = '\\t') # уже размеченные данные\n",
    "test = pd.read_csv('test.tsv',sep = '\\t')   # данные, которые нужно будет разметить\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b876f4a",
   "metadata": {},
   "source": [
    "1 - фейковая новость  \n",
    "0 - реальная новость"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2409b04",
   "metadata": {},
   "source": [
    "Посмотрим на накоторые настоящие новостные заголовки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "bc204d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>is_fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Агент Кокорина назвал езду по встречке житейской историей</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ФАС заблокировала поставку скоростных трамваев для Москвы</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Россияне обхитрили рост цен</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Звезда «Ворониных» раскрыл подробности о своем состоянии</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Microsoft объявила дату выхода очков дополненной реальности Hololens</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Топилин провозгласил окончание зарплатного кризиса в России</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Режиссера Алексея Германа наградили орденом</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Энтони Андерсон стал молодым папашей</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Ubisoft анонсировала новую часть игры Ghost Recon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>На Байконуре сломали малайзийский спутник</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   title  \\\n",
       "1   Агент Кокорина назвал езду по встречке житейской историей              \n",
       "3   ФАС заблокировала поставку скоростных трамваев для Москвы              \n",
       "7   Россияне обхитрили рост цен                                            \n",
       "8   Звезда «Ворониных» раскрыл подробности о своем состоянии               \n",
       "9   Microsoft объявила дату выхода очков дополненной реальности Hololens   \n",
       "13  Топилин провозгласил окончание зарплатного кризиса в России            \n",
       "14  Режиссера Алексея Германа наградили орденом                            \n",
       "18  Энтони Андерсон стал молодым папашей                                   \n",
       "20  Ubisoft анонсировала новую часть игры Ghost Recon                      \n",
       "21  На Байконуре сломали малайзийский спутник                              \n",
       "\n",
       "    is_fake  \n",
       "1   0        \n",
       "3   0        \n",
       "7   0        \n",
       "8   0        \n",
       "9   0        \n",
       "13  0        \n",
       "14  0        \n",
       "18  0        \n",
       "20  0        \n",
       "21  0        "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.is_fake == 0].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2641de96",
   "metadata": {},
   "source": [
    "Теперь на фейковые."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "1fe7c9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>is_fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Москвичу Владимиру Клутину пришёл счёт за вмешательство в американские выборы</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Госдума рассмотрит возможность введения секретных статей Уголовного кодекса</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Против Навального завели дело о недоносительстве на Волкова</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Российским студентам запретят учиться за рубежом</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Путин пишет книгу об истории Украины</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Марат Хуснуллин призвал прописать в законе понятие многонационального дома</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Для проведения профилактических работ с 15 по 19 сентября в России отключат интернет</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>В России введут обязательный техосмотр садового инвентаря</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Олаф Шольц: «Дед рассказывал, какие вкусные на Украине куры, молоко и яйца»</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Беглов: «Петербург был основан до нашей эры, он на полторы тысячи лет старше Москвы»</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                   title  \\\n",
       "0   Москвичу Владимиру Клутину пришёл счёт за вмешательство в американские выборы          \n",
       "2   Госдума рассмотрит возможность введения секретных статей Уголовного кодекса            \n",
       "4   Против Навального завели дело о недоносительстве на Волкова                            \n",
       "5   Российским студентам запретят учиться за рубежом                                       \n",
       "6   Путин пишет книгу об истории Украины                                                   \n",
       "10  Марат Хуснуллин призвал прописать в законе понятие многонационального дома             \n",
       "11  Для проведения профилактических работ с 15 по 19 сентября в России отключат интернет   \n",
       "12  В России введут обязательный техосмотр садового инвентаря                              \n",
       "15  Олаф Шольц: «Дед рассказывал, какие вкусные на Украине куры, молоко и яйца»            \n",
       "16  Беглов: «Петербург был основан до нашей эры, он на полторы тысячи лет старше Москвы»   \n",
       "\n",
       "    is_fake  \n",
       "0   1        \n",
       "2   1        \n",
       "4   1        \n",
       "5   1        \n",
       "6   1        \n",
       "10  1        \n",
       "11  1        \n",
       "12  1        \n",
       "15  1        \n",
       "16  1        "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.is_fake == 1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "53657947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5758, 2)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "953e5e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904932b1",
   "metadata": {},
   "source": [
    "Посмотрим на количество примеров класса 0 и 1 в данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "40ef8900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2879\n",
       "0    2879\n",
       "Name: is_fake, dtype: int64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.is_fake.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1da9ea",
   "metadata": {},
   "source": [
    "Для дальнейшего анализа объеденим train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "305dea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76639bc0",
   "metadata": {},
   "source": [
    "## Предобработка  \n",
    "### Предобработка будет содержать следующие пункты:  \n",
    "1) Приведение текста к нижнему регистру  \n",
    "2) Удаление пунктуации  \n",
    "3) Удаление стоп-слов  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73db36c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "8b20ac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    \"\"\"data должен иметь тип  pandas.core.frame.DataFrame\"\"\"\n",
    "    # приведение к нижнему регистру\n",
    "    \n",
    "    \n",
    "    # удаление пунктуации\n",
    "    \n",
    "    \n",
    "    # удаление стоп-слов\n",
    "    \n",
    "    \n",
    "    # попытка заменить незнакомые слова\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91051e01",
   "metadata": {},
   "source": [
    "Посмотрим какие стоп-слова встречаются в данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c650317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corpus():\n",
    "    \"\"\"Функция, которая создает массив всех слов в датафрейме\"\"\"\n",
    "    corpus=[]\n",
    "    for x in df['title'].str.split():\n",
    "        for i in x:\n",
    "            corpus.append(i)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "bafba0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = create_corpus()\n",
    "dic = defaultdict(int)\n",
    "\n",
    "for word in corpus:\n",
    "    if word in russian_stopwords:\n",
    "        dic[word]+=1\n",
    "        \n",
    "top=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:30] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "51829312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y=zip(*top)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(x, y)\n",
    "\n",
    "fig.set_figwidth(17)    #  ширина Figure\n",
    "fig.set_figheight(6)    #  высота Figure\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d498bcd",
   "metadata": {},
   "source": [
    "Посмотрим какие знаки пунктуации содержатся в данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "fe767595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "corpus=create_corpus()\n",
    "\n",
    "dic=defaultdict(int)\n",
    "special = string.punctuation + \"»\" + '«'+ \"°\"\n",
    "for i in range(len(corpus)):\n",
    "    if corpus[i] in special:\n",
    "        dic[corpus[i]]+=1\n",
    "    for punkt in special:\n",
    "        if punkt in corpus[i]:\n",
    "            dic[punkt]+=1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "66f99016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 21 artists>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top=sorted(dic.items(), key=lambda x:x[1],reverse=True)\n",
    "x,y=zip(*top)\n",
    "plt.bar(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "2d8c90ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "88676984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(line):\n",
    "    for p in string.punctuation:\n",
    "        if p in line:\n",
    "            if p == '-':\n",
    "                line = line.replace(p, ' ')\n",
    "            else:\n",
    "                line = line.replace(p, '')\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "38cd5243",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title']=df['title'].apply(lambda x : remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d66f516f-29bb-43bb-88bc-ff1f9db6a136",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title']=df['title'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "b4015221-c883-4984-af5e-a9e7c6d8fc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>is_fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>москвичу владимиру клутину пришёл счёт за вмешательство в американские выборы</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>агент кокорина назвал езду по встречке житейской историей</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>госдума рассмотрит возможность введения секретных статей уголовного кодекса</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>фас заблокировала поставку скоростных трамваев для москвы</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>против навального завели дело о недоносительстве на волкова</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>российским студентам запретят учиться за рубежом</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>путин пишет книгу об истории украины</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>россияне обхитрили рост цен</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>звезда «ворониных» раскрыл подробности о своем состоянии</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>microsoft объявила дату выхода очков дополненной реальности hololens</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           title  \\\n",
       "0  москвичу владимиру клутину пришёл счёт за вмешательство в американские выборы   \n",
       "1  агент кокорина назвал езду по встречке житейской историей                       \n",
       "2  госдума рассмотрит возможность введения секретных статей уголовного кодекса     \n",
       "3  фас заблокировала поставку скоростных трамваев для москвы                       \n",
       "4  против навального завели дело о недоносительстве на волкова                     \n",
       "5  российским студентам запретят учиться за рубежом                                \n",
       "6  путин пишет книгу об истории украины                                            \n",
       "7  россияне обхитрили рост цен                                                     \n",
       "8  звезда «ворониных» раскрыл подробности о своем состоянии                        \n",
       "9  microsoft объявила дату выхода очков дополненной реальности hololens            \n",
       "\n",
       "   is_fake  \n",
       "0  1        \n",
       "1  0        \n",
       "2  1        \n",
       "3  0        \n",
       "4  1        \n",
       "5  1        \n",
       "6  1        \n",
       "7  0        \n",
       "8  0        \n",
       "9  0        "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ddca237b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corpus(df):\n",
    "    corpus=[]\n",
    "    for train in tqdm(df['title']):\n",
    "        words=[word.lower() for word in word_tokenize(train) if((word.isalpha()==1) & (word not in russian_stopwords) & (len(word)>3))]\n",
    "        corpus.append(words)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "18306317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6758/6758 [00:01<00:00, 4709.49it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus=create_corpus(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "f0a6717d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx = 0\n",
    "for i in range(len(corpus)):\n",
    "    if len(corpus[i])>mx:\n",
    "        mx = len(corpus[i])\n",
    "mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "72d1135d-696f-40e0-8356-1d6787b3668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "    \n",
    "    PER,\n",
    "    NamesExtractor,\n",
    "\n",
    "    Doc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d29ced11",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = NewsEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0966b1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество знакомых слов:  43867\n",
      "Количество незнакомых слов:  1707\n",
      "Количество слов, которые стали знакомыми после удаления 1-2 последних букв:  422\n",
      "Итоговое кол-во незнакомых слов:  1285\n"
     ]
    }
   ],
   "source": [
    "known = 0\n",
    "unknown = 0\n",
    "unknown_became_known = 0\n",
    "corpus_known = []\n",
    "corpus_unknown = []\n",
    "for i in range(len(corpus)):\n",
    "    for j in range(len(corpus[i])):\n",
    "        if corpus[i][j] in emb:\n",
    "            known +=1\n",
    "            corpus_known.append(corpus[i][j])\n",
    "        else:\n",
    "            unknown +=1\n",
    "            if corpus[i][j][0:-1:1] in emb:\n",
    "                unknown_became_known += 1\n",
    "                corpus_known.append(corpus[i][j][0:-1:1])\n",
    "            elif corpus[i][j][0:-2:1] in emb:\n",
    "                unknown_became_known += 1\n",
    "                corpus_known.append(corpus[i][j][0:-2:1])\n",
    "            else:\n",
    "                corpus_unknown.append(corpus[i][j])\n",
    "print(\"Количество знакомых слов: \",known)\n",
    "print(\"Количество незнакомых слов: \",unknown)\n",
    "print(\"Количество слов, которые стали знакомыми после удаления 1-2 последних букв: \", unknown_became_known)\n",
    "print(\"Итоговое кол-во незнакомых слов: \", unknown - unknown_became_known )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "15ea9078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#теперь попробуем поставить слова в начальную форму используя наташку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e189b7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "syntax_parser = NewsSyntaxParser(emb)\n",
    "ner_tagger = NewsNERTagger(emb)\n",
    "names_extractor = NamesExtractor(morph_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "781ad571",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = np.arange(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e53ef118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>is_fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>москвичу владимиру клутину пришёл счёт за вмеш...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>агент кокорина назвал езду по встречке житейск...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>госдума рассмотрит возможность введения секрет...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>фас заблокировала поставку скоростных трамваев...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>против навального завели дело о недоносительст...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6753</th>\n",
       "      <td>прокуратура заподозрила явлинского в авторитар...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6754</th>\n",
       "      <td>в день победы стратегические ракетоносцы ту 16...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6755</th>\n",
       "      <td>ск возбудил дело против авиакомпании «победа» ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6756</th>\n",
       "      <td>криптомонетный двор туркменистана выпустил юби...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6757</th>\n",
       "      <td>deutsche bahn заплатит рекордный штраф за чтен...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6758 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  is_fake\n",
       "0     москвичу владимиру клутину пришёл счёт за вмеш...        1\n",
       "1     агент кокорина назвал езду по встречке житейск...        0\n",
       "2     госдума рассмотрит возможность введения секрет...        1\n",
       "3     фас заблокировала поставку скоростных трамваев...        0\n",
       "4     против навального завели дело о недоносительст...        1\n",
       "...                                                 ...      ...\n",
       "6753  прокуратура заподозрила явлинского в авторитар...        0\n",
       "6754  в день победы стратегические ракетоносцы ту 16...        0\n",
       "6755  ск возбудил дело против авиакомпании «победа» ...        0\n",
       "6756  криптомонетный двор туркменистана выпустил юби...        0\n",
       "6757  deutsche bahn заплатит рекордный штраф за чтен...        0\n",
       "\n",
       "[6758 rows x 2 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2f7db188",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(corpus_unknown)):\n",
    "    corpus_unknown[i] = Doc(corpus_unknown[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8c6c4019",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_lemms = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "93ad51ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(corpus_unknown)):\n",
    "    corpus_unknown[i].segment(segmenter)\n",
    "    corpus_unknown[i].tag_morph(morph_tagger)\n",
    "    corpus_unknown[i].tokens[0].lemmatize(morph_vocab)\n",
    "    corpus_lemms.append(corpus_unknown[i].tokens[0].lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "07594bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "uncnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ace2632b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(corpus_lemms)):\n",
    "    if corpus_lemms[i] in emb:\n",
    "        cnt +=1\n",
    "        corpus_known.append(corpus_lemms[i])\n",
    "    elif corpus_lemms[i][0:-1:1] in emb:\n",
    "        cnt +=1\n",
    "        corpus_known.append(corpus_lemms[i][0:-1:1])\n",
    "    elif corpus_lemms[i][0:-2:1] in emb:\n",
    "        cnt +=1\n",
    "        corpus_known.append(corpus_lemms[i][0:-2:1])\n",
    "    else:\n",
    "        uncnt += 1\n",
    "\n",
    "print(cnt)\n",
    "# 349 слов изучено"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4d60f79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44638"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9b989a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18806"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(corpus_known))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d63e643b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'бузова' in emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "eafd9e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN=20\n",
    "tokenizer_obj=Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(corpus)\n",
    "sequences=tokenizer_obj.texts_to_sequences(corpus)\n",
    "\n",
    "tweet_pad=pad_sequences(sequences,maxlen=MAX_LEN,truncating='post',padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d8a4ed10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6801,  1816,  6802, ...,     0,     0,     0],\n",
       "       [ 2505,  6805,    34, ...,     0,     0,     0],\n",
       "       [   74,  1082,   876, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [ 2403,    95,    11, ...,     0,     0,     0],\n",
       "       [19783, 19784,  2323, ...,     0,     0,     0],\n",
       "       [ 3498, 19786,  1117, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bf789394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 19787\n"
     ]
    }
   ],
   "source": [
    "word_index=tokenizer_obj.word_index\n",
    "print('Number of unique words:',len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8071eb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19787/19787 [00:01<00:00, 12925.02it/s]\n"
     ]
    }
   ],
   "source": [
    "num_words=len(word_index)+1\n",
    "embedding_matrix=np.zeros((num_words,300))\n",
    "\n",
    "for word,i in tqdm(word_index.items()):\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    \n",
    "    if word in emb:\n",
    "        embedding_matrix[i]=emb[word]\n",
    "    elif word[0:-1:1] in emb:\n",
    "        embedding_matrix[i] = emb[word[0:-1:1]]\n",
    "    elif word[0:-2:1] in emb:\n",
    "        embedding_matrix[i] = emb[word[0:-2:1]]\n",
    "    else:\n",
    "        word = Doc(word)\n",
    "        word.segment(segmenter)\n",
    "        word.tag_morph(morph_tagger)\n",
    "        word.tokens[0].lemmatize(morph_vocab)\n",
    "        if word.tokens[0].lemma in emb:\n",
    "            embedding_matrix[i] = emb[word.tokens[0].lemma]\n",
    "        elif word.tokens[0].lemma[0:-1:1] in emb:\n",
    "            embedding_matrix[i] = emb[word.tokens[0].lemma[0:-1:1]]\n",
    "        elif word.tokens[0].lemma[0:-2:1] in emb:\n",
    "            embedding_matrix[i] = emb[word.tokens[0].lemma[0:-2:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "668b41e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "\n",
    "embedding=Embedding(num_words,300,embeddings_initializer=Constant(embedding_matrix),\n",
    "                   input_length=MAX_LEN,trainable=False)\n",
    "\n",
    "model.add(embedding)\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(64 , dropout=0.2, recurrent_dropout=0.2,kernel_initializer='glorot_uniform'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "optimzer=Adam(learning_rate=1e-5)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimzer,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bc676bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 20, 300)           5936400   \n",
      "                                                                 \n",
      " spatial_dropout1d_8 (Spatia  (None, 20, 300)          0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 64)                93440     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,029,905\n",
      "Trainable params: 93,505\n",
      "Non-trainable params: 5,936,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f8d22d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_m =tweet_pad[:train.shape[0]]\n",
    "test_m =tweet_pad[train.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c6cb18c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train (4894, 20)\n",
      "Shape of Validation  (864, 20)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(train_m,train['is_fake'].values,test_size=0.15)\n",
    "print('Shape of train',X_train.shape)\n",
    "print(\"Shape of Validation \",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "07ec4a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "98/98 - 7s - loss: 0.6927 - accuracy: 0.4990 - val_loss: 0.6915 - val_accuracy: 0.5475 - 7s/epoch - 71ms/step\n",
      "Epoch 2/50\n",
      "98/98 - 3s - loss: 0.6914 - accuracy: 0.5513 - val_loss: 0.6899 - val_accuracy: 0.6100 - 3s/epoch - 27ms/step\n",
      "Epoch 3/50\n",
      "98/98 - 3s - loss: 0.6901 - accuracy: 0.5770 - val_loss: 0.6880 - val_accuracy: 0.6528 - 3s/epoch - 27ms/step\n",
      "Epoch 4/50\n",
      "98/98 - 3s - loss: 0.6882 - accuracy: 0.6212 - val_loss: 0.6855 - val_accuracy: 0.6759 - 3s/epoch - 28ms/step\n",
      "Epoch 5/50\n",
      "98/98 - 3s - loss: 0.6859 - accuracy: 0.6430 - val_loss: 0.6819 - val_accuracy: 0.6944 - 3s/epoch - 32ms/step\n",
      "Epoch 6/50\n",
      "98/98 - 3s - loss: 0.6825 - accuracy: 0.6571 - val_loss: 0.6768 - val_accuracy: 0.7083 - 3s/epoch - 31ms/step\n",
      "Epoch 7/50\n",
      "98/98 - 10s - loss: 0.6781 - accuracy: 0.6676 - val_loss: 0.6689 - val_accuracy: 0.7234 - 10s/epoch - 99ms/step\n",
      "Epoch 8/50\n",
      "98/98 - 3s - loss: 0.6709 - accuracy: 0.6806 - val_loss: 0.6567 - val_accuracy: 0.7373 - 3s/epoch - 28ms/step\n",
      "Epoch 9/50\n",
      "98/98 - 3s - loss: 0.6593 - accuracy: 0.6908 - val_loss: 0.6375 - val_accuracy: 0.7407 - 3s/epoch - 27ms/step\n",
      "Epoch 10/50\n",
      "98/98 - 3s - loss: 0.6412 - accuracy: 0.6992 - val_loss: 0.6077 - val_accuracy: 0.7442 - 3s/epoch - 27ms/step\n",
      "Epoch 11/50\n",
      "98/98 - 3s - loss: 0.6180 - accuracy: 0.7064 - val_loss: 0.5717 - val_accuracy: 0.7569 - 3s/epoch - 27ms/step\n",
      "Epoch 12/50\n",
      "98/98 - 3s - loss: 0.5868 - accuracy: 0.7264 - val_loss: 0.5332 - val_accuracy: 0.7720 - 3s/epoch - 29ms/step\n",
      "Epoch 13/50\n",
      "98/98 - 3s - loss: 0.5608 - accuracy: 0.7378 - val_loss: 0.5027 - val_accuracy: 0.7743 - 3s/epoch - 31ms/step\n",
      "Epoch 14/50\n",
      "98/98 - 3s - loss: 0.5370 - accuracy: 0.7542 - val_loss: 0.4793 - val_accuracy: 0.7812 - 3s/epoch - 32ms/step\n",
      "Epoch 15/50\n",
      "98/98 - 3s - loss: 0.5235 - accuracy: 0.7562 - val_loss: 0.4632 - val_accuracy: 0.7917 - 3s/epoch - 31ms/step\n",
      "Epoch 16/50\n",
      "98/98 - 3s - loss: 0.5055 - accuracy: 0.7722 - val_loss: 0.4513 - val_accuracy: 0.7975 - 3s/epoch - 29ms/step\n",
      "Epoch 17/50\n",
      "98/98 - 3s - loss: 0.4988 - accuracy: 0.7675 - val_loss: 0.4429 - val_accuracy: 0.7963 - 3s/epoch - 29ms/step\n",
      "Epoch 18/50\n",
      "98/98 - 3s - loss: 0.4893 - accuracy: 0.7636 - val_loss: 0.4373 - val_accuracy: 0.7986 - 3s/epoch - 32ms/step\n",
      "Epoch 19/50\n",
      "98/98 - 3s - loss: 0.4815 - accuracy: 0.7722 - val_loss: 0.4331 - val_accuracy: 0.8009 - 3s/epoch - 32ms/step\n",
      "Epoch 20/50\n",
      "98/98 - 3s - loss: 0.4761 - accuracy: 0.7767 - val_loss: 0.4295 - val_accuracy: 0.8044 - 3s/epoch - 32ms/step\n",
      "Epoch 21/50\n",
      "98/98 - 3s - loss: 0.4722 - accuracy: 0.7746 - val_loss: 0.4269 - val_accuracy: 0.8009 - 3s/epoch - 32ms/step\n",
      "Epoch 22/50\n",
      "98/98 - 3s - loss: 0.4672 - accuracy: 0.7826 - val_loss: 0.4254 - val_accuracy: 0.7998 - 3s/epoch - 31ms/step\n",
      "Epoch 23/50\n",
      "98/98 - 3s - loss: 0.4649 - accuracy: 0.7818 - val_loss: 0.4231 - val_accuracy: 0.8032 - 3s/epoch - 31ms/step\n",
      "Epoch 24/50\n",
      "98/98 - 3s - loss: 0.4606 - accuracy: 0.7840 - val_loss: 0.4217 - val_accuracy: 0.7998 - 3s/epoch - 33ms/step\n",
      "Epoch 25/50\n",
      "98/98 - 3s - loss: 0.4561 - accuracy: 0.7838 - val_loss: 0.4201 - val_accuracy: 0.8009 - 3s/epoch - 31ms/step\n",
      "Epoch 26/50\n",
      "98/98 - 3s - loss: 0.4581 - accuracy: 0.7897 - val_loss: 0.4186 - val_accuracy: 0.7963 - 3s/epoch - 32ms/step\n",
      "Epoch 27/50\n",
      "98/98 - 3s - loss: 0.4532 - accuracy: 0.7879 - val_loss: 0.4176 - val_accuracy: 0.7986 - 3s/epoch - 31ms/step\n",
      "Epoch 28/50\n",
      "98/98 - 3s - loss: 0.4512 - accuracy: 0.7914 - val_loss: 0.4161 - val_accuracy: 0.7975 - 3s/epoch - 32ms/step\n",
      "Epoch 29/50\n",
      "98/98 - 3s - loss: 0.4498 - accuracy: 0.7906 - val_loss: 0.4160 - val_accuracy: 0.7986 - 3s/epoch - 33ms/step\n",
      "Epoch 30/50\n",
      "98/98 - 3s - loss: 0.4456 - accuracy: 0.7934 - val_loss: 0.4141 - val_accuracy: 0.8009 - 3s/epoch - 31ms/step\n",
      "Epoch 31/50\n",
      "98/98 - 3s - loss: 0.4524 - accuracy: 0.7922 - val_loss: 0.4132 - val_accuracy: 0.7998 - 3s/epoch - 31ms/step\n",
      "Epoch 32/50\n",
      "98/98 - 3s - loss: 0.4428 - accuracy: 0.7971 - val_loss: 0.4116 - val_accuracy: 0.7986 - 3s/epoch - 31ms/step\n",
      "Epoch 33/50\n",
      "98/98 - 4s - loss: 0.4409 - accuracy: 0.7955 - val_loss: 0.4111 - val_accuracy: 0.7975 - 4s/epoch - 37ms/step\n",
      "Epoch 34/50\n",
      "98/98 - 5s - loss: 0.4396 - accuracy: 0.7977 - val_loss: 0.4102 - val_accuracy: 0.8009 - 5s/epoch - 48ms/step\n",
      "Epoch 35/50\n",
      "98/98 - 5s - loss: 0.4379 - accuracy: 0.7973 - val_loss: 0.4091 - val_accuracy: 0.7998 - 5s/epoch - 48ms/step\n",
      "Epoch 36/50\n",
      "98/98 - 4s - loss: 0.4320 - accuracy: 0.8008 - val_loss: 0.4083 - val_accuracy: 0.8009 - 4s/epoch - 42ms/step\n",
      "Epoch 37/50\n",
      "98/98 - 4s - loss: 0.4400 - accuracy: 0.7977 - val_loss: 0.4076 - val_accuracy: 0.8009 - 4s/epoch - 43ms/step\n",
      "Epoch 38/50\n",
      "98/98 - 4s - loss: 0.4339 - accuracy: 0.8038 - val_loss: 0.4067 - val_accuracy: 0.8021 - 4s/epoch - 42ms/step\n",
      "Epoch 39/50\n",
      "98/98 - 4s - loss: 0.4360 - accuracy: 0.7975 - val_loss: 0.4060 - val_accuracy: 0.8021 - 4s/epoch - 42ms/step\n",
      "Epoch 40/50\n",
      "98/98 - 4s - loss: 0.4361 - accuracy: 0.7977 - val_loss: 0.4060 - val_accuracy: 0.8032 - 4s/epoch - 40ms/step\n",
      "Epoch 41/50\n",
      "98/98 - 4s - loss: 0.4331 - accuracy: 0.8016 - val_loss: 0.4057 - val_accuracy: 0.8079 - 4s/epoch - 44ms/step\n",
      "Epoch 42/50\n",
      "98/98 - 4s - loss: 0.4321 - accuracy: 0.8026 - val_loss: 0.4051 - val_accuracy: 0.8079 - 4s/epoch - 44ms/step\n",
      "Epoch 43/50\n",
      "98/98 - 5s - loss: 0.4276 - accuracy: 0.8051 - val_loss: 0.4046 - val_accuracy: 0.8102 - 5s/epoch - 47ms/step\n",
      "Epoch 44/50\n",
      "98/98 - 4s - loss: 0.4308 - accuracy: 0.7985 - val_loss: 0.4033 - val_accuracy: 0.8113 - 4s/epoch - 41ms/step\n",
      "Epoch 45/50\n",
      "98/98 - 4s - loss: 0.4302 - accuracy: 0.8047 - val_loss: 0.4029 - val_accuracy: 0.8113 - 4s/epoch - 41ms/step\n",
      "Epoch 46/50\n",
      "98/98 - 4s - loss: 0.4264 - accuracy: 0.8079 - val_loss: 0.4024 - val_accuracy: 0.8113 - 4s/epoch - 42ms/step\n",
      "Epoch 47/50\n",
      "98/98 - 4s - loss: 0.4267 - accuracy: 0.8055 - val_loss: 0.4014 - val_accuracy: 0.8125 - 4s/epoch - 39ms/step\n",
      "Epoch 48/50\n",
      "98/98 - 4s - loss: 0.4255 - accuracy: 0.8043 - val_loss: 0.4007 - val_accuracy: 0.8125 - 4s/epoch - 36ms/step\n",
      "Epoch 49/50\n",
      "98/98 - 4s - loss: 0.4196 - accuracy: 0.8067 - val_loss: 0.4006 - val_accuracy: 0.8137 - 4s/epoch - 38ms/step\n",
      "Epoch 50/50\n",
      "98/98 - 3s - loss: 0.4255 - accuracy: 0.8045 - val_loss: 0.3997 - val_accuracy: 0.8148 - 3s/epoch - 34ms/step\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,batch_size=50,epochs=50,validation_data=(X_test,y_test),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "cd235b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "49/49 - 3s - loss: 0.4148 - accuracy: 0.8141 - val_loss: 0.3994 - val_accuracy: 0.8148 - 3s/epoch - 54ms/step\n",
      "Epoch 2/50\n",
      "49/49 - 3s - loss: 0.4140 - accuracy: 0.8092 - val_loss: 0.3988 - val_accuracy: 0.8171 - 3s/epoch - 52ms/step\n",
      "Epoch 3/50\n",
      "49/49 - 3s - loss: 0.4207 - accuracy: 0.8075 - val_loss: 0.3986 - val_accuracy: 0.8171 - 3s/epoch - 52ms/step\n",
      "Epoch 4/50\n",
      "49/49 - 3s - loss: 0.4246 - accuracy: 0.8089 - val_loss: 0.3982 - val_accuracy: 0.8171 - 3s/epoch - 55ms/step\n",
      "Epoch 5/50\n",
      "49/49 - 3s - loss: 0.4174 - accuracy: 0.8116 - val_loss: 0.3977 - val_accuracy: 0.8160 - 3s/epoch - 54ms/step\n",
      "Epoch 6/50\n",
      "49/49 - 3s - loss: 0.4140 - accuracy: 0.8112 - val_loss: 0.3972 - val_accuracy: 0.8171 - 3s/epoch - 53ms/step\n",
      "Epoch 7/50\n",
      "49/49 - 3s - loss: 0.4143 - accuracy: 0.8157 - val_loss: 0.3970 - val_accuracy: 0.8171 - 3s/epoch - 51ms/step\n",
      "Epoch 8/50\n",
      "49/49 - 3s - loss: 0.4203 - accuracy: 0.8110 - val_loss: 0.3967 - val_accuracy: 0.8171 - 3s/epoch - 51ms/step\n",
      "Epoch 9/50\n",
      "49/49 - 3s - loss: 0.4204 - accuracy: 0.8098 - val_loss: 0.3963 - val_accuracy: 0.8160 - 3s/epoch - 52ms/step\n",
      "Epoch 10/50\n",
      "49/49 - 3s - loss: 0.4134 - accuracy: 0.8130 - val_loss: 0.3961 - val_accuracy: 0.8148 - 3s/epoch - 53ms/step\n",
      "Epoch 11/50\n",
      "49/49 - 3s - loss: 0.4165 - accuracy: 0.8163 - val_loss: 0.3962 - val_accuracy: 0.8171 - 3s/epoch - 56ms/step\n",
      "Epoch 12/50\n",
      "49/49 - 3s - loss: 0.4165 - accuracy: 0.8163 - val_loss: 0.3957 - val_accuracy: 0.8183 - 3s/epoch - 53ms/step\n",
      "Epoch 13/50\n",
      "49/49 - 3s - loss: 0.4117 - accuracy: 0.8157 - val_loss: 0.3950 - val_accuracy: 0.8148 - 3s/epoch - 54ms/step\n",
      "Epoch 14/50\n",
      "49/49 - 4s - loss: 0.4110 - accuracy: 0.8177 - val_loss: 0.3947 - val_accuracy: 0.8148 - 4s/epoch - 72ms/step\n",
      "Epoch 15/50\n",
      "49/49 - 3s - loss: 0.4101 - accuracy: 0.8132 - val_loss: 0.3945 - val_accuracy: 0.8137 - 3s/epoch - 64ms/step\n",
      "Epoch 16/50\n",
      "49/49 - 3s - loss: 0.4114 - accuracy: 0.8202 - val_loss: 0.3943 - val_accuracy: 0.8137 - 3s/epoch - 63ms/step\n",
      "Epoch 17/50\n",
      "49/49 - 3s - loss: 0.4130 - accuracy: 0.8087 - val_loss: 0.3943 - val_accuracy: 0.8160 - 3s/epoch - 61ms/step\n",
      "Epoch 18/50\n",
      "49/49 - 3s - loss: 0.4159 - accuracy: 0.8147 - val_loss: 0.3941 - val_accuracy: 0.8160 - 3s/epoch - 61ms/step\n",
      "Epoch 19/50\n",
      "49/49 - 3s - loss: 0.4101 - accuracy: 0.8114 - val_loss: 0.3936 - val_accuracy: 0.8171 - 3s/epoch - 58ms/step\n",
      "Epoch 20/50\n",
      "49/49 - 3s - loss: 0.4090 - accuracy: 0.8204 - val_loss: 0.3933 - val_accuracy: 0.8183 - 3s/epoch - 64ms/step\n",
      "Epoch 21/50\n",
      "49/49 - 3s - loss: 0.4198 - accuracy: 0.8128 - val_loss: 0.3930 - val_accuracy: 0.8183 - 3s/epoch - 71ms/step\n",
      "Epoch 22/50\n",
      "49/49 - 3s - loss: 0.4051 - accuracy: 0.8147 - val_loss: 0.3925 - val_accuracy: 0.8183 - 3s/epoch - 64ms/step\n",
      "Epoch 23/50\n",
      "49/49 - 3s - loss: 0.4069 - accuracy: 0.8190 - val_loss: 0.3922 - val_accuracy: 0.8183 - 3s/epoch - 62ms/step\n",
      "Epoch 24/50\n",
      "49/49 - 4s - loss: 0.4053 - accuracy: 0.8155 - val_loss: 0.3920 - val_accuracy: 0.8183 - 4s/epoch - 73ms/step\n",
      "Epoch 25/50\n",
      "49/49 - 3s - loss: 0.4063 - accuracy: 0.8204 - val_loss: 0.3914 - val_accuracy: 0.8183 - 3s/epoch - 62ms/step\n",
      "Epoch 26/50\n",
      "49/49 - 3s - loss: 0.4043 - accuracy: 0.8198 - val_loss: 0.3916 - val_accuracy: 0.8183 - 3s/epoch - 58ms/step\n",
      "Epoch 27/50\n",
      "49/49 - 3s - loss: 0.4093 - accuracy: 0.8165 - val_loss: 0.3919 - val_accuracy: 0.8183 - 3s/epoch - 61ms/step\n",
      "Epoch 28/50\n",
      "49/49 - 3s - loss: 0.4084 - accuracy: 0.8147 - val_loss: 0.3916 - val_accuracy: 0.8183 - 3s/epoch - 55ms/step\n",
      "Epoch 29/50\n",
      "49/49 - 3s - loss: 0.4040 - accuracy: 0.8226 - val_loss: 0.3908 - val_accuracy: 0.8183 - 3s/epoch - 52ms/step\n",
      "Epoch 30/50\n",
      "49/49 - 3s - loss: 0.4044 - accuracy: 0.8143 - val_loss: 0.3901 - val_accuracy: 0.8194 - 3s/epoch - 52ms/step\n",
      "Epoch 31/50\n",
      "49/49 - 3s - loss: 0.4056 - accuracy: 0.8159 - val_loss: 0.3899 - val_accuracy: 0.8183 - 3s/epoch - 53ms/step\n",
      "Epoch 32/50\n",
      "49/49 - 3s - loss: 0.4055 - accuracy: 0.8151 - val_loss: 0.3897 - val_accuracy: 0.8171 - 3s/epoch - 54ms/step\n",
      "Epoch 33/50\n",
      "49/49 - 3s - loss: 0.4022 - accuracy: 0.8190 - val_loss: 0.3898 - val_accuracy: 0.8183 - 3s/epoch - 56ms/step\n",
      "Epoch 34/50\n",
      "49/49 - 3s - loss: 0.4038 - accuracy: 0.8159 - val_loss: 0.3888 - val_accuracy: 0.8171 - 3s/epoch - 53ms/step\n",
      "Epoch 35/50\n",
      "49/49 - 3s - loss: 0.3965 - accuracy: 0.8265 - val_loss: 0.3888 - val_accuracy: 0.8160 - 3s/epoch - 52ms/step\n",
      "Epoch 36/50\n",
      "49/49 - 3s - loss: 0.3976 - accuracy: 0.8208 - val_loss: 0.3884 - val_accuracy: 0.8160 - 3s/epoch - 51ms/step\n",
      "Epoch 37/50\n",
      "49/49 - 3s - loss: 0.4032 - accuracy: 0.8220 - val_loss: 0.3879 - val_accuracy: 0.8183 - 3s/epoch - 53ms/step\n",
      "Epoch 38/50\n",
      "49/49 - 3s - loss: 0.3994 - accuracy: 0.8192 - val_loss: 0.3881 - val_accuracy: 0.8171 - 3s/epoch - 56ms/step\n",
      "Epoch 39/50\n",
      "49/49 - 3s - loss: 0.4032 - accuracy: 0.8171 - val_loss: 0.3881 - val_accuracy: 0.8171 - 3s/epoch - 56ms/step\n",
      "Epoch 40/50\n",
      "49/49 - 3s - loss: 0.3977 - accuracy: 0.8175 - val_loss: 0.3873 - val_accuracy: 0.8171 - 3s/epoch - 55ms/step\n",
      "Epoch 41/50\n",
      "49/49 - 3s - loss: 0.3987 - accuracy: 0.8171 - val_loss: 0.3865 - val_accuracy: 0.8171 - 3s/epoch - 52ms/step\n",
      "Epoch 42/50\n",
      "49/49 - 3s - loss: 0.3936 - accuracy: 0.8230 - val_loss: 0.3863 - val_accuracy: 0.8171 - 3s/epoch - 52ms/step\n",
      "Epoch 43/50\n",
      "49/49 - 3s - loss: 0.3953 - accuracy: 0.8228 - val_loss: 0.3863 - val_accuracy: 0.8171 - 3s/epoch - 51ms/step\n",
      "Epoch 44/50\n",
      "49/49 - 3s - loss: 0.3987 - accuracy: 0.8175 - val_loss: 0.3855 - val_accuracy: 0.8171 - 3s/epoch - 53ms/step\n",
      "Epoch 45/50\n",
      "49/49 - 3s - loss: 0.3958 - accuracy: 0.8212 - val_loss: 0.3853 - val_accuracy: 0.8171 - 3s/epoch - 56ms/step\n",
      "Epoch 46/50\n",
      "49/49 - 3s - loss: 0.3955 - accuracy: 0.8224 - val_loss: 0.3844 - val_accuracy: 0.8183 - 3s/epoch - 52ms/step\n",
      "Epoch 47/50\n",
      "49/49 - 3s - loss: 0.3996 - accuracy: 0.8241 - val_loss: 0.3841 - val_accuracy: 0.8183 - 3s/epoch - 51ms/step\n",
      "Epoch 48/50\n",
      "49/49 - 3s - loss: 0.3937 - accuracy: 0.8210 - val_loss: 0.3841 - val_accuracy: 0.8171 - 3s/epoch - 51ms/step\n",
      "Epoch 49/50\n",
      "49/49 - 3s - loss: 0.3914 - accuracy: 0.8243 - val_loss: 0.3845 - val_accuracy: 0.8218 - 3s/epoch - 53ms/step\n",
      "Epoch 50/50\n",
      "49/49 - 3s - loss: 0.4014 - accuracy: 0.8220 - val_loss: 0.3840 - val_accuracy: 0.8206 - 3s/epoch - 52ms/step\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,batch_size=100,epochs=50,validation_data=(X_test,y_test),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "45f60899",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "49/49 - 2s - loss: 0.3928 - accuracy: 0.8245 - val_loss: 0.3838 - val_accuracy: 0.8206 - 2s/epoch - 48ms/step\n",
      "Epoch 2/250\n",
      "49/49 - 3s - loss: 0.3957 - accuracy: 0.8253 - val_loss: 0.3836 - val_accuracy: 0.8206 - 3s/epoch - 53ms/step\n",
      "Epoch 3/250\n",
      "49/49 - 2s - loss: 0.3914 - accuracy: 0.8235 - val_loss: 0.3835 - val_accuracy: 0.8206 - 2s/epoch - 49ms/step\n",
      "Epoch 4/250\n",
      "49/49 - 2s - loss: 0.3940 - accuracy: 0.8237 - val_loss: 0.3834 - val_accuracy: 0.8206 - 2s/epoch - 47ms/step\n",
      "Epoch 5/250\n",
      "49/49 - 2s - loss: 0.3899 - accuracy: 0.8318 - val_loss: 0.3829 - val_accuracy: 0.8206 - 2s/epoch - 46ms/step\n",
      "Epoch 6/250\n",
      "49/49 - 2s - loss: 0.3843 - accuracy: 0.8288 - val_loss: 0.3826 - val_accuracy: 0.8194 - 2s/epoch - 47ms/step\n",
      "Epoch 7/250\n",
      "49/49 - 2s - loss: 0.3862 - accuracy: 0.8282 - val_loss: 0.3824 - val_accuracy: 0.8194 - 2s/epoch - 46ms/step\n",
      "Epoch 8/250\n",
      "49/49 - 2s - loss: 0.3878 - accuracy: 0.8275 - val_loss: 0.3822 - val_accuracy: 0.8206 - 2s/epoch - 47ms/step\n",
      "Epoch 9/250\n",
      "49/49 - 2s - loss: 0.3927 - accuracy: 0.8284 - val_loss: 0.3820 - val_accuracy: 0.8206 - 2s/epoch - 46ms/step\n",
      "Epoch 10/250\n",
      "49/49 - 2s - loss: 0.3913 - accuracy: 0.8247 - val_loss: 0.3809 - val_accuracy: 0.8206 - 2s/epoch - 45ms/step\n",
      "Epoch 11/250\n",
      "49/49 - 2s - loss: 0.3908 - accuracy: 0.8226 - val_loss: 0.3809 - val_accuracy: 0.8206 - 2s/epoch - 47ms/step\n",
      "Epoch 12/250\n",
      "49/49 - 3s - loss: 0.3844 - accuracy: 0.8288 - val_loss: 0.3803 - val_accuracy: 0.8218 - 3s/epoch - 57ms/step\n",
      "Epoch 13/250\n",
      "49/49 - 3s - loss: 0.3864 - accuracy: 0.8265 - val_loss: 0.3809 - val_accuracy: 0.8218 - 3s/epoch - 57ms/step\n",
      "Epoch 14/250\n",
      "49/49 - 3s - loss: 0.3931 - accuracy: 0.8267 - val_loss: 0.3798 - val_accuracy: 0.8218 - 3s/epoch - 59ms/step\n",
      "Epoch 15/250\n",
      "49/49 - 3s - loss: 0.3847 - accuracy: 0.8253 - val_loss: 0.3795 - val_accuracy: 0.8229 - 3s/epoch - 64ms/step\n",
      "Epoch 16/250\n",
      "49/49 - 3s - loss: 0.3921 - accuracy: 0.8263 - val_loss: 0.3787 - val_accuracy: 0.8229 - 3s/epoch - 65ms/step\n",
      "Epoch 17/250\n",
      "49/49 - 3s - loss: 0.3787 - accuracy: 0.8327 - val_loss: 0.3787 - val_accuracy: 0.8229 - 3s/epoch - 58ms/step\n",
      "Epoch 18/250\n",
      "49/49 - 3s - loss: 0.3792 - accuracy: 0.8341 - val_loss: 0.3787 - val_accuracy: 0.8241 - 3s/epoch - 56ms/step\n",
      "Epoch 19/250\n",
      "49/49 - 3s - loss: 0.3857 - accuracy: 0.8269 - val_loss: 0.3780 - val_accuracy: 0.8241 - 3s/epoch - 56ms/step\n",
      "Epoch 20/250\n",
      "49/49 - 3s - loss: 0.3834 - accuracy: 0.8312 - val_loss: 0.3782 - val_accuracy: 0.8241 - 3s/epoch - 59ms/step\n",
      "Epoch 21/250\n",
      "49/49 - 3s - loss: 0.3814 - accuracy: 0.8292 - val_loss: 0.3781 - val_accuracy: 0.8241 - 3s/epoch - 62ms/step\n",
      "Epoch 22/250\n",
      "49/49 - 3s - loss: 0.3833 - accuracy: 0.8306 - val_loss: 0.3782 - val_accuracy: 0.8229 - 3s/epoch - 57ms/step\n",
      "Epoch 23/250\n",
      "49/49 - 3s - loss: 0.3771 - accuracy: 0.8351 - val_loss: 0.3777 - val_accuracy: 0.8241 - 3s/epoch - 56ms/step\n",
      "Epoch 24/250\n",
      "49/49 - 3s - loss: 0.3857 - accuracy: 0.8259 - val_loss: 0.3769 - val_accuracy: 0.8241 - 3s/epoch - 54ms/step\n",
      "Epoch 25/250\n",
      "49/49 - 3s - loss: 0.3745 - accuracy: 0.8318 - val_loss: 0.3771 - val_accuracy: 0.8241 - 3s/epoch - 59ms/step\n",
      "Epoch 26/250\n",
      "49/49 - 3s - loss: 0.3789 - accuracy: 0.8337 - val_loss: 0.3762 - val_accuracy: 0.8241 - 3s/epoch - 57ms/step\n",
      "Epoch 27/250\n",
      "49/49 - 3s - loss: 0.3877 - accuracy: 0.8261 - val_loss: 0.3759 - val_accuracy: 0.8241 - 3s/epoch - 53ms/step\n",
      "Epoch 28/250\n",
      "49/49 - 2s - loss: 0.3764 - accuracy: 0.8335 - val_loss: 0.3760 - val_accuracy: 0.8252 - 2s/epoch - 47ms/step\n",
      "Epoch 29/250\n",
      "49/49 - 2s - loss: 0.3833 - accuracy: 0.8302 - val_loss: 0.3758 - val_accuracy: 0.8252 - 2s/epoch - 47ms/step\n",
      "Epoch 30/250\n",
      "49/49 - 2s - loss: 0.3801 - accuracy: 0.8318 - val_loss: 0.3760 - val_accuracy: 0.8264 - 2s/epoch - 47ms/step\n",
      "Epoch 31/250\n",
      "49/49 - 2s - loss: 0.3869 - accuracy: 0.8288 - val_loss: 0.3747 - val_accuracy: 0.8252 - 2s/epoch - 47ms/step\n",
      "Epoch 32/250\n",
      "49/49 - 2s - loss: 0.3711 - accuracy: 0.8327 - val_loss: 0.3745 - val_accuracy: 0.8252 - 2s/epoch - 47ms/step\n",
      "Epoch 33/250\n",
      "49/49 - 2s - loss: 0.3714 - accuracy: 0.8371 - val_loss: 0.3745 - val_accuracy: 0.8241 - 2s/epoch - 47ms/step\n",
      "Epoch 34/250\n",
      "49/49 - 2s - loss: 0.3707 - accuracy: 0.8378 - val_loss: 0.3754 - val_accuracy: 0.8252 - 2s/epoch - 48ms/step\n",
      "Epoch 35/250\n",
      "49/49 - 2s - loss: 0.3677 - accuracy: 0.8369 - val_loss: 0.3749 - val_accuracy: 0.8252 - 2s/epoch - 49ms/step\n",
      "Epoch 36/250\n",
      "49/49 - 2s - loss: 0.3754 - accuracy: 0.8345 - val_loss: 0.3742 - val_accuracy: 0.8264 - 2s/epoch - 49ms/step\n",
      "Epoch 37/250\n",
      "49/49 - 2s - loss: 0.3763 - accuracy: 0.8353 - val_loss: 0.3740 - val_accuracy: 0.8264 - 2s/epoch - 49ms/step\n",
      "Epoch 38/250\n",
      "49/49 - 2s - loss: 0.3767 - accuracy: 0.8357 - val_loss: 0.3738 - val_accuracy: 0.8264 - 2s/epoch - 48ms/step\n",
      "Epoch 39/250\n",
      "49/49 - 2s - loss: 0.3751 - accuracy: 0.8363 - val_loss: 0.3735 - val_accuracy: 0.8264 - 2s/epoch - 50ms/step\n",
      "Epoch 40/250\n",
      "49/49 - 3s - loss: 0.3726 - accuracy: 0.8329 - val_loss: 0.3732 - val_accuracy: 0.8264 - 3s/epoch - 55ms/step\n",
      "Epoch 41/250\n",
      "49/49 - 2s - loss: 0.3693 - accuracy: 0.8351 - val_loss: 0.3723 - val_accuracy: 0.8275 - 2s/epoch - 50ms/step\n",
      "Epoch 42/250\n",
      "49/49 - 3s - loss: 0.3727 - accuracy: 0.8316 - val_loss: 0.3719 - val_accuracy: 0.8275 - 3s/epoch - 60ms/step\n",
      "Epoch 43/250\n",
      "49/49 - 2s - loss: 0.3716 - accuracy: 0.8333 - val_loss: 0.3725 - val_accuracy: 0.8275 - 2s/epoch - 48ms/step\n",
      "Epoch 44/250\n",
      "49/49 - 2s - loss: 0.3687 - accuracy: 0.8402 - val_loss: 0.3720 - val_accuracy: 0.8275 - 2s/epoch - 48ms/step\n",
      "Epoch 45/250\n",
      "49/49 - 2s - loss: 0.3727 - accuracy: 0.8349 - val_loss: 0.3715 - val_accuracy: 0.8287 - 2s/epoch - 48ms/step\n",
      "Epoch 46/250\n",
      "49/49 - 2s - loss: 0.3738 - accuracy: 0.8418 - val_loss: 0.3712 - val_accuracy: 0.8310 - 2s/epoch - 49ms/step\n",
      "Epoch 47/250\n",
      "49/49 - 2s - loss: 0.3728 - accuracy: 0.8351 - val_loss: 0.3715 - val_accuracy: 0.8299 - 2s/epoch - 47ms/step\n",
      "Epoch 48/250\n",
      "49/49 - 3s - loss: 0.3709 - accuracy: 0.8382 - val_loss: 0.3715 - val_accuracy: 0.8299 - 3s/epoch - 61ms/step\n",
      "Epoch 49/250\n",
      "49/49 - 3s - loss: 0.3683 - accuracy: 0.8406 - val_loss: 0.3703 - val_accuracy: 0.8310 - 3s/epoch - 55ms/step\n",
      "Epoch 50/250\n",
      "49/49 - 2s - loss: 0.3690 - accuracy: 0.8380 - val_loss: 0.3697 - val_accuracy: 0.8310 - 2s/epoch - 50ms/step\n",
      "Epoch 51/250\n",
      "49/49 - 2s - loss: 0.3675 - accuracy: 0.8347 - val_loss: 0.3695 - val_accuracy: 0.8310 - 2s/epoch - 49ms/step\n",
      "Epoch 52/250\n",
      "49/49 - 2s - loss: 0.3680 - accuracy: 0.8320 - val_loss: 0.3695 - val_accuracy: 0.8299 - 2s/epoch - 50ms/step\n",
      "Epoch 53/250\n",
      "49/49 - 2s - loss: 0.3693 - accuracy: 0.8369 - val_loss: 0.3699 - val_accuracy: 0.8287 - 2s/epoch - 49ms/step\n",
      "Epoch 54/250\n",
      "49/49 - 3s - loss: 0.3649 - accuracy: 0.8410 - val_loss: 0.3687 - val_accuracy: 0.8310 - 3s/epoch - 53ms/step\n",
      "Epoch 55/250\n",
      "49/49 - 3s - loss: 0.3659 - accuracy: 0.8406 - val_loss: 0.3690 - val_accuracy: 0.8287 - 3s/epoch - 51ms/step\n",
      "Epoch 56/250\n",
      "49/49 - 2s - loss: 0.3569 - accuracy: 0.8435 - val_loss: 0.3688 - val_accuracy: 0.8310 - 2s/epoch - 47ms/step\n",
      "Epoch 57/250\n",
      "49/49 - 2s - loss: 0.3719 - accuracy: 0.8410 - val_loss: 0.3684 - val_accuracy: 0.8310 - 2s/epoch - 48ms/step\n",
      "Epoch 58/250\n",
      "49/49 - 3s - loss: 0.3637 - accuracy: 0.8423 - val_loss: 0.3675 - val_accuracy: 0.8310 - 3s/epoch - 51ms/step\n",
      "Epoch 59/250\n",
      "49/49 - 3s - loss: 0.3755 - accuracy: 0.8316 - val_loss: 0.3677 - val_accuracy: 0.8299 - 3s/epoch - 51ms/step\n",
      "Epoch 60/250\n",
      "49/49 - 3s - loss: 0.3579 - accuracy: 0.8363 - val_loss: 0.3668 - val_accuracy: 0.8310 - 3s/epoch - 52ms/step\n",
      "Epoch 61/250\n",
      "49/49 - 3s - loss: 0.3615 - accuracy: 0.8492 - val_loss: 0.3657 - val_accuracy: 0.8299 - 3s/epoch - 53ms/step\n",
      "Epoch 62/250\n",
      "49/49 - 3s - loss: 0.3574 - accuracy: 0.8445 - val_loss: 0.3674 - val_accuracy: 0.8287 - 3s/epoch - 58ms/step\n",
      "Epoch 63/250\n",
      "49/49 - 3s - loss: 0.3579 - accuracy: 0.8443 - val_loss: 0.3666 - val_accuracy: 0.8299 - 3s/epoch - 57ms/step\n",
      "Epoch 64/250\n",
      "49/49 - 3s - loss: 0.3660 - accuracy: 0.8404 - val_loss: 0.3661 - val_accuracy: 0.8310 - 3s/epoch - 56ms/step\n",
      "Epoch 65/250\n",
      "49/49 - 3s - loss: 0.3642 - accuracy: 0.8359 - val_loss: 0.3655 - val_accuracy: 0.8310 - 3s/epoch - 52ms/step\n",
      "Epoch 66/250\n",
      "49/49 - 3s - loss: 0.3610 - accuracy: 0.8435 - val_loss: 0.3664 - val_accuracy: 0.8310 - 3s/epoch - 56ms/step\n",
      "Epoch 67/250\n",
      "49/49 - 3s - loss: 0.3649 - accuracy: 0.8408 - val_loss: 0.3660 - val_accuracy: 0.8322 - 3s/epoch - 58ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/250\n",
      "49/49 - 3s - loss: 0.3605 - accuracy: 0.8429 - val_loss: 0.3650 - val_accuracy: 0.8322 - 3s/epoch - 51ms/step\n",
      "Epoch 69/250\n",
      "49/49 - 3s - loss: 0.3650 - accuracy: 0.8361 - val_loss: 0.3647 - val_accuracy: 0.8322 - 3s/epoch - 53ms/step\n",
      "Epoch 70/250\n",
      "49/49 - 3s - loss: 0.3584 - accuracy: 0.8470 - val_loss: 0.3634 - val_accuracy: 0.8310 - 3s/epoch - 61ms/step\n",
      "Epoch 71/250\n",
      "49/49 - 3s - loss: 0.3660 - accuracy: 0.8357 - val_loss: 0.3642 - val_accuracy: 0.8310 - 3s/epoch - 59ms/step\n",
      "Epoch 72/250\n",
      "49/49 - 2s - loss: 0.3627 - accuracy: 0.8431 - val_loss: 0.3629 - val_accuracy: 0.8322 - 2s/epoch - 50ms/step\n",
      "Epoch 73/250\n",
      "49/49 - 3s - loss: 0.3605 - accuracy: 0.8374 - val_loss: 0.3632 - val_accuracy: 0.8299 - 3s/epoch - 56ms/step\n",
      "Epoch 74/250\n",
      "49/49 - 3s - loss: 0.3553 - accuracy: 0.8447 - val_loss: 0.3626 - val_accuracy: 0.8299 - 3s/epoch - 62ms/step\n",
      "Epoch 75/250\n",
      "49/49 - 3s - loss: 0.3619 - accuracy: 0.8404 - val_loss: 0.3630 - val_accuracy: 0.8299 - 3s/epoch - 55ms/step\n",
      "Epoch 76/250\n",
      "49/49 - 2s - loss: 0.3671 - accuracy: 0.8355 - val_loss: 0.3632 - val_accuracy: 0.8299 - 2s/epoch - 51ms/step\n",
      "Epoch 77/250\n",
      "49/49 - 2s - loss: 0.3567 - accuracy: 0.8439 - val_loss: 0.3625 - val_accuracy: 0.8310 - 2s/epoch - 50ms/step\n",
      "Epoch 78/250\n",
      "49/49 - 2s - loss: 0.3573 - accuracy: 0.8416 - val_loss: 0.3606 - val_accuracy: 0.8322 - 2s/epoch - 48ms/step\n",
      "Epoch 79/250\n",
      "49/49 - 3s - loss: 0.3630 - accuracy: 0.8396 - val_loss: 0.3611 - val_accuracy: 0.8310 - 3s/epoch - 52ms/step\n",
      "Epoch 80/250\n",
      "49/49 - 2s - loss: 0.3512 - accuracy: 0.8451 - val_loss: 0.3607 - val_accuracy: 0.8310 - 2s/epoch - 49ms/step\n",
      "Epoch 81/250\n",
      "49/49 - 2s - loss: 0.3571 - accuracy: 0.8429 - val_loss: 0.3620 - val_accuracy: 0.8299 - 2s/epoch - 50ms/step\n",
      "Epoch 82/250\n",
      "49/49 - 3s - loss: 0.3561 - accuracy: 0.8474 - val_loss: 0.3615 - val_accuracy: 0.8287 - 3s/epoch - 54ms/step\n",
      "Epoch 83/250\n",
      "49/49 - 3s - loss: 0.3492 - accuracy: 0.8519 - val_loss: 0.3615 - val_accuracy: 0.8310 - 3s/epoch - 55ms/step\n",
      "Epoch 84/250\n",
      "49/49 - 2s - loss: 0.3506 - accuracy: 0.8463 - val_loss: 0.3610 - val_accuracy: 0.8299 - 2s/epoch - 50ms/step\n",
      "Epoch 85/250\n",
      "49/49 - 3s - loss: 0.3574 - accuracy: 0.8468 - val_loss: 0.3601 - val_accuracy: 0.8299 - 3s/epoch - 59ms/step\n",
      "Epoch 86/250\n",
      "49/49 - 2s - loss: 0.3484 - accuracy: 0.8465 - val_loss: 0.3599 - val_accuracy: 0.8287 - 2s/epoch - 51ms/step\n",
      "Epoch 87/250\n",
      "49/49 - 3s - loss: 0.3526 - accuracy: 0.8443 - val_loss: 0.3598 - val_accuracy: 0.8287 - 3s/epoch - 56ms/step\n",
      "Epoch 88/250\n",
      "49/49 - 3s - loss: 0.3507 - accuracy: 0.8498 - val_loss: 0.3600 - val_accuracy: 0.8299 - 3s/epoch - 56ms/step\n",
      "Epoch 89/250\n",
      "49/49 - 3s - loss: 0.3463 - accuracy: 0.8447 - val_loss: 0.3590 - val_accuracy: 0.8299 - 3s/epoch - 57ms/step\n",
      "Epoch 90/250\n",
      "49/49 - 3s - loss: 0.3509 - accuracy: 0.8453 - val_loss: 0.3595 - val_accuracy: 0.8322 - 3s/epoch - 57ms/step\n",
      "Epoch 91/250\n",
      "49/49 - 2s - loss: 0.3516 - accuracy: 0.8461 - val_loss: 0.3590 - val_accuracy: 0.8333 - 2s/epoch - 50ms/step\n",
      "Epoch 92/250\n",
      "49/49 - 3s - loss: 0.3480 - accuracy: 0.8455 - val_loss: 0.3584 - val_accuracy: 0.8333 - 3s/epoch - 53ms/step\n",
      "Epoch 93/250\n",
      "49/49 - 3s - loss: 0.3525 - accuracy: 0.8443 - val_loss: 0.3593 - val_accuracy: 0.8322 - 3s/epoch - 56ms/step\n",
      "Epoch 94/250\n",
      "49/49 - 3s - loss: 0.3539 - accuracy: 0.8486 - val_loss: 0.3578 - val_accuracy: 0.8322 - 3s/epoch - 60ms/step\n",
      "Epoch 95/250\n",
      "49/49 - 3s - loss: 0.3440 - accuracy: 0.8508 - val_loss: 0.3585 - val_accuracy: 0.8333 - 3s/epoch - 62ms/step\n",
      "Epoch 96/250\n",
      "49/49 - 3s - loss: 0.3484 - accuracy: 0.8519 - val_loss: 0.3587 - val_accuracy: 0.8322 - 3s/epoch - 52ms/step\n",
      "Epoch 97/250\n",
      "49/49 - 3s - loss: 0.3493 - accuracy: 0.8465 - val_loss: 0.3593 - val_accuracy: 0.8345 - 3s/epoch - 55ms/step\n",
      "Epoch 98/250\n",
      "49/49 - 3s - loss: 0.3434 - accuracy: 0.8508 - val_loss: 0.3585 - val_accuracy: 0.8345 - 3s/epoch - 64ms/step\n",
      "Epoch 99/250\n",
      "49/49 - 3s - loss: 0.3424 - accuracy: 0.8539 - val_loss: 0.3569 - val_accuracy: 0.8322 - 3s/epoch - 60ms/step\n",
      "Epoch 100/250\n",
      "49/49 - 3s - loss: 0.3492 - accuracy: 0.8463 - val_loss: 0.3572 - val_accuracy: 0.8333 - 3s/epoch - 60ms/step\n",
      "Epoch 101/250\n",
      "49/49 - 3s - loss: 0.3449 - accuracy: 0.8492 - val_loss: 0.3578 - val_accuracy: 0.8333 - 3s/epoch - 57ms/step\n",
      "Epoch 102/250\n",
      "49/49 - 3s - loss: 0.3448 - accuracy: 0.8492 - val_loss: 0.3560 - val_accuracy: 0.8345 - 3s/epoch - 58ms/step\n",
      "Epoch 103/250\n",
      "49/49 - 3s - loss: 0.3490 - accuracy: 0.8476 - val_loss: 0.3562 - val_accuracy: 0.8322 - 3s/epoch - 63ms/step\n",
      "Epoch 104/250\n",
      "49/49 - 3s - loss: 0.3473 - accuracy: 0.8502 - val_loss: 0.3568 - val_accuracy: 0.8322 - 3s/epoch - 56ms/step\n",
      "Epoch 105/250\n",
      "49/49 - 3s - loss: 0.3512 - accuracy: 0.8404 - val_loss: 0.3560 - val_accuracy: 0.8322 - 3s/epoch - 58ms/step\n",
      "Epoch 106/250\n",
      "49/49 - 3s - loss: 0.3375 - accuracy: 0.8527 - val_loss: 0.3554 - val_accuracy: 0.8333 - 3s/epoch - 53ms/step\n",
      "Epoch 107/250\n",
      "49/49 - 3s - loss: 0.3424 - accuracy: 0.8498 - val_loss: 0.3554 - val_accuracy: 0.8322 - 3s/epoch - 53ms/step\n",
      "Epoch 108/250\n",
      "49/49 - 3s - loss: 0.3452 - accuracy: 0.8502 - val_loss: 0.3556 - val_accuracy: 0.8333 - 3s/epoch - 52ms/step\n",
      "Epoch 109/250\n",
      "49/49 - 3s - loss: 0.3433 - accuracy: 0.8494 - val_loss: 0.3560 - val_accuracy: 0.8322 - 3s/epoch - 58ms/step\n",
      "Epoch 110/250\n",
      "49/49 - 3s - loss: 0.3374 - accuracy: 0.8539 - val_loss: 0.3555 - val_accuracy: 0.8322 - 3s/epoch - 55ms/step\n",
      "Epoch 111/250\n",
      "49/49 - 3s - loss: 0.3485 - accuracy: 0.8500 - val_loss: 0.3532 - val_accuracy: 0.8322 - 3s/epoch - 60ms/step\n",
      "Epoch 112/250\n",
      "49/49 - 3s - loss: 0.3433 - accuracy: 0.8496 - val_loss: 0.3543 - val_accuracy: 0.8333 - 3s/epoch - 58ms/step\n",
      "Epoch 113/250\n",
      "49/49 - 3s - loss: 0.3407 - accuracy: 0.8564 - val_loss: 0.3540 - val_accuracy: 0.8333 - 3s/epoch - 52ms/step\n",
      "Epoch 114/250\n",
      "49/49 - 2s - loss: 0.3477 - accuracy: 0.8461 - val_loss: 0.3531 - val_accuracy: 0.8310 - 2s/epoch - 50ms/step\n",
      "Epoch 115/250\n",
      "49/49 - 2s - loss: 0.3450 - accuracy: 0.8500 - val_loss: 0.3533 - val_accuracy: 0.8322 - 2s/epoch - 50ms/step\n",
      "Epoch 116/250\n",
      "49/49 - 3s - loss: 0.3385 - accuracy: 0.8564 - val_loss: 0.3541 - val_accuracy: 0.8356 - 3s/epoch - 51ms/step\n",
      "Epoch 117/250\n",
      "49/49 - 3s - loss: 0.3451 - accuracy: 0.8490 - val_loss: 0.3519 - val_accuracy: 0.8322 - 3s/epoch - 55ms/step\n",
      "Epoch 118/250\n",
      "49/49 - 4s - loss: 0.3363 - accuracy: 0.8537 - val_loss: 0.3527 - val_accuracy: 0.8322 - 4s/epoch - 75ms/step\n",
      "Epoch 119/250\n",
      "49/49 - 3s - loss: 0.3359 - accuracy: 0.8564 - val_loss: 0.3522 - val_accuracy: 0.8322 - 3s/epoch - 63ms/step\n",
      "Epoch 120/250\n",
      "49/49 - 3s - loss: 0.3385 - accuracy: 0.8531 - val_loss: 0.3522 - val_accuracy: 0.8310 - 3s/epoch - 69ms/step\n",
      "Epoch 121/250\n",
      "49/49 - 3s - loss: 0.3392 - accuracy: 0.8508 - val_loss: 0.3532 - val_accuracy: 0.8333 - 3s/epoch - 64ms/step\n",
      "Epoch 122/250\n",
      "49/49 - 3s - loss: 0.3398 - accuracy: 0.8557 - val_loss: 0.3517 - val_accuracy: 0.8322 - 3s/epoch - 65ms/step\n",
      "Epoch 123/250\n",
      "49/49 - 3s - loss: 0.3391 - accuracy: 0.8535 - val_loss: 0.3512 - val_accuracy: 0.8322 - 3s/epoch - 64ms/step\n",
      "Epoch 124/250\n",
      "49/49 - 3s - loss: 0.3373 - accuracy: 0.8555 - val_loss: 0.3511 - val_accuracy: 0.8322 - 3s/epoch - 64ms/step\n",
      "Epoch 125/250\n",
      "49/49 - 3s - loss: 0.3375 - accuracy: 0.8517 - val_loss: 0.3508 - val_accuracy: 0.8345 - 3s/epoch - 60ms/step\n",
      "Epoch 126/250\n",
      "49/49 - 3s - loss: 0.3435 - accuracy: 0.8486 - val_loss: 0.3509 - val_accuracy: 0.8356 - 3s/epoch - 59ms/step\n",
      "Epoch 127/250\n",
      "49/49 - 3s - loss: 0.3373 - accuracy: 0.8557 - val_loss: 0.3519 - val_accuracy: 0.8368 - 3s/epoch - 61ms/step\n",
      "Epoch 128/250\n",
      "49/49 - 3s - loss: 0.3323 - accuracy: 0.8572 - val_loss: 0.3503 - val_accuracy: 0.8368 - 3s/epoch - 64ms/step\n",
      "Epoch 129/250\n",
      "49/49 - 3s - loss: 0.3333 - accuracy: 0.8586 - val_loss: 0.3506 - val_accuracy: 0.8368 - 3s/epoch - 65ms/step\n",
      "Epoch 130/250\n",
      "49/49 - 3s - loss: 0.3381 - accuracy: 0.8535 - val_loss: 0.3497 - val_accuracy: 0.8368 - 3s/epoch - 61ms/step\n",
      "Epoch 131/250\n",
      "49/49 - 3s - loss: 0.3355 - accuracy: 0.8498 - val_loss: 0.3498 - val_accuracy: 0.8380 - 3s/epoch - 59ms/step\n",
      "Epoch 132/250\n",
      "49/49 - 3s - loss: 0.3228 - accuracy: 0.8621 - val_loss: 0.3497 - val_accuracy: 0.8380 - 3s/epoch - 61ms/step\n",
      "Epoch 133/250\n",
      "49/49 - 3s - loss: 0.3290 - accuracy: 0.8553 - val_loss: 0.3499 - val_accuracy: 0.8380 - 3s/epoch - 69ms/step\n",
      "Epoch 134/250\n",
      "49/49 - 3s - loss: 0.3328 - accuracy: 0.8557 - val_loss: 0.3509 - val_accuracy: 0.8391 - 3s/epoch - 69ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/250\n",
      "49/49 - 3s - loss: 0.3289 - accuracy: 0.8582 - val_loss: 0.3506 - val_accuracy: 0.8391 - 3s/epoch - 60ms/step\n",
      "Epoch 136/250\n",
      "49/49 - 3s - loss: 0.3307 - accuracy: 0.8596 - val_loss: 0.3492 - val_accuracy: 0.8368 - 3s/epoch - 60ms/step\n",
      "Epoch 137/250\n",
      "49/49 - 3s - loss: 0.3260 - accuracy: 0.8586 - val_loss: 0.3492 - val_accuracy: 0.8356 - 3s/epoch - 65ms/step\n",
      "Epoch 138/250\n",
      "49/49 - 3s - loss: 0.3349 - accuracy: 0.8551 - val_loss: 0.3476 - val_accuracy: 0.8368 - 3s/epoch - 63ms/step\n",
      "Epoch 139/250\n",
      "49/49 - 3s - loss: 0.3253 - accuracy: 0.8609 - val_loss: 0.3489 - val_accuracy: 0.8380 - 3s/epoch - 67ms/step\n",
      "Epoch 140/250\n",
      "49/49 - 3s - loss: 0.3260 - accuracy: 0.8551 - val_loss: 0.3473 - val_accuracy: 0.8403 - 3s/epoch - 58ms/step\n",
      "Epoch 141/250\n",
      "49/49 - 3s - loss: 0.3313 - accuracy: 0.8580 - val_loss: 0.3481 - val_accuracy: 0.8368 - 3s/epoch - 54ms/step\n",
      "Epoch 142/250\n",
      "49/49 - 3s - loss: 0.3344 - accuracy: 0.8551 - val_loss: 0.3475 - val_accuracy: 0.8380 - 3s/epoch - 58ms/step\n",
      "Epoch 143/250\n",
      "49/49 - 3s - loss: 0.3271 - accuracy: 0.8594 - val_loss: 0.3475 - val_accuracy: 0.8380 - 3s/epoch - 55ms/step\n",
      "Epoch 144/250\n",
      "49/49 - 3s - loss: 0.3306 - accuracy: 0.8539 - val_loss: 0.3472 - val_accuracy: 0.8403 - 3s/epoch - 59ms/step\n",
      "Epoch 145/250\n",
      "49/49 - 3s - loss: 0.3228 - accuracy: 0.8609 - val_loss: 0.3472 - val_accuracy: 0.8414 - 3s/epoch - 56ms/step\n",
      "Epoch 146/250\n",
      "49/49 - 3s - loss: 0.3311 - accuracy: 0.8568 - val_loss: 0.3469 - val_accuracy: 0.8426 - 3s/epoch - 53ms/step\n",
      "Epoch 147/250\n",
      "49/49 - 3s - loss: 0.3313 - accuracy: 0.8572 - val_loss: 0.3466 - val_accuracy: 0.8426 - 3s/epoch - 54ms/step\n",
      "Epoch 148/250\n",
      "49/49 - 3s - loss: 0.3300 - accuracy: 0.8557 - val_loss: 0.3454 - val_accuracy: 0.8438 - 3s/epoch - 55ms/step\n",
      "Epoch 149/250\n",
      "49/49 - 3s - loss: 0.3195 - accuracy: 0.8604 - val_loss: 0.3444 - val_accuracy: 0.8426 - 3s/epoch - 57ms/step\n",
      "Epoch 150/250\n",
      "49/49 - 3s - loss: 0.3215 - accuracy: 0.8609 - val_loss: 0.3445 - val_accuracy: 0.8426 - 3s/epoch - 56ms/step\n",
      "Epoch 151/250\n",
      "49/49 - 3s - loss: 0.3250 - accuracy: 0.8606 - val_loss: 0.3458 - val_accuracy: 0.8449 - 3s/epoch - 58ms/step\n",
      "Epoch 152/250\n",
      "49/49 - 3s - loss: 0.3213 - accuracy: 0.8627 - val_loss: 0.3445 - val_accuracy: 0.8438 - 3s/epoch - 57ms/step\n",
      "Epoch 153/250\n",
      "49/49 - 3s - loss: 0.3288 - accuracy: 0.8555 - val_loss: 0.3445 - val_accuracy: 0.8449 - 3s/epoch - 59ms/step\n",
      "Epoch 154/250\n",
      "49/49 - 3s - loss: 0.3221 - accuracy: 0.8621 - val_loss: 0.3435 - val_accuracy: 0.8449 - 3s/epoch - 55ms/step\n",
      "Epoch 155/250\n",
      "49/49 - 3s - loss: 0.3295 - accuracy: 0.8588 - val_loss: 0.3441 - val_accuracy: 0.8461 - 3s/epoch - 57ms/step\n",
      "Epoch 156/250\n",
      "49/49 - 3s - loss: 0.3200 - accuracy: 0.8609 - val_loss: 0.3433 - val_accuracy: 0.8438 - 3s/epoch - 54ms/step\n",
      "Epoch 157/250\n",
      "49/49 - 3s - loss: 0.3203 - accuracy: 0.8627 - val_loss: 0.3439 - val_accuracy: 0.8461 - 3s/epoch - 54ms/step\n",
      "Epoch 158/250\n",
      "49/49 - 3s - loss: 0.3240 - accuracy: 0.8647 - val_loss: 0.3447 - val_accuracy: 0.8449 - 3s/epoch - 56ms/step\n",
      "Epoch 159/250\n",
      "49/49 - 3s - loss: 0.3171 - accuracy: 0.8660 - val_loss: 0.3429 - val_accuracy: 0.8449 - 3s/epoch - 59ms/step\n",
      "Epoch 160/250\n",
      "49/49 - 4s - loss: 0.3189 - accuracy: 0.8633 - val_loss: 0.3427 - val_accuracy: 0.8461 - 4s/epoch - 77ms/step\n",
      "Epoch 161/250\n",
      "49/49 - 4s - loss: 0.3240 - accuracy: 0.8633 - val_loss: 0.3424 - val_accuracy: 0.8449 - 4s/epoch - 77ms/step\n",
      "Epoch 162/250\n",
      "49/49 - 4s - loss: 0.3263 - accuracy: 0.8576 - val_loss: 0.3430 - val_accuracy: 0.8438 - 4s/epoch - 91ms/step\n",
      "Epoch 163/250\n",
      "49/49 - 4s - loss: 0.3170 - accuracy: 0.8666 - val_loss: 0.3415 - val_accuracy: 0.8461 - 4s/epoch - 81ms/step\n",
      "Epoch 164/250\n",
      "49/49 - 4s - loss: 0.3232 - accuracy: 0.8641 - val_loss: 0.3410 - val_accuracy: 0.8461 - 4s/epoch - 77ms/step\n",
      "Epoch 165/250\n",
      "49/49 - 4s - loss: 0.3147 - accuracy: 0.8678 - val_loss: 0.3406 - val_accuracy: 0.8461 - 4s/epoch - 81ms/step\n",
      "Epoch 166/250\n",
      "49/49 - 3s - loss: 0.3186 - accuracy: 0.8592 - val_loss: 0.3423 - val_accuracy: 0.8472 - 3s/epoch - 61ms/step\n",
      "Epoch 167/250\n",
      "49/49 - 3s - loss: 0.3140 - accuracy: 0.8653 - val_loss: 0.3418 - val_accuracy: 0.8484 - 3s/epoch - 51ms/step\n",
      "Epoch 168/250\n",
      "49/49 - 3s - loss: 0.3141 - accuracy: 0.8666 - val_loss: 0.3416 - val_accuracy: 0.8495 - 3s/epoch - 52ms/step\n",
      "Epoch 169/250\n",
      "49/49 - 3s - loss: 0.3146 - accuracy: 0.8596 - val_loss: 0.3417 - val_accuracy: 0.8472 - 3s/epoch - 54ms/step\n",
      "Epoch 170/250\n",
      "49/49 - 4s - loss: 0.3168 - accuracy: 0.8641 - val_loss: 0.3404 - val_accuracy: 0.8484 - 4s/epoch - 84ms/step\n",
      "Epoch 171/250\n",
      "49/49 - 4s - loss: 0.3186 - accuracy: 0.8653 - val_loss: 0.3406 - val_accuracy: 0.8472 - 4s/epoch - 83ms/step\n",
      "Epoch 172/250\n",
      "49/49 - 5s - loss: 0.3207 - accuracy: 0.8653 - val_loss: 0.3401 - val_accuracy: 0.8507 - 5s/epoch - 95ms/step\n",
      "Epoch 173/250\n",
      "49/49 - 5s - loss: 0.3113 - accuracy: 0.8672 - val_loss: 0.3407 - val_accuracy: 0.8495 - 5s/epoch - 93ms/step\n",
      "Epoch 174/250\n",
      "49/49 - 4s - loss: 0.3130 - accuracy: 0.8666 - val_loss: 0.3392 - val_accuracy: 0.8472 - 4s/epoch - 86ms/step\n",
      "Epoch 175/250\n",
      "49/49 - 4s - loss: 0.3143 - accuracy: 0.8647 - val_loss: 0.3388 - val_accuracy: 0.8484 - 4s/epoch - 83ms/step\n",
      "Epoch 176/250\n",
      "49/49 - 4s - loss: 0.3107 - accuracy: 0.8655 - val_loss: 0.3386 - val_accuracy: 0.8484 - 4s/epoch - 87ms/step\n",
      "Epoch 177/250\n",
      "49/49 - 5s - loss: 0.3077 - accuracy: 0.8655 - val_loss: 0.3401 - val_accuracy: 0.8507 - 5s/epoch - 95ms/step\n",
      "Epoch 178/250\n",
      "49/49 - 5s - loss: 0.3216 - accuracy: 0.8598 - val_loss: 0.3383 - val_accuracy: 0.8484 - 5s/epoch - 101ms/step\n",
      "Epoch 179/250\n",
      "49/49 - 4s - loss: 0.3082 - accuracy: 0.8692 - val_loss: 0.3381 - val_accuracy: 0.8484 - 4s/epoch - 89ms/step\n",
      "Epoch 180/250\n",
      "49/49 - 5s - loss: 0.3146 - accuracy: 0.8641 - val_loss: 0.3392 - val_accuracy: 0.8507 - 5s/epoch - 100ms/step\n",
      "Epoch 181/250\n",
      "49/49 - 5s - loss: 0.3123 - accuracy: 0.8666 - val_loss: 0.3376 - val_accuracy: 0.8484 - 5s/epoch - 96ms/step\n",
      "Epoch 182/250\n",
      "49/49 - 5s - loss: 0.3078 - accuracy: 0.8692 - val_loss: 0.3380 - val_accuracy: 0.8507 - 5s/epoch - 97ms/step\n",
      "Epoch 183/250\n",
      "49/49 - 5s - loss: 0.3137 - accuracy: 0.8723 - val_loss: 0.3383 - val_accuracy: 0.8507 - 5s/epoch - 100ms/step\n",
      "Epoch 184/250\n",
      "49/49 - 5s - loss: 0.3016 - accuracy: 0.8739 - val_loss: 0.3365 - val_accuracy: 0.8484 - 5s/epoch - 98ms/step\n",
      "Epoch 185/250\n",
      "49/49 - 4s - loss: 0.3073 - accuracy: 0.8668 - val_loss: 0.3364 - val_accuracy: 0.8495 - 4s/epoch - 87ms/step\n",
      "Epoch 186/250\n",
      "49/49 - 4s - loss: 0.3155 - accuracy: 0.8641 - val_loss: 0.3375 - val_accuracy: 0.8507 - 4s/epoch - 87ms/step\n",
      "Epoch 187/250\n",
      "49/49 - 4s - loss: 0.3027 - accuracy: 0.8705 - val_loss: 0.3374 - val_accuracy: 0.8507 - 4s/epoch - 86ms/step\n",
      "Epoch 188/250\n",
      "49/49 - 4s - loss: 0.3111 - accuracy: 0.8676 - val_loss: 0.3361 - val_accuracy: 0.8495 - 4s/epoch - 83ms/step\n",
      "Epoch 189/250\n",
      "49/49 - 4s - loss: 0.3136 - accuracy: 0.8674 - val_loss: 0.3359 - val_accuracy: 0.8507 - 4s/epoch - 77ms/step\n",
      "Epoch 190/250\n",
      "49/49 - 4s - loss: 0.3021 - accuracy: 0.8735 - val_loss: 0.3349 - val_accuracy: 0.8507 - 4s/epoch - 80ms/step\n",
      "Epoch 191/250\n",
      "49/49 - 4s - loss: 0.3093 - accuracy: 0.8707 - val_loss: 0.3374 - val_accuracy: 0.8484 - 4s/epoch - 80ms/step\n",
      "Epoch 192/250\n",
      "49/49 - 4s - loss: 0.2985 - accuracy: 0.8705 - val_loss: 0.3367 - val_accuracy: 0.8484 - 4s/epoch - 74ms/step\n",
      "Epoch 193/250\n",
      "49/49 - 4s - loss: 0.3000 - accuracy: 0.8715 - val_loss: 0.3359 - val_accuracy: 0.8507 - 4s/epoch - 75ms/step\n",
      "Epoch 194/250\n",
      "49/49 - 4s - loss: 0.3048 - accuracy: 0.8700 - val_loss: 0.3347 - val_accuracy: 0.8507 - 4s/epoch - 72ms/step\n",
      "Epoch 195/250\n",
      "49/49 - 4s - loss: 0.3073 - accuracy: 0.8651 - val_loss: 0.3344 - val_accuracy: 0.8507 - 4s/epoch - 75ms/step\n",
      "Epoch 196/250\n",
      "49/49 - 4s - loss: 0.3061 - accuracy: 0.8692 - val_loss: 0.3350 - val_accuracy: 0.8519 - 4s/epoch - 78ms/step\n",
      "Epoch 197/250\n",
      "49/49 - 4s - loss: 0.3097 - accuracy: 0.8662 - val_loss: 0.3341 - val_accuracy: 0.8530 - 4s/epoch - 81ms/step\n",
      "Epoch 198/250\n",
      "49/49 - 4s - loss: 0.3033 - accuracy: 0.8768 - val_loss: 0.3336 - val_accuracy: 0.8530 - 4s/epoch - 77ms/step\n",
      "Epoch 199/250\n",
      "49/49 - 4s - loss: 0.3030 - accuracy: 0.8698 - val_loss: 0.3339 - val_accuracy: 0.8542 - 4s/epoch - 74ms/step\n",
      "Epoch 200/250\n",
      "49/49 - 4s - loss: 0.2970 - accuracy: 0.8733 - val_loss: 0.3342 - val_accuracy: 0.8530 - 4s/epoch - 75ms/step\n",
      "Epoch 201/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 - 4s - loss: 0.3124 - accuracy: 0.8643 - val_loss: 0.3344 - val_accuracy: 0.8519 - 4s/epoch - 82ms/step\n",
      "Epoch 202/250\n",
      "49/49 - 4s - loss: 0.2953 - accuracy: 0.8752 - val_loss: 0.3331 - val_accuracy: 0.8530 - 4s/epoch - 76ms/step\n",
      "Epoch 203/250\n",
      "49/49 - 4s - loss: 0.3003 - accuracy: 0.8739 - val_loss: 0.3339 - val_accuracy: 0.8542 - 4s/epoch - 74ms/step\n",
      "Epoch 204/250\n",
      "49/49 - 4s - loss: 0.3024 - accuracy: 0.8698 - val_loss: 0.3335 - val_accuracy: 0.8542 - 4s/epoch - 75ms/step\n",
      "Epoch 205/250\n",
      "49/49 - 4s - loss: 0.2972 - accuracy: 0.8752 - val_loss: 0.3330 - val_accuracy: 0.8542 - 4s/epoch - 78ms/step\n",
      "Epoch 206/250\n",
      "49/49 - 4s - loss: 0.2990 - accuracy: 0.8739 - val_loss: 0.3319 - val_accuracy: 0.8542 - 4s/epoch - 76ms/step\n",
      "Epoch 207/250\n",
      "49/49 - 4s - loss: 0.3015 - accuracy: 0.8655 - val_loss: 0.3329 - val_accuracy: 0.8530 - 4s/epoch - 77ms/step\n",
      "Epoch 208/250\n",
      "49/49 - 4s - loss: 0.3059 - accuracy: 0.8690 - val_loss: 0.3309 - val_accuracy: 0.8542 - 4s/epoch - 78ms/step\n",
      "Epoch 209/250\n",
      "49/49 - 4s - loss: 0.3050 - accuracy: 0.8678 - val_loss: 0.3318 - val_accuracy: 0.8542 - 4s/epoch - 77ms/step\n",
      "Epoch 210/250\n",
      "49/49 - 4s - loss: 0.2959 - accuracy: 0.8739 - val_loss: 0.3314 - val_accuracy: 0.8542 - 4s/epoch - 79ms/step\n",
      "Epoch 211/250\n",
      "49/49 - 4s - loss: 0.3080 - accuracy: 0.8707 - val_loss: 0.3320 - val_accuracy: 0.8530 - 4s/epoch - 79ms/step\n",
      "Epoch 212/250\n",
      "49/49 - 4s - loss: 0.2974 - accuracy: 0.8749 - val_loss: 0.3290 - val_accuracy: 0.8565 - 4s/epoch - 76ms/step\n",
      "Epoch 213/250\n",
      "49/49 - 4s - loss: 0.3002 - accuracy: 0.8727 - val_loss: 0.3306 - val_accuracy: 0.8542 - 4s/epoch - 79ms/step\n",
      "Epoch 214/250\n",
      "49/49 - 4s - loss: 0.3003 - accuracy: 0.8709 - val_loss: 0.3294 - val_accuracy: 0.8553 - 4s/epoch - 74ms/step\n",
      "Epoch 215/250\n",
      "49/49 - 4s - loss: 0.2966 - accuracy: 0.8725 - val_loss: 0.3304 - val_accuracy: 0.8519 - 4s/epoch - 77ms/step\n",
      "Epoch 216/250\n",
      "49/49 - 4s - loss: 0.2975 - accuracy: 0.8772 - val_loss: 0.3303 - val_accuracy: 0.8519 - 4s/epoch - 74ms/step\n",
      "Epoch 217/250\n",
      "49/49 - 4s - loss: 0.2997 - accuracy: 0.8739 - val_loss: 0.3307 - val_accuracy: 0.8519 - 4s/epoch - 75ms/step\n",
      "Epoch 218/250\n",
      "49/49 - 4s - loss: 0.3038 - accuracy: 0.8666 - val_loss: 0.3290 - val_accuracy: 0.8530 - 4s/epoch - 82ms/step\n",
      "Epoch 219/250\n",
      "49/49 - 4s - loss: 0.3001 - accuracy: 0.8733 - val_loss: 0.3295 - val_accuracy: 0.8507 - 4s/epoch - 77ms/step\n",
      "Epoch 220/250\n",
      "49/49 - 4s - loss: 0.3019 - accuracy: 0.8700 - val_loss: 0.3281 - val_accuracy: 0.8553 - 4s/epoch - 72ms/step\n",
      "Epoch 221/250\n",
      "49/49 - 4s - loss: 0.2915 - accuracy: 0.8784 - val_loss: 0.3276 - val_accuracy: 0.8553 - 4s/epoch - 78ms/step\n",
      "Epoch 222/250\n",
      "49/49 - 4s - loss: 0.2901 - accuracy: 0.8770 - val_loss: 0.3283 - val_accuracy: 0.8530 - 4s/epoch - 80ms/step\n",
      "Epoch 223/250\n",
      "49/49 - 4s - loss: 0.2924 - accuracy: 0.8741 - val_loss: 0.3290 - val_accuracy: 0.8530 - 4s/epoch - 81ms/step\n",
      "Epoch 224/250\n",
      "49/49 - 4s - loss: 0.2977 - accuracy: 0.8694 - val_loss: 0.3264 - val_accuracy: 0.8576 - 4s/epoch - 78ms/step\n",
      "Epoch 225/250\n",
      "49/49 - 4s - loss: 0.2873 - accuracy: 0.8809 - val_loss: 0.3266 - val_accuracy: 0.8553 - 4s/epoch - 81ms/step\n",
      "Epoch 226/250\n",
      "49/49 - 4s - loss: 0.3024 - accuracy: 0.8721 - val_loss: 0.3297 - val_accuracy: 0.8519 - 4s/epoch - 80ms/step\n",
      "Epoch 227/250\n",
      "49/49 - 4s - loss: 0.2964 - accuracy: 0.8662 - val_loss: 0.3267 - val_accuracy: 0.8530 - 4s/epoch - 79ms/step\n",
      "Epoch 228/250\n",
      "49/49 - 4s - loss: 0.2950 - accuracy: 0.8770 - val_loss: 0.3293 - val_accuracy: 0.8507 - 4s/epoch - 82ms/step\n",
      "Epoch 229/250\n",
      "49/49 - 4s - loss: 0.2928 - accuracy: 0.8782 - val_loss: 0.3270 - val_accuracy: 0.8542 - 4s/epoch - 82ms/step\n",
      "Epoch 230/250\n",
      "49/49 - 4s - loss: 0.2852 - accuracy: 0.8803 - val_loss: 0.3265 - val_accuracy: 0.8542 - 4s/epoch - 82ms/step\n",
      "Epoch 231/250\n",
      "49/49 - 4s - loss: 0.2850 - accuracy: 0.8786 - val_loss: 0.3255 - val_accuracy: 0.8565 - 4s/epoch - 79ms/step\n",
      "Epoch 232/250\n",
      "49/49 - 4s - loss: 0.2858 - accuracy: 0.8799 - val_loss: 0.3263 - val_accuracy: 0.8565 - 4s/epoch - 77ms/step\n",
      "Epoch 233/250\n",
      "49/49 - 5s - loss: 0.2921 - accuracy: 0.8786 - val_loss: 0.3260 - val_accuracy: 0.8565 - 5s/epoch - 93ms/step\n",
      "Epoch 234/250\n",
      "49/49 - 4s - loss: 0.2888 - accuracy: 0.8799 - val_loss: 0.3247 - val_accuracy: 0.8553 - 4s/epoch - 78ms/step\n",
      "Epoch 235/250\n",
      "49/49 - 3s - loss: 0.2892 - accuracy: 0.8743 - val_loss: 0.3250 - val_accuracy: 0.8565 - 3s/epoch - 71ms/step\n",
      "Epoch 236/250\n",
      "49/49 - 3s - loss: 0.2846 - accuracy: 0.8848 - val_loss: 0.3254 - val_accuracy: 0.8576 - 3s/epoch - 64ms/step\n",
      "Epoch 237/250\n",
      "49/49 - 3s - loss: 0.2894 - accuracy: 0.8774 - val_loss: 0.3263 - val_accuracy: 0.8542 - 3s/epoch - 57ms/step\n",
      "Epoch 238/250\n",
      "49/49 - 3s - loss: 0.2913 - accuracy: 0.8774 - val_loss: 0.3255 - val_accuracy: 0.8588 - 3s/epoch - 53ms/step\n",
      "Epoch 239/250\n",
      "49/49 - 3s - loss: 0.2910 - accuracy: 0.8799 - val_loss: 0.3254 - val_accuracy: 0.8553 - 3s/epoch - 55ms/step\n",
      "Epoch 240/250\n",
      "49/49 - 3s - loss: 0.2972 - accuracy: 0.8723 - val_loss: 0.3234 - val_accuracy: 0.8588 - 3s/epoch - 54ms/step\n",
      "Epoch 241/250\n",
      "49/49 - 3s - loss: 0.2837 - accuracy: 0.8794 - val_loss: 0.3243 - val_accuracy: 0.8553 - 3s/epoch - 55ms/step\n",
      "Epoch 242/250\n",
      "49/49 - 3s - loss: 0.2766 - accuracy: 0.8827 - val_loss: 0.3247 - val_accuracy: 0.8565 - 3s/epoch - 56ms/step\n",
      "Epoch 243/250\n",
      "49/49 - 3s - loss: 0.2845 - accuracy: 0.8823 - val_loss: 0.3239 - val_accuracy: 0.8542 - 3s/epoch - 57ms/step\n",
      "Epoch 244/250\n",
      "49/49 - 3s - loss: 0.2816 - accuracy: 0.8819 - val_loss: 0.3258 - val_accuracy: 0.8565 - 3s/epoch - 57ms/step\n",
      "Epoch 245/250\n",
      "49/49 - 3s - loss: 0.2803 - accuracy: 0.8846 - val_loss: 0.3247 - val_accuracy: 0.8565 - 3s/epoch - 58ms/step\n",
      "Epoch 246/250\n",
      "49/49 - 3s - loss: 0.2829 - accuracy: 0.8764 - val_loss: 0.3246 - val_accuracy: 0.8565 - 3s/epoch - 59ms/step\n",
      "Epoch 247/250\n",
      "49/49 - 3s - loss: 0.2867 - accuracy: 0.8760 - val_loss: 0.3250 - val_accuracy: 0.8542 - 3s/epoch - 71ms/step\n",
      "Epoch 248/250\n",
      "49/49 - 4s - loss: 0.2785 - accuracy: 0.8817 - val_loss: 0.3256 - val_accuracy: 0.8553 - 4s/epoch - 84ms/step\n",
      "Epoch 249/250\n",
      "49/49 - 4s - loss: 0.2869 - accuracy: 0.8807 - val_loss: 0.3239 - val_accuracy: 0.8553 - 4s/epoch - 80ms/step\n",
      "Epoch 250/250\n",
      "49/49 - 4s - loss: 0.2832 - accuracy: 0.8841 - val_loss: 0.3236 - val_accuracy: 0.8565 - 4s/epoch - 82ms/step\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,batch_size=100,epochs=250,validation_data=(X_test,y_test),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5f6c991f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "1224/1224 - 20s - loss: 0.2872 - accuracy: 0.8782 - val_loss: 0.3166 - val_accuracy: 0.8634 - 20s/epoch - 16ms/step\n",
      "Epoch 2/250\n",
      "1224/1224 - 20s - loss: 0.2762 - accuracy: 0.8856 - val_loss: 0.3170 - val_accuracy: 0.8646 - 20s/epoch - 16ms/step\n",
      "Epoch 3/250\n",
      "1224/1224 - 23s - loss: 0.2777 - accuracy: 0.8856 - val_loss: 0.3186 - val_accuracy: 0.8634 - 23s/epoch - 19ms/step\n",
      "Epoch 4/250\n",
      "1224/1224 - 26s - loss: 0.2765 - accuracy: 0.8852 - val_loss: 0.3156 - val_accuracy: 0.8669 - 26s/epoch - 21ms/step\n",
      "Epoch 5/250\n",
      "1224/1224 - 25s - loss: 0.2792 - accuracy: 0.8807 - val_loss: 0.3121 - val_accuracy: 0.8727 - 25s/epoch - 21ms/step\n",
      "Epoch 6/250\n",
      "1224/1224 - 27s - loss: 0.2797 - accuracy: 0.8833 - val_loss: 0.3176 - val_accuracy: 0.8634 - 27s/epoch - 22ms/step\n",
      "Epoch 7/250\n",
      "1224/1224 - 28s - loss: 0.2709 - accuracy: 0.8862 - val_loss: 0.3119 - val_accuracy: 0.8727 - 28s/epoch - 23ms/step\n",
      "Epoch 8/250\n",
      "1224/1224 - 22s - loss: 0.2725 - accuracy: 0.8846 - val_loss: 0.3140 - val_accuracy: 0.8646 - 22s/epoch - 18ms/step\n",
      "Epoch 9/250\n",
      "1224/1224 - 30s - loss: 0.2551 - accuracy: 0.8950 - val_loss: 0.3265 - val_accuracy: 0.8623 - 30s/epoch - 24ms/step\n",
      "Epoch 10/250\n",
      "1224/1224 - 27s - loss: 0.2625 - accuracy: 0.8841 - val_loss: 0.3137 - val_accuracy: 0.8646 - 27s/epoch - 22ms/step\n",
      "Epoch 11/250\n",
      "1224/1224 - 28s - loss: 0.2669 - accuracy: 0.8860 - val_loss: 0.3158 - val_accuracy: 0.8657 - 28s/epoch - 23ms/step\n",
      "Epoch 12/250\n",
      "1224/1224 - 26s - loss: 0.2575 - accuracy: 0.8911 - val_loss: 0.3228 - val_accuracy: 0.8646 - 26s/epoch - 21ms/step\n",
      "Epoch 13/250\n",
      "1224/1224 - 19s - loss: 0.2526 - accuracy: 0.8964 - val_loss: 0.3162 - val_accuracy: 0.8715 - 19s/epoch - 15ms/step\n",
      "Epoch 14/250\n",
      "1224/1224 - 22s - loss: 0.2583 - accuracy: 0.8929 - val_loss: 0.3176 - val_accuracy: 0.8750 - 22s/epoch - 18ms/step\n",
      "Epoch 15/250\n",
      "1224/1224 - 26s - loss: 0.2525 - accuracy: 0.8929 - val_loss: 0.3169 - val_accuracy: 0.8727 - 26s/epoch - 21ms/step\n",
      "Epoch 16/250\n",
      "1224/1224 - 24s - loss: 0.2473 - accuracy: 0.8956 - val_loss: 0.3139 - val_accuracy: 0.8681 - 24s/epoch - 20ms/step\n",
      "Epoch 17/250\n",
      "1224/1224 - 26s - loss: 0.2521 - accuracy: 0.8960 - val_loss: 0.3232 - val_accuracy: 0.8704 - 26s/epoch - 21ms/step\n",
      "Epoch 18/250\n",
      "1224/1224 - 23s - loss: 0.2462 - accuracy: 0.8997 - val_loss: 0.3222 - val_accuracy: 0.8727 - 23s/epoch - 19ms/step\n",
      "Epoch 19/250\n",
      "1224/1224 - 25s - loss: 0.2578 - accuracy: 0.8921 - val_loss: 0.3109 - val_accuracy: 0.8715 - 25s/epoch - 20ms/step\n",
      "Epoch 20/250\n",
      "1224/1224 - 28s - loss: 0.2466 - accuracy: 0.9013 - val_loss: 0.3094 - val_accuracy: 0.8727 - 28s/epoch - 23ms/step\n",
      "Epoch 21/250\n",
      "1224/1224 - 27s - loss: 0.2407 - accuracy: 0.8989 - val_loss: 0.3117 - val_accuracy: 0.8704 - 27s/epoch - 22ms/step\n",
      "Epoch 22/250\n",
      "1224/1224 - 26s - loss: 0.2384 - accuracy: 0.9005 - val_loss: 0.3208 - val_accuracy: 0.8715 - 26s/epoch - 21ms/step\n",
      "Epoch 23/250\n",
      "1224/1224 - 26s - loss: 0.2407 - accuracy: 0.8980 - val_loss: 0.3092 - val_accuracy: 0.8750 - 26s/epoch - 21ms/step\n",
      "Epoch 24/250\n",
      "1224/1224 - 23s - loss: 0.2414 - accuracy: 0.9015 - val_loss: 0.3170 - val_accuracy: 0.8738 - 23s/epoch - 19ms/step\n",
      "Epoch 25/250\n",
      "1224/1224 - 23s - loss: 0.2436 - accuracy: 0.9021 - val_loss: 0.3191 - val_accuracy: 0.8692 - 23s/epoch - 18ms/step\n",
      "Epoch 26/250\n",
      "1224/1224 - 25s - loss: 0.2355 - accuracy: 0.9019 - val_loss: 0.3183 - val_accuracy: 0.8704 - 25s/epoch - 20ms/step\n",
      "Epoch 27/250\n",
      "1224/1224 - 23s - loss: 0.2245 - accuracy: 0.9128 - val_loss: 0.3071 - val_accuracy: 0.8773 - 23s/epoch - 19ms/step\n",
      "Epoch 28/250\n",
      "1224/1224 - 23s - loss: 0.2293 - accuracy: 0.9056 - val_loss: 0.3092 - val_accuracy: 0.8785 - 23s/epoch - 19ms/step\n",
      "Epoch 29/250\n",
      "1224/1224 - 24s - loss: 0.2338 - accuracy: 0.9042 - val_loss: 0.3089 - val_accuracy: 0.8750 - 24s/epoch - 19ms/step\n",
      "Epoch 30/250\n",
      "1224/1224 - 24s - loss: 0.2258 - accuracy: 0.9099 - val_loss: 0.3088 - val_accuracy: 0.8738 - 24s/epoch - 19ms/step\n",
      "Epoch 31/250\n",
      "1224/1224 - 22s - loss: 0.2255 - accuracy: 0.9085 - val_loss: 0.3145 - val_accuracy: 0.8738 - 22s/epoch - 18ms/step\n",
      "Epoch 32/250\n",
      "1224/1224 - 22s - loss: 0.2220 - accuracy: 0.9142 - val_loss: 0.3076 - val_accuracy: 0.8843 - 22s/epoch - 18ms/step\n",
      "Epoch 33/250\n",
      "1224/1224 - 25s - loss: 0.2253 - accuracy: 0.9105 - val_loss: 0.3188 - val_accuracy: 0.8727 - 25s/epoch - 21ms/step\n",
      "Epoch 34/250\n",
      "1224/1224 - 20s - loss: 0.2226 - accuracy: 0.9089 - val_loss: 0.3145 - val_accuracy: 0.8738 - 20s/epoch - 16ms/step\n",
      "Epoch 35/250\n",
      "1224/1224 - 18s - loss: 0.2277 - accuracy: 0.9070 - val_loss: 0.3131 - val_accuracy: 0.8796 - 18s/epoch - 14ms/step\n",
      "Epoch 36/250\n",
      "1224/1224 - 19s - loss: 0.2264 - accuracy: 0.9087 - val_loss: 0.3073 - val_accuracy: 0.8819 - 19s/epoch - 15ms/step\n",
      "Epoch 37/250\n",
      "1224/1224 - 18s - loss: 0.2279 - accuracy: 0.9093 - val_loss: 0.3118 - val_accuracy: 0.8843 - 18s/epoch - 15ms/step\n",
      "Epoch 38/250\n",
      "1224/1224 - 18s - loss: 0.2196 - accuracy: 0.9081 - val_loss: 0.3126 - val_accuracy: 0.8843 - 18s/epoch - 14ms/step\n",
      "Epoch 39/250\n",
      "1224/1224 - 18s - loss: 0.2191 - accuracy: 0.9095 - val_loss: 0.3137 - val_accuracy: 0.8843 - 18s/epoch - 15ms/step\n",
      "Epoch 40/250\n",
      "1224/1224 - 19s - loss: 0.2228 - accuracy: 0.9036 - val_loss: 0.3146 - val_accuracy: 0.8808 - 19s/epoch - 15ms/step\n",
      "Epoch 41/250\n",
      "1224/1224 - 17s - loss: 0.2190 - accuracy: 0.9146 - val_loss: 0.3096 - val_accuracy: 0.8819 - 17s/epoch - 14ms/step\n",
      "Epoch 42/250\n",
      "1224/1224 - 17s - loss: 0.2202 - accuracy: 0.9152 - val_loss: 0.3196 - val_accuracy: 0.8785 - 17s/epoch - 14ms/step\n",
      "Epoch 43/250\n",
      "1224/1224 - 18s - loss: 0.2124 - accuracy: 0.9162 - val_loss: 0.3098 - val_accuracy: 0.8796 - 18s/epoch - 15ms/step\n",
      "Epoch 44/250\n",
      "1224/1224 - 19s - loss: 0.2122 - accuracy: 0.9156 - val_loss: 0.3169 - val_accuracy: 0.8773 - 19s/epoch - 15ms/step\n",
      "Epoch 45/250\n",
      "1224/1224 - 18s - loss: 0.2072 - accuracy: 0.9172 - val_loss: 0.3210 - val_accuracy: 0.8750 - 18s/epoch - 15ms/step\n",
      "Epoch 46/250\n",
      "1224/1224 - 18s - loss: 0.2075 - accuracy: 0.9162 - val_loss: 0.3162 - val_accuracy: 0.8750 - 18s/epoch - 15ms/step\n",
      "Epoch 47/250\n",
      "1224/1224 - 17s - loss: 0.2064 - accuracy: 0.9174 - val_loss: 0.3151 - val_accuracy: 0.8773 - 17s/epoch - 14ms/step\n",
      "Epoch 48/250\n",
      "1224/1224 - 17s - loss: 0.2130 - accuracy: 0.9146 - val_loss: 0.3111 - val_accuracy: 0.8762 - 17s/epoch - 14ms/step\n",
      "Epoch 49/250\n",
      "1224/1224 - 17s - loss: 0.2036 - accuracy: 0.9197 - val_loss: 0.3112 - val_accuracy: 0.8750 - 17s/epoch - 14ms/step\n",
      "Epoch 50/250\n",
      "1224/1224 - 17s - loss: 0.2023 - accuracy: 0.9162 - val_loss: 0.3164 - val_accuracy: 0.8785 - 17s/epoch - 14ms/step\n",
      "Epoch 51/250\n",
      "1224/1224 - 18s - loss: 0.2016 - accuracy: 0.9187 - val_loss: 0.3220 - val_accuracy: 0.8808 - 18s/epoch - 15ms/step\n",
      "Epoch 52/250\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14024/1069306208.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Users\\George\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\George\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\George\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\George\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\George\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\George\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\George\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mD:\\Users\\George\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\George\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,batch_size=4,epochs=250,validation_data=(X_test,y_test),verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c052a3",
   "metadata": {},
   "source": [
    "# ans = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05215e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c47c7998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(864, 20)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "55e3381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = np.round(ans).astype(int).reshape(864)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a96b4fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.49      0.51       432\n",
      "           1       0.53      0.59      0.56       432\n",
      "\n",
      "    accuracy                           0.54       864\n",
      "   macro avg       0.54      0.54      0.54       864\n",
      "weighted avg       0.54      0.54      0.54       864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ans,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "086782dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 2, 'epochs': 250, 'steps': 49}\n"
     ]
    }
   ],
   "source": [
    "print(history.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "85d5227c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b895023d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e43a1fa9",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12176/1716962898.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mzeros\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mones\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "ones = 0\n",
    "zeros = 0\n",
    "for i in range(len(ans)):\n",
    "    if ans[i][0]>=0.5:\n",
    "        ans[i][0] = 1\n",
    "        ones+=1\n",
    "    else:\n",
    "        ans[i][0] = 0\n",
    "        zeros += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a00b1a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "adb418b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "73bdc840",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre=model.predict(test_m)\n",
    "y_pre=np.round(y_pre).astype(int).reshape(1000)\n",
    "sub=pd.DataFrame({'title':test['title'].values.tolist(),'is_fake':y_pre})\n",
    "sub.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3684a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
